{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Import-packages\" data-toc-modified-id=\"1.-Import-packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Import packages</a></span></li><li><span><a href=\"#2.-Set-variables\" data-toc-modified-id=\"2.-Set-variables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. Set variables</a></span></li><li><span><a href=\"#3.-Set-functions\" data-toc-modified-id=\"3.-Set-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Set functions</a></span></li><li><span><a href=\"#4.-Load-data\" data-toc-modified-id=\"4.-Load-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. Load data</a></span></li><li><span><a href=\"#5.-Concat-data\" data-toc-modified-id=\"5.-Concat-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>5. Concat data</a></span></li><li><span><a href=\"#6.-Clear-and-analyse-data\" data-toc-modified-id=\"6.-Clear-and-analyse-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>6. Clear and analyse data</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Get-skewed-columns\" data-toc-modified-id=\"6.1-Get-skewed-columns-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>6.1 Get skewed columns</a></span></li><li><span><a href=\"#6.2-Get-highly-correlated-columns\" data-toc-modified-id=\"6.2-Get-highly-correlated-columns-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>6.2 Get highly correlated columns</a></span></li><li><span><a href=\"#6.3-Analyse-missing-values-in-columns\" data-toc-modified-id=\"6.3-Analyse-missing-values-in-columns-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>6.3 Analyse missing values in columns</a></span></li></ul></li><li><span><a href=\"#7.-Load-processed-data\" data-toc-modified-id=\"7.-Load-processed-data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>7. Load processed data</a></span></li><li><span><a href=\"#8.-Boruta\" data-toc-modified-id=\"8.-Boruta-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>8. Boruta</a></span></li><li><span><a href=\"#9.-RandomForest\" data-toc-modified-id=\"9.-RandomForest-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>9. RandomForest</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Finding-the-best-depth\" data-toc-modified-id=\"9.1-Finding-the-best-depth-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>9.1 Finding the best depth</a></span></li><li><span><a href=\"#9.2-Model-with-all-features\" data-toc-modified-id=\"9.2-Model-with-all-features-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>9.2 Model with all features</a></span></li><li><span><a href=\"#9.3-Finding-the-best-params\" data-toc-modified-id=\"9.3-Finding-the-best-params-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>9.3 Finding the best params</a></span></li><li><span><a href=\"#9.4-Final-model\" data-toc-modified-id=\"9.4-Final-model-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>9.4 Final model</a></span></li></ul></li><li><span><a href=\"#10.-ExtraTrees\" data-toc-modified-id=\"10.-ExtraTrees-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>10. ExtraTrees</a></span><ul class=\"toc-item\"><li><span><a href=\"#10.1-Finding-the-best-depth\" data-toc-modified-id=\"10.1-Finding-the-best-depth-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>10.1 Finding the best depth</a></span></li><li><span><a href=\"#10.2-Model-with-all-features\" data-toc-modified-id=\"10.2-Model-with-all-features-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>10.2 Model with all features</a></span></li><li><span><a href=\"#10.3-Finding-the-best-params\" data-toc-modified-id=\"10.3-Finding-the-best-params-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>10.3 Finding the best params</a></span></li><li><span><a href=\"#10.4-Final-model\" data-toc-modified-id=\"10.4-Final-model-10.4\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>10.4 Final model</a></span></li></ul></li><li><span><a href=\"#11.-XGBoost\" data-toc-modified-id=\"11.-XGBoost-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>11. XGBoost</a></span><ul class=\"toc-item\"><li><span><a href=\"#11.0-XGBoost-datasets\" data-toc-modified-id=\"11.0-XGBoost-datasets-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>11.0 XGBoost datasets</a></span></li><li><span><a href=\"#11.1-Finding-the-best-depth\" data-toc-modified-id=\"11.1-Finding-the-best-depth-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>11.1 Finding the best depth</a></span></li><li><span><a href=\"#11.2-Model-with-all-features\" data-toc-modified-id=\"11.2-Model-with-all-features-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>11.2 Model with all features</a></span></li><li><span><a href=\"#11.3-Finding-the-best-params\" data-toc-modified-id=\"11.3-Finding-the-best-params-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>11.3 Finding the best params</a></span></li><li><span><a href=\"#11.4-Final-model\" data-toc-modified-id=\"11.4-Final-model-11.5\"><span class=\"toc-item-num\">11.5&nbsp;&nbsp;</span>11.4 Final model</a></span></li></ul></li><li><span><a href=\"#12.-LightGBM\" data-toc-modified-id=\"12.-LightGBM-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>12. LightGBM</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.0-LightGBM-datasets\" data-toc-modified-id=\"7.0-LightGBM-datasets-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>7.0 LightGBM datasets</a></span></li><li><span><a href=\"#12.1-Finding-the-best-depth-and-num_leaves-trees\" data-toc-modified-id=\"12.1-Finding-the-best-depth-and-num_leaves-trees-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>12.1 Finding the best depth and num_leaves trees</a></span></li><li><span><a href=\"#12.2-Model-with-all-features-trees\" data-toc-modified-id=\"12.2-Model-with-all-features-trees-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>12.2 Model with all features trees</a></span></li><li><span><a href=\"#12.3-Finding-the-best-params-trees\" data-toc-modified-id=\"12.3-Finding-the-best-params-trees-12.4\"><span class=\"toc-item-num\">12.4&nbsp;&nbsp;</span>12.3 Finding the best params trees</a></span></li><li><span><a href=\"#12.4-Final-model-trees\" data-toc-modified-id=\"12.4-Final-model-trees-12.5\"><span class=\"toc-item-num\">12.5&nbsp;&nbsp;</span>12.4 Final model trees</a></span></li><li><span><a href=\"#12.5-Finding-the-best-params-goss\" data-toc-modified-id=\"12.5-Finding-the-best-params-goss-12.6\"><span class=\"toc-item-num\">12.6&nbsp;&nbsp;</span>12.5 Finding the best params goss</a></span></li><li><span><a href=\"#12.6-Final-model-goss\" data-toc-modified-id=\"12.6-Final-model-goss-12.7\"><span class=\"toc-item-num\">12.7&nbsp;&nbsp;</span>12.6 Final model goss</a></span></li><li><span><a href=\"#12.7-Finding-the-best-params-dart\" data-toc-modified-id=\"12.7-Finding-the-best-params-dart-12.8\"><span class=\"toc-item-num\">12.8&nbsp;&nbsp;</span>12.7 Finding the best params dart</a></span></li><li><span><a href=\"#12.8-Final-model-dart\" data-toc-modified-id=\"12.8-Final-model-dart-12.9\"><span class=\"toc-item-num\">12.9&nbsp;&nbsp;</span>12.8 Final model dart</a></span></li></ul></li><li><span><a href=\"#13.-Catboost\" data-toc-modified-id=\"13.-Catboost-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>13. Catboost</a></span><ul class=\"toc-item\"><li><span><a href=\"#13.0-Catboost-datasets\" data-toc-modified-id=\"13.0-Catboost-datasets-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>13.0 Catboost datasets</a></span></li><li><span><a href=\"#13.1-Finding-the-best-one_hot_max_size-and-depth\" data-toc-modified-id=\"13.1-Finding-the-best-one_hot_max_size-and-depth-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>13.1 Finding the best one_hot_max_size and depth</a></span></li><li><span><a href=\"#13.2-Model-with-all-features\" data-toc-modified-id=\"13.2-Model-with-all-features-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;</span>13.2 Model with all features</a></span></li><li><span><a href=\"#13.3-Finding-the-best-params\" data-toc-modified-id=\"13.3-Finding-the-best-params-13.4\"><span class=\"toc-item-num\">13.4&nbsp;&nbsp;</span>13.3 Finding the best params</a></span></li><li><span><a href=\"#13.4-Final-model\" data-toc-modified-id=\"13.4-Final-model-13.5\"><span class=\"toc-item-num\">13.5&nbsp;&nbsp;</span>13.4 Final model</a></span></li></ul></li><li><span><a href=\"#14.-NN\" data-toc-modified-id=\"14.-NN-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>14. NN</a></span></li><li><span><a href=\"#15.-Final-calcs\" data-toc-modified-id=\"15.-Final-calcs-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>15. Final calcs</a></span></li><li><span><a href=\"#16.-Stacking\" data-toc-modified-id=\"16.-Stacking-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>16. Stacking</a></span></li><li><span><a href=\"#17.--Ensemble\" data-toc-modified-id=\"17.--Ensemble-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>17.  Ensemble</a></span></li><li><span><a href=\"#18.-Submit\" data-toc-modified-id=\"18.-Submit-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>18. Submit</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:18.996636Z",
     "start_time": "2019-04-25T18:58:59.863406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctbst\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import tensorflow as tf\n",
    "KERAS_BACKEND=tf\n",
    "import keras as K\n",
    "#from keras import *\n",
    "#from keras.utils import *\n",
    "#from keras.models import *\n",
    "#from keras.callbacks import *\n",
    "#from keras.optimizers import *\n",
    "#from keras.layers import *\n",
    "#from keras.layers.core import *\n",
    "#from keras.layers.recurrent import *\n",
    "#from keras.layers.normalization import *\n",
    "#from keras.layers.advanced_activations import *\n",
    "#from keras import backend as K\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(20, 10))\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "from plotly.offline import *\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from pylab import *\n",
    "init_notebook_mode(connected=True)\n",
    "import shap\n",
    "from tqdm import *\n",
    "from IPython.display import *\n",
    "import missingno\n",
    "\n",
    "import threading as th\n",
    "import multiprocessing as mp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:19.000593Z",
     "start_time": "2019-04-25T18:59:18.997601Z"
    }
   },
   "outputs": [],
   "source": [
    "#cannot use seed cause python has function with the same name\n",
    "random_state = 1\n",
    "path = 'D:/Python/Kaggle/Santander/'\n",
    "n_threads = mp.cpu_count()-1 #th.active_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:19.031527Z",
     "start_time": "2019-04-25T18:59:19.001590Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_wide(f):\n",
    "    def wrapped():\n",
    "        rcParams['figure.figsize'] = 20, 10\n",
    "    return wrapped\n",
    "\n",
    "def data_convert(df, col_exc, do_print=True):\n",
    "    \n",
    "    columns = [column for column in df.columns if column not in [col_exc]]\n",
    "    \n",
    "    for column in columns:\n",
    "\n",
    "        if (df[column].dtype not in ['datetime64[ns]', 'object', 'float']):\n",
    "            \n",
    "            mn = df[column].min()\n",
    "            mx = df[column].max()\n",
    "            \n",
    "            #uint\n",
    "            if (mn >= 0):\n",
    "                \n",
    "                #uint8\n",
    "                if (mx < 255):\n",
    "                    try:\n",
    "                        column_type = str(df[column].dtype)\n",
    "                        df[column] = df[column].astype('uint8')\n",
    "                        if do_print:\n",
    "                            print(\n",
    "                                column,\n",
    "                                'with type',\n",
    "                                column_type,\n",
    "                                'converted to uint8'\n",
    "                            )\n",
    "                    except:\n",
    "                        print(sys.exc_info()[0])\n",
    "                \n",
    "                #uint16\n",
    "                elif (mx < 65535):\n",
    "                    try:\n",
    "                        column_type = str(df[column].dtype)\n",
    "                        df[column] = df[column].astype('uint16')\n",
    "                        if do_print:\n",
    "                            print(\n",
    "                                column,\n",
    "                                'with type',\n",
    "                                column_type,\n",
    "                                'converted to uint16'\n",
    "                            )\n",
    "                    except:\n",
    "                        print(sys.exc_info()[0])\n",
    "                        \n",
    "                #uint32\n",
    "                elif (mx < 4294967295):\n",
    "                    try:\n",
    "                        column_type = str(df[column].dtype)\n",
    "                        df[column] = df[column].astype('uint32')\n",
    "                        if do_print:\n",
    "                            print(\n",
    "                                column,\n",
    "                                'with type',\n",
    "                                column_type,\n",
    "                                'converted to uint32'\n",
    "                            )\n",
    "                    except:\n",
    "                        print(sys.exc_info()[0])\n",
    "                        \n",
    "                #uint64\n",
    "                elif (mx < 18446744073709551615):\n",
    "                    try:\n",
    "                        column_type = str(df[column].dtype)\n",
    "                        df[column] = df[column].astype('uint64')\n",
    "                        if do_print:\n",
    "                            print(\n",
    "                                column,\n",
    "                                'with type',\n",
    "                                column_type,\n",
    "                                'converted to uint64'\n",
    "                            )\n",
    "                    except:\n",
    "                        print(sys.exc_info()[0])\n",
    "            \n",
    "            #int8\n",
    "            elif ((-128 <= mn <= 127) & (-128 <= mx <= 127)):\n",
    "                try:\n",
    "                    column_type = str(df[column].dtype)\n",
    "                    df[column] = df[column].astype('int8')\n",
    "                    if do_print:\n",
    "                        print(\n",
    "                            column,\n",
    "                            'with type',\n",
    "                            column_type,\n",
    "                            'converted to int8'\n",
    "                        )\n",
    "                except:\n",
    "                    print(sys.exc_info()[0])\n",
    "                \n",
    "            #int16\n",
    "            elif ((-32768 <= mn <= 32767) & (-32768 <= mx <= 32767)):\n",
    "                try:\n",
    "                    column_type = str(df[column].dtype)\n",
    "                    df[column] = df[column].astype('int16')\n",
    "                    if do_print:\n",
    "                        print(\n",
    "                            column,\n",
    "                            'with type',\n",
    "                            column_type,\n",
    "                            'converted to int16'\n",
    "                        )\n",
    "                except:\n",
    "                    print(sys.exc_info()[0])\n",
    "                \n",
    "            #int32\n",
    "            elif ((-2147483648 <= mn <= 2147483647) & (-2147483648 <= mx <= 2147483647)):\n",
    "                try:\n",
    "                    column_type = str(df[column].dtype)\n",
    "                    df[column] = df[column].astype('int32')\n",
    "                    if do_print:\n",
    "                        print(\n",
    "                            column,\n",
    "                            'with type',\n",
    "                            column_type,\n",
    "                            'converted to int32'\n",
    "                        )\n",
    "                except:\n",
    "                    print(sys.exc_info()[0])\n",
    "        \n",
    "        elif (df[column].dtype == 'float'):\n",
    "            \n",
    "            try:\n",
    "                column_type = str(df[column].dtype)\n",
    "                df[column] = df[column].astype('float32')\n",
    "                if do_print:\n",
    "                    print(\n",
    "                        column,\n",
    "                        'with type',\n",
    "                        column_type,\n",
    "                        'converted to float32'\n",
    "                    )\n",
    "            except:\n",
    "                print(sys.exc_info()[0]) \n",
    "        \n",
    "        else:\n",
    "            if do_print:\n",
    "                print(\n",
    "                    column,\n",
    "                    'has no convertable type'\n",
    "                )\n",
    "                \n",
    "    return df\n",
    "            \n",
    "def data_desc(df):\n",
    "    \n",
    "    df_types = pd.DataFrame(df.dtypes.reset_index()).rename(columns={'index': 'column', 0: 'type'})\n",
    "    \n",
    "    for c in df_types['column'].values:\n",
    "        \n",
    "        null = 'EXIST' if df[c].isnull().any()==True else 'DOES NOT EXIST'\n",
    "        column_type = df_types[df_types['column']==c]['type'].values[0]\n",
    "        \n",
    "        print(\n",
    "            'NULL VALUES',\n",
    "            null,\n",
    "            'WITH FORMAT',\n",
    "            column_type,\n",
    "            'IN COLUMN',\n",
    "            c\n",
    "        )\n",
    "        \n",
    "    print(df.dtypes)\n",
    "    return df.describe().T\n",
    "\n",
    "#@plot_wide\n",
    "def simple_analysis(df, cat_feat=None, target=''):\n",
    "    \n",
    "    features = df.columns\n",
    "    dt = df.dtypes\n",
    "    \n",
    "    sns.heatmap(df.corr())\n",
    "    plt.show()\n",
    "    \n",
    "    columns = pd.DataFrame(df.dtypes).reset_index().rename(columns={'index': 'column', 0: 'type'})\n",
    "    dig_feat = columns[columns['type']!='object']['column'].values\n",
    "    \n",
    "    for d in dig_feat:\n",
    "        \n",
    "        sns.distplot(df[d])\n",
    "        plt.show()\n",
    "        \n",
    "    if cat_feat != None:\n",
    "        \n",
    "        for c in cat_feat:\n",
    "            \n",
    "            #sns.stripplot(\n",
    "            #    x=target,\n",
    "            #    y=c,\n",
    "            #    data=df,\n",
    "            #    jitter=True,\n",
    "            #    linewidth=1\n",
    "            #)\n",
    "            sns.boxplot(\n",
    "                x=c,\n",
    "                y=target,\n",
    "                data=df\n",
    "            )\n",
    "            plt.show()\n",
    "            \n",
    "def data_skew(df):\n",
    "    \n",
    "    sk_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                'column': c,\n",
    "                'uniq': df[c].nunique(),\n",
    "                'skewness': df[c].value_counts(normalize=True).values[0] * 100\n",
    "            } for c in df.columns\n",
    "        ]\n",
    "    )\n",
    "    sk_df = sk_df.sort_values('skewness', ascending=False)\n",
    "    return sk_df\n",
    "            \n",
    "def plot_feat_imp(feat, imp, n_feat):\n",
    "    \n",
    "    feat = feat[:n_feat]\n",
    "    df_temp = pd.DataFrame(feat, columns=['feature'])\n",
    "    df_temp['imp'] = imp[:n_feat]\n",
    "    df_temp.sort_values(\n",
    "        by=['imp'],\n",
    "        ascending=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    n_feat = len(feat)\n",
    "    \n",
    "    plt.barh(\n",
    "        range(n_feat),\n",
    "        df_temp['imp'],\n",
    "        align='center'\n",
    "    )\n",
    "    \n",
    "    plt.yticks(np.arange(n_feat), df_temp['feature'])\n",
    "    plt.xlabel(xlabel('Importance'))\n",
    "    plt.ylabel('Feature')\n",
    "    del df_temp; gc.collect()\n",
    "    \n",
    "def plot_vc(x, y_train, y_valid, xlabel='DEPTH'):\n",
    "    '''\n",
    "    plt.title('Validation curve')\n",
    "    plt.xlabel('depth')\n",
    "    plt.ylabel('roc_auc')\n",
    "    sns.lineplot(\n",
    "        x=x,\n",
    "        y=y_train,\n",
    "        label='Train'\n",
    "    )\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=x,\n",
    "        y=y_valid,\n",
    "        label='Valid'\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    '''\n",
    "    train = Scatter(\n",
    "        x=x,\n",
    "        y=y_train,\n",
    "        name='Train',\n",
    "        line=dict(\n",
    "            color='rgba(240, 65, 65, .9)',\n",
    "            shape='hvh'\n",
    "        ),\n",
    "        mode='lines+markers',\n",
    "        connectgaps=True\n",
    "    )\n",
    "    \n",
    "    valid = Scatter(\n",
    "        x=x,\n",
    "        y=y_valid,\n",
    "        name='Valid',\n",
    "        line=dict(\n",
    "            color='rgba(65, 100, 240, .9)',\n",
    "            shape='hvh'\n",
    "        ),\n",
    "        mode='lines+markers',\n",
    "        connectgaps=True\n",
    "    )\n",
    "    \n",
    "    data = [train, valid]\n",
    "    \n",
    "    layout = dict(\n",
    "        title='Validation curve',\n",
    "        legend=dict(\n",
    "            x=.9,\n",
    "            y=1\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title='ROC AUC',\n",
    "            autorange=False,\n",
    "            range=[0, 1.1],\n",
    "            #tickformat='0.0%'\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            title=xlabel,\n",
    "            dtick=1\n",
    "        ),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig = dict(\n",
    "        data=data,\n",
    "        layout=layout\n",
    "    )\n",
    "    \n",
    "    iplot(fig)\n",
    "            \n",
    "def model_mean(**kwargs):\n",
    "    \n",
    "    X_train = kwargs['X_train']\n",
    "    X_valid = kwargs['X_valid']\n",
    "    X_test = kwargs['X_test']\n",
    "    y_train = kwargs['y_train']\n",
    "    y_valid = kwargs['y_valid']\n",
    "    y_test = kwargs['y_test']\n",
    "    feat = kwargs['feat']\n",
    "\n",
    "    if 'cat_feat' in kwargs.keys():\n",
    "        cat_feat = kwargs['cat_feat']\n",
    "\n",
    "    model = kwargs['model']\n",
    "    random_state = kwargs['random_state']\n",
    "    samples = kwargs['samples']\n",
    "    info = kwargs['info']\n",
    "    y_valid_preds = []\n",
    "    y_test_preds = []\n",
    "    \n",
    "    for i in range(0, samples):\n",
    "        \n",
    "        if 'cat_feat' in kwargs.keys():\n",
    "            \n",
    "            y_valid_pred_, y_test_pred_ = model(\n",
    "                X_train,\n",
    "                X_valid,\n",
    "                X_test,\n",
    "                y_train,\n",
    "                y_valid,\n",
    "                y_test,\n",
    "                feat,\n",
    "                cat_feat,\n",
    "                random_state+i\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            y_valid_pred_, y_test_pred_ = model(\n",
    "                X_train,\n",
    "                X_valid,\n",
    "                X_test,\n",
    "                y_train,\n",
    "                y_valid,\n",
    "                y_test,\n",
    "                feat,\n",
    "                random_state+1\n",
    "            )\n",
    "\n",
    "        y_valid_preds.append(y_valid_pred_)\n",
    "        y_test_preds.append(y_test_pred_)\n",
    "    \n",
    "    y_valid_pred = np.mean(y_valid_preds, axis=0)\n",
    "    y_test_pred = np.mean(y_test_preds, axis=0)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        print(\n",
    "            samples,\n",
    "            info,\n",
    "            'MODELS',\n",
    "            '\\nROC_AUC train score:',\n",
    "            roc_auc_score(y_valid, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        'CANNOT CALC METRIC'\n",
    "    \n",
    "    print(\n",
    "        samples,\n",
    "        info,\n",
    "        'MODELS',\n",
    "        '\\nROC_AUC test score:',\n",
    "        roc_auc_score(y_test, y_test_pred)\n",
    "    )\n",
    "   \n",
    "    return y_valid_pred, y_test_pred\n",
    "\n",
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "\n",
    "def eval_auc(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'auc', fast_auc(labels, preds), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "X_train = pd.read_csv(path + 'train.csv', sep=',')\n",
    "\n",
    "X_train = data_convert(\n",
    "    df=X_train,\n",
    "    col_exc='target'\n",
    ")\n",
    "\n",
    "X_test = pd.read_csv(path + 'test.csv', sep=',')\n",
    "\n",
    "X_test = data_convert(\n",
    "    df=X_test,\n",
    "    col_exc=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "print(X_train.info())\n",
    "simple_analysis(\n",
    "    df=X_train.drop(labels=['ID_code'], axis=1),\n",
    "    cat_feat=None,\n",
    "    target='target'\n",
    ")\n",
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "print(X_test.info())\n",
    "simple_analysis(\n",
    "    df=X_test,\n",
    "    cat_feat=None,\n",
    "    target='target'\n",
    ")\n",
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([X_train.drop(labels=['ID_code', 'target'], axis=1), X_test.drop(labels=['ID_code'], axis=1)], axis=0)\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Clear and analyse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Get skewed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "data_skew(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Get highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(X_train.drop(labels=['ID_code'], axis=1).columns)\n",
    "\n",
    "try:\n",
    "    cols.remove('target')\n",
    "except:\n",
    "    print('Target is not there')\n",
    "finally:\n",
    "    cols.append('target')\n",
    "\n",
    "df_corr = X_train[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 10\n",
    "\n",
    "for i in tqdm_notebook(range(len(X_train.columns)-step)):\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    cols = list(X_train.columns[i:i+step])\n",
    "    try:\n",
    "        cols.remove('target')\n",
    "    except:\n",
    "        print('Target is not there')\n",
    "    finally:\n",
    "        cols.append('target')\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=X_train[cols].corr(),\n",
    "        cmap='RdBu_r',\n",
    "        annot=True,\n",
    "        center=0.0\n",
    "    )\n",
    "    plt.title('Correlation between columns ' + str(i) + '-' + str(i+step))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Analyse missing values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(X_train.drop(labels=['ID_code', 'target'], axis=1).columns)\n",
    "\n",
    "l = len(cols)\n",
    "inc = 0\n",
    "\n",
    "for i in range(0, l, 50):\n",
    "    \n",
    "    if i==0:\n",
    "        missingno.bar(df_full[cols[:i+50]])\n",
    "    else:\n",
    "        missingno.bar(df_full[cols[i:i+50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = X_test.copy()\n",
    "df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "del df_test; gc.collect()\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.677233Z",
     "start_time": "2019-04-25T18:59:19.032524Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "X_train = pd.read_csv(path + 'train.csv')\n",
    "X_train = data_convert(\n",
    "    df=X_train,\n",
    "    col_exc=''\n",
    ")\n",
    "\n",
    "X_test = pd.read_csv(path + 'test.csv')\n",
    "X_test = data_convert(\n",
    "    df=X_test,\n",
    "    col_exc=''\n",
    ")\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "feat = list(X_train.drop(labels=['ID_code', 'target'], axis=1).columns)\n",
    "print(len(feat))\n",
    "cat_feat = []\n",
    "\n",
    "y_train = X_train[target]\n",
    "y_test_fake = np.ones(X_test.shape[0])\n",
    "#for roc auc score\n",
    "y_test_fake[0] = 0\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_train[feat],\n",
    "    y_train,\n",
    "    test_size=.25,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "#balance = y_train_r[y_train_r==0].shape[0]/y_train_r[y_train_r==1].shape[0]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.719105Z",
     "start_time": "2019-04-25T18:59:57.678221Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.head(1000)\n",
    "X_test = X_test.head(1000)\n",
    "y_train = y_train.head(1000)\n",
    "y_test_fake = y_test_fake[:1000]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_train[feat],\n",
    "    y_train,\n",
    "    test_size=.25,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T19:23:34.711354Z",
     "start_time": "2019-04-22T19:23:34.702378Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=250,\n",
    "    criterion='gini',\n",
    "    max_depth=5, #using pruned trees as gihub documentation said\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=n_threads,\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "feat_sel = BorutaPy(\n",
    "    estimator=model,\n",
    "    n_estimators=1000,\n",
    "    perc=100,\n",
    "    alpha=0.05,\n",
    "    two_step=True,\n",
    "    max_iter=100,\n",
    "    random_state=random_state,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "feat_sel.fit(\n",
    "    X=X_train[feat].replace([np.NAN, np.inf, np.NINF], [0, 0, 0]).values,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "#print('\\n Initial features: ', feat_common + feat_hor + feat_ver )\n",
    "\n",
    "print('\\n Number of selected features:')\n",
    "print(feat_sel.n_features_)\n",
    "\n",
    "feat_df = pd.DataFrame(feat, columns=['feat'])\n",
    "feat_df['rank']=feat_sel.ranking_\n",
    "feat_df = feat_df.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "print ('\\n Top %d features:' % feat_sel.n_features_)\n",
    "print (feat_df.head(feat_sel.n_features_))\n",
    "\n",
    "#print ('\\n Feature ranking:')\n",
    "#print (feat_sel.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Finding the best depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:06:02.821341Z",
     "start_time": "2019-04-24T18:05:52.074807Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "depths = range(1, 100, 10)\n",
    "\n",
    "for d in tqdm_notebook(depths):\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=250,\n",
    "        criterion='gini',\n",
    "        max_depth=d,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_features='auto',\n",
    "        max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None,\n",
    "        bootstrap=True,\n",
    "        oob_score=False,\n",
    "        n_jobs=n_threads,\n",
    "        random_state=random_state,\n",
    "        verbose=0,\n",
    "        warm_start=False,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "        y=y_train_r,\n",
    "        sample_weight=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict_proba(\n",
    "        X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    )\n",
    "    \n",
    "    y_pred_train = y_pred_train[:, 1]\n",
    "    \n",
    "    y_pred_test = model.predict_proba(\n",
    "        X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    )\n",
    "    \n",
    "    y_pred_test = y_pred_test[:, 1]\n",
    "    \n",
    "    train_results.append(roc_auc_score(y_train_r, y_pred_train))\n",
    "    valid_results.append(roc_auc_score(y_test_r, y_pred_test))\n",
    "    \n",
    "plot_vc(\n",
    "    x=[d for d in depths],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='DEPTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:30:02.466451Z",
     "start_time": "2019-04-24T20:30:02.380337Z"
    }
   },
   "source": [
    "## 9.2 Model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    criterion='gini',\n",
    "    max_depth=6,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=n_threads,\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X=X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    y=y_train_r,\n",
    "    sample_weight=None\n",
    ")\n",
    "\n",
    "y_pred = model.predict_proba(\n",
    "    X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC score:',\n",
    "    roc_auc_score(y_test_r, y_pred),\n",
    ")\n",
    "\n",
    "plot_feat_imp(\n",
    "    feat=feat,\n",
    "    imp=model.feature_importances_,\n",
    "    n_feat=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Finding the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    criterion='gini',\n",
    "    max_depth=6,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=n_threads,\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=6, stop=6, num=1)],\n",
    "    'min_samples_split': [int(x) for x in np.linspace(start=2, stop=64, num=10)],\n",
    "    'min_samples_leaf': [int(x) for x in np.linspace(start=10, stop=300, num=10)],\n",
    "    'min_weight_fraction_leaf': [float(x) for x in np.linspace(start=0., stop=.5, num=5)],\n",
    "    'max_features': [float(x) for x in np.linspace(start=.1, stop=.9, num=5)],\n",
    "    'max_leaf_nodes': [int(x) for x in np.linspace(start=10, stop=300, num=10)] + [None],\n",
    "    #'min_impurity_descrease': [0.0],\n",
    "    #'min_impurity_split': [None],\n",
    "    'bootstrap': [False, True],\n",
    "    #'oob_score': [False, True],\n",
    "    #'warm_start': [False, True]\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='neg_log_loss',\n",
    "    cv=3,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    y=y_train_r\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC score:',\n",
    "    roc_auc_score(y_test_r, y_pred),\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.727084Z",
     "start_time": "2019-04-25T18:59:57.720102Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_RFC(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, random_state):\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        criterion='gini',\n",
    "        max_depth=6,\n",
    "        min_samples_split=15,\n",
    "        min_samples_leaf=10,\n",
    "        min_weight_fraction_leaf=.125,\n",
    "        max_features=.5,\n",
    "        max_leaf_nodes=74,\n",
    "        min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None,\n",
    "        bootstrap=False,\n",
    "        oob_score=False,\n",
    "        n_jobs=n_threads,\n",
    "        random_state=random_state,\n",
    "        verbose=0,\n",
    "        warm_start=False,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X=X_train[feat],\n",
    "        y=y_train,\n",
    "        sample_weight=None\n",
    "    )\n",
    "\n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict_proba(\n",
    "            X_valid[feat]\n",
    "        )\n",
    "\n",
    "        y_valid_pred = y_valid_pred[:, 1]\n",
    "\n",
    "        print(\n",
    "            'MODEL RFC',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(y_valid, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict_proba(\n",
    "        X_test[feat]\n",
    "    )\n",
    "\n",
    "    y_test_pred = y_test_pred[:, 1]\n",
    "\n",
    "    print(\n",
    "        'MODEL RFC',\n",
    "        '\\nROC AUC test score:',\n",
    "        roc_auc_score(y_test, y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. ExtraTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Finding the best depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "depths = range(1, 100, 10)\n",
    "\n",
    "for d in tqdm_notebook(depths):\n",
    "\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=250,\n",
    "        criterion='gini',\n",
    "        max_depth=d,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_features='auto',\n",
    "        max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None,\n",
    "        bootstrap=True,\n",
    "        oob_score=False,\n",
    "        n_jobs=n_threads,\n",
    "        random_state=random_state,\n",
    "        verbose=0,\n",
    "        warm_start=False,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "        y_train_r,\n",
    "        sample_weight=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict_proba(\n",
    "        X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    )\n",
    "    \n",
    "    y_pred_train = y_pred_train[:, 1]\n",
    "    \n",
    "    y_pred_test = model.predict_proba(\n",
    "        X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    )\n",
    "    \n",
    "    y_pred_test = y_pred_test[:, 1]\n",
    "    \n",
    "    train_results.append(roc_auc_score(y_train_r, y_pred_train))\n",
    "    valid_results.append(roc_auc_score(y_test_r, y_pred_test))\n",
    "    \n",
    "plot_vc(\n",
    "    x=[d for d in depths],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='DEPTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=250,\n",
    "    criterion='gini',\n",
    "    max_depth=6,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=n_threads,\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X=X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    y=y_train_r,\n",
    "    sample_weight=None\n",
    ")\n",
    "\n",
    "y_pred = model.predict_proba(\n",
    "    X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC score:',\n",
    "    roc_auc_score(y_test_r, y_pred),\n",
    ")\n",
    "\n",
    "plot_feat_imp(\n",
    "    feat=feat,\n",
    "    imp=model.feature_importances_,\n",
    "    n_feat=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Finding the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T20:35:07.675733Z",
     "start_time": "2019-04-19T20:35:03.283262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=250,\n",
    "    criterion='gini',\n",
    "    max_depth=6,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=n_threads,\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=6, stop=6, num=1)],\n",
    "    'min_samples_split': [int(x) for x in np.linspace(start=2, stop=64, num=10)],\n",
    "    'min_samples_leaf': [int(x) for x in np.linspace(start=10, stop=300, num=10)],\n",
    "    'min_weight_fraction_leaf': [float(x) for x in np.linspace(start=0., stop=.5, num=5)],\n",
    "    'max_features': [float(x) for x in np.linspace(start=.1, stop=.9, num=5)],\n",
    "    'max_leaf_nodes': [int(x) for x in np.linspace(start=10, stop=300, num=10)] + [None],\n",
    "    #'min_impurity_descrease': [0.0],\n",
    "    #'min_impurity_split': [None],\n",
    "    'bootstrap': [False, True],\n",
    "    #'oob_score': [False, True],\n",
    "    #'warm_start': [False, True]\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='neg_log_loss',\n",
    "    cv=3,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=X_train_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    "    y=y_train_r\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    X_test_r.replace([np.NAN, np.inf, np.NINF], [0, 0, 0]),\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC score:',\n",
    "    roc_auc_score(y_test_r, y_pred),\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:08.668156Z",
     "start_time": "2019-04-25T19:01:08.661175Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_ETC(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, random_state):\n",
    "    \n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=10,\n",
    "        criterion='gini',\n",
    "        max_depth=6,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=42,\n",
    "        min_weight_fraction_leaf=.25,\n",
    "        max_features=.7,\n",
    "        max_leaf_nodes=300,\n",
    "        min_impurity_decrease=0.,\n",
    "        min_impurity_split=None,\n",
    "        bootstrap=False,\n",
    "        oob_score=False,\n",
    "        n_jobs=n_threads,\n",
    "        random_state=random_state,\n",
    "        verbose=0,\n",
    "        warm_start=False,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X=X_train[feat],\n",
    "        y=y_train,\n",
    "        sample_weight=None\n",
    "    )\n",
    "    \n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict_proba(\n",
    "            X_valid[feat]\n",
    "        )\n",
    "\n",
    "        y_valid_pred = y_valid_pred[:, 1]\n",
    "\n",
    "        print(\n",
    "            'MODEL ETC',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(y_valid, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict_proba(\n",
    "        X_test[feat]\n",
    "    )\n",
    "\n",
    "    y_test_pred = y_test_pred[:, 1]\n",
    "\n",
    "    print(\n",
    "        'MODEL ETC',\n",
    "        '\\nROC AUC test score:',\n",
    "        roc_auc_score(y_test, y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.0 XGBoost datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T20:52:29.138632Z",
     "start_time": "2019-04-19T20:52:29.109710Z"
    }
   },
   "outputs": [],
   "source": [
    "#you should skip categorical_feature setting in dataset and set in train if you gonna use gpu\n",
    "\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(\n",
    "    X_train[feat],\n",
    "    y_train,\n",
    "    test_size=.1,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "X_test_xgb = X_test_xgb[feat]\n",
    "\n",
    "X_train_xgb, X_eval_xgb, y_train_xgb, y_eval_xgb = train_test_split(\n",
    "    X_train_xgb,\n",
    "    y_train_xgb,\n",
    "    test_size=.25,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train_xgb\n",
    ")\n",
    "\n",
    "train_xgb_full = xgb.DMatrix(\n",
    "    data=X_train[feat],\n",
    "    label=y_train,\n",
    "    missing=None,\n",
    "    weight=None,\n",
    "    silent=False,\n",
    "    feature_names=feat,\n",
    "    #feature_types=X_train[feat].dtypes,\n",
    "    nthread=n_threads\n",
    ")\n",
    "\n",
    "train_xgb = xgb.DMatrix(\n",
    "    data=X_train_xgb,\n",
    "    label=y_train_xgb,\n",
    "    missing=None,\n",
    "    weight=None,\n",
    "    silent=False,\n",
    "    feature_names=feat,\n",
    "    #feature_types=X_train_xgb[feat].dtypes,\n",
    "    nthread=n_threads\n",
    ")\n",
    "\n",
    "eval_xgb = xgb.DMatrix(\n",
    "    data=X_eval_xgb,\n",
    "    label=y_eval_xgb,\n",
    "    missing=None,\n",
    "    weight=None,\n",
    "    silent=False,\n",
    "    feature_names=feat,\n",
    "    #feature_types=X_valid_xgb[feat].dtypes,\n",
    "    nthread=n_threads\n",
    ")\n",
    "\n",
    "test_xgb = xgb.DMatrix(\n",
    "    data=X_test_xgb,\n",
    "    label=y_test_xgb,\n",
    "    missing=None,\n",
    "    weight=None,\n",
    "    silent=False,\n",
    "    feature_names=feat,\n",
    "    #feature_types=X_test_xgb[feat].dtypes,\n",
    "    nthread=n_threads\n",
    ")\n",
    "\n",
    "balance = y_train_xgb[y_train_xgb==0].shape[0]/y_train_xgb[y_train_xgb==1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Finding the best depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:51:17.789269Z",
     "start_time": "2019-04-19T16:51:16.695195Z"
    }
   },
   "outputs": [],
   "source": [
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "depths = range(1, 17, 2)\n",
    "\n",
    "for d in tqdm_notebook(depths):\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=d,\n",
    "        #eta\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=10000,\n",
    "        verbosity=1,\n",
    "        silent=None,\n",
    "        objective='binary:logistic',\n",
    "        booster='gbtree',\n",
    "        #nthread\n",
    "        n_jobs=n_threads,\n",
    "        gamma=0,\n",
    "        min_child_weight=1,\n",
    "        max_delta_step=0,\n",
    "        subsample=.75,\n",
    "        colsample_bytree=.75,\n",
    "        colsample_bylevel=.75,\n",
    "        colsample_bynode=.75,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1,\n",
    "        scale_pos_weight=balance,\n",
    "        base_score=0.5,\n",
    "        #random_state\n",
    "        seed=random_state,\n",
    "        missing=None,\n",
    "        #**kwargs\n",
    "        #booster='gbtree', #default\n",
    "        #silent=0, #default\n",
    "        #verbosity=1, #default\n",
    "        #nthread=n_threads,\n",
    "        disable_default_eval_metric=0, #default\n",
    "        #num_pbuffer=?, #set automatically by XGBoost, no need to be set by user\n",
    "        #num_feature=?, #set automatically by XGBoost, no need to be set by user\n",
    "    #Parameters for Tree Booster (booster=gbtree)\n",
    "        #learning_rate\n",
    "        #eta=.1,\n",
    "        #min_split_loss\n",
    "        #gamma=0,\n",
    "        #max_depth=6, #default\n",
    "        #min_child_weight=1, #default #The larger min_child_weight is, the more conservative the algorithm will be.\n",
    "        #max_delta_step=0, #default #Set it to value of 1-10 might help control the update.\n",
    "        #subsample=.75,\n",
    "        #colsample_bytree=.75,\n",
    "        #colsample_bylevel=.75,\n",
    "        #colsample_bynode=.75,\n",
    "        ##reg_lambda l2\n",
    "        #lambda=1, #default\n",
    "        ##reg_alpha l1\n",
    "        #alpha=0, #default\n",
    "        tree_method='hist', #gpu_hist\n",
    "        #sketch_eps=.03, #Only used for tree_method=approx.\n",
    "        #scale_pos_weight=balance, #default\n",
    "        #updater='grow_histmaker', #default\n",
    "        refresh_leaf=1, #default\n",
    "        process_type='default', #default\n",
    "        grow_policy='depthwise', #default\n",
    "        #max_leaves=0, #Only relevant when grow_policy=lossguide is set.\n",
    "        max_bin=256, #default\n",
    "        predictor='cpu_predictor', #gpu_predictor\n",
    "        num_parallel_tree=1, #default\n",
    "    #Additional parameters for Dart Booster (booster=dart)\n",
    "        #sample_type='uniform', #default\n",
    "        #normalize_type='tree', #default\n",
    "        #rate_drop=0.0, #default\n",
    "        #one_dorp=0, #default\n",
    "        #skip_drop=0.0, #default\n",
    "    #Parameters for Linear Booster (booster=gblinear)\n",
    "        ##reg_lambda l2\n",
    "        #lambda=1, #default\n",
    "        ##reg_alpha l1\n",
    "        #alpha=0, #default\n",
    "        #updater='shotgun', #default\n",
    "        #feature_selector='cyclic', #default\n",
    "        #top_k=0, #default\n",
    "    #Parameters for Tweedie Regression (objective=reg:tweedie)\n",
    "        #tweedie_variance_power=1.5, #default\n",
    "    #Learning Task Parameters\n",
    "        #objective='binary:logistic',\n",
    "        #base_score=.5, #default\n",
    "        #eval_metric='auc',\n",
    "        #seed=random_state\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=X_train_xgb,\n",
    "        y=y_train_xgb,\n",
    "        sample_weight=None,\n",
    "        eval_set=[(X_train_xgb, y_train_xgb), (X_eval_xgb, y_eval_xgb)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=3000,\n",
    "        verbose=False,\n",
    "        xgb_model=None,\n",
    "        sample_weight_eval_set=None,\n",
    "        callbacks=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict_proba(\n",
    "        data=X_train_xgb,\n",
    "        ntree_limit=None,\n",
    "        validate_features=True\n",
    "    )\n",
    "\n",
    "    y_pred_train = y_pred_train[:, 1]\n",
    "    \n",
    "    y_pred_test = model.predict_proba(\n",
    "        data=X_test_xgb,\n",
    "        ntree_limit=model.best_ntree_limit,\n",
    "        validate_features=True\n",
    "    )\n",
    "    \n",
    "    y_pred_test = y_pred_test[:, 1]\n",
    "    \n",
    "    train_results.append(roc_auc_score(y_train_xgb, y_pred_train))\n",
    "    valid_results.append(roc_auc_score(y_test_xgb, y_pred_test))\n",
    "\n",
    "plot_vc(\n",
    "    x=[d for d in depths],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='DEPTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:13:42.031482Z",
     "start_time": "2019-04-19T17:13:27.557137Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#callback\n",
    "\n",
    "params = {\n",
    "#General Parameters\n",
    "    'booster': 'gbtree', #default\n",
    "    'silent': 0, #default\n",
    "    'verbosity': 1, #default\n",
    "    'nthread': n_threads,\n",
    "    'disable_default_eval_metric': 0, #default\n",
    "    #'num_pbuffer': ?, #set automatically by XGBoost, no need to be set by user\n",
    "    #'num_feature': ?, #set automatically by XGBoost, no need to be set by user\n",
    "#Parameters for Tree Booster (booster=gbtree)\n",
    "    #learning_rate\n",
    "    'eta': .1,\n",
    "    #min_split_loss\n",
    "    'gamma': 0,\n",
    "    'max_depth': 6, #default\n",
    "    'min_child_weight': 1, #default #The larger min_child_weight is, the more conservative the algorithm will be.\n",
    "    'max_delta_step': 0, #default #Set it to value of 1-10 might help control the update.\n",
    "    'subsample': .75,\n",
    "    'colsample_bytree': .75,\n",
    "    'colsample_bylevel': .75,\n",
    "    'colsample_bynode': .75,\n",
    "    #reg_lambda l2\n",
    "    'lambda': 1, #default\n",
    "    #reg_alpha l1\n",
    "    'alpha': 0, #default\n",
    "    'tree_method': 'hist', #gpu_hist\n",
    "    #'sketch_eps': .03, #Only used for tree_method=approx.\n",
    "    'scale_pos_weight': balance, #default\n",
    "    #'updater': 'grow_histmaker', #default\n",
    "    'refresh_leaf': 1, #default\n",
    "    'process_type': 'default', #default\n",
    "    'grow_policy': 'depthwise', #default\n",
    "    #'max_leaves': 0, #Only relevant when grow_policy=lossguide is set.\n",
    "    'max_bin': 256, #default\n",
    "    'predictor': 'cpu_predictor', #gpu_predictor\n",
    "    'num_parallel_tree': 1, #default\n",
    "#Additional parameters for Dart Booster (booster=dart)\n",
    "    #'sample_type': 'uniform', #default\n",
    "    #'normalize_type': 'tree', #default\n",
    "    #'rate_drop': 0.0, #default\n",
    "    #'one_dorp': 0, #default\n",
    "    #'skip_drop': 0.0, #default\n",
    "#Parameters for Linear Booster (booster=gblinear)\n",
    "    ##reg_lambda l2\n",
    "    #'lambda': 1, #default\n",
    "    ##reg_alpha l1\n",
    "    #'alpha': 0, #default\n",
    "    #'updater': 'shotgun', #default\n",
    "    #'feature_selector': 'cyclic', #default\n",
    "    #'top_k': 0, #default\n",
    "#Parameters for Tweedie Regression (objective=reg:tweedie)\n",
    "    #'tweedie_variance_power': 1.5, #default\n",
    "#Learning Task Parameters\n",
    "    'objective': 'reg:logistic',\n",
    "    'base_score': .5, #default\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': random_state\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train_xgb,\n",
    "    num_boost_round=10000,\n",
    "    evals=[(train_xgb, 'train'), (eval_xgb, 'eval')],\n",
    "    obj=None,\n",
    "    feval=None,\n",
    "    maximize=False,\n",
    "    early_stopping_rounds=3000,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=1000,\n",
    "    xgb_model=None,\n",
    "    callbacks=None,\n",
    "    learning_rates=None\n",
    ")\n",
    "\n",
    "y_pred = model.predict(\n",
    "    data=test_xgb,\n",
    "    output_margin=False,\n",
    "    ntree_limit=model.best_ntree_limit,\n",
    "    pred_leaf=False,\n",
    "    pred_contribs=False,\n",
    "    approx_contribs=False,\n",
    "    pred_interactions=False,\n",
    "    validate_features=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'BEST MODEL ITERATION:',\n",
    "    model.best_iteration\n",
    ")\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_xgb.get_label(), y_pred)\n",
    ")\n",
    "\n",
    "xgb.plot_importance(\n",
    "    booster=model,\n",
    "    ax=None,\n",
    "    height=0.2,\n",
    "    xlim=None,\n",
    "    ylim=None,\n",
    "    title='Feature importance',\n",
    "    xlabel='F score',\n",
    "    ylabel='Features',\n",
    "    importance_type='weight',\n",
    "    max_num_features=None,\n",
    "    grid=True,\n",
    "    show_values=True,\n",
    "    #**kwargs\n",
    ")\n",
    "\n",
    "xgb.plot_tree(\n",
    "    booster=model,\n",
    "    fmap='',\n",
    "    num_trees=model.best_ntree_limit,\n",
    "    rankdir='UT',\n",
    "    ax=None,\n",
    "    #**kwargs\n",
    ")\n",
    "\n",
    "model.save_model(\n",
    "    'xgboost_model.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:52:01.593629Z",
     "start_time": "2019-04-19T16:52:01.532792Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb.to_graphviz(\n",
    "    booster=model,\n",
    "    fmap='',\n",
    "    num_trees=model.best_ntree_limit,\n",
    "    rankdir='UT',\n",
    "    yes_color='#0000FF',\n",
    "    no_color='#FF0000',\n",
    "    condition_node_params=None,\n",
    "    leaf_node_params=None,\n",
    "    #**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:27:24.121154Z",
     "start_time": "2019-04-18T20:27:23.468116Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=train_xgb_full,\n",
    "    num_boost_round=10,\n",
    "    nfold=3,\n",
    "    stratified=True,\n",
    "    folds=None,\n",
    "    metrics=('auc'),\n",
    "    obj=None,\n",
    "    feval=None,\n",
    "    maximize=False,\n",
    "    early_stopping_rounds=3000,\n",
    "    fpreproc=None,\n",
    "    as_pandas=True,\n",
    "    verbose_eval=1000,\n",
    "    show_stdv=True,\n",
    "    seed=random_state,\n",
    "    callbacks=None,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Finding the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:12:58.465390Z",
     "start_time": "2019-04-19T17:12:56.251670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    #eta\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=10000,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    #nthread\n",
    "    n_jobs=n_threads,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=.75,\n",
    "    colsample_bytree=.75,\n",
    "    colsample_bylevel=.75,\n",
    "    colsample_bynode=.75,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=balance,\n",
    "    base_score=0.5,\n",
    "    #random_state\n",
    "    seed=random_state,\n",
    "    missing=None,\n",
    "    #**kwargs\n",
    "    #booster='gbtree', #default\n",
    "    #silent=0, #default\n",
    "    #verbosity=1, #default\n",
    "    #nthread=n_threads,\n",
    "    disable_default_eval_metric=0, #default\n",
    "    #num_pbuffer=?, #set automatically by XGBoost, no need to be set by user\n",
    "    #num_feature=?, #set automatically by XGBoost, no need to be set by user\n",
    "#Parameters for Tree Booster (booster=gbtree)\n",
    "    #learning_rate\n",
    "    #eta=.1,\n",
    "    #min_split_loss\n",
    "    #gamma=0,\n",
    "    #max_depth=6, #default\n",
    "    #min_child_weight=1, #default #The larger min_child_weight is, the more conservative the algorithm will be.\n",
    "    #max_delta_step=0, #default #Set it to value of 1-10 might help control the update.\n",
    "    #subsample=.75,\n",
    "    #colsample_bytree=.75,\n",
    "    #colsample_bylevel=.75,\n",
    "    #colsample_bynode=.75,\n",
    "    ##reg_lambda l2\n",
    "    #lambda=1, #default\n",
    "    ##reg_alpha l1\n",
    "    #alpha=0, #default\n",
    "    tree_method='hist', #gpu_hist\n",
    "    #sketch_eps=.03, #Only used for tree_method=approx.\n",
    "    #scale_pos_weight=balance, #default\n",
    "    #updater='grow_histmaker', #default\n",
    "    refresh_leaf=1, #default\n",
    "    process_type='default', #default\n",
    "    grow_policy='depthwise', #default\n",
    "    #max_leaves=0, #Only relevant when grow_policy=lossguide is set.\n",
    "    max_bin=256, #default\n",
    "    predictor='cpu_predictor', #gpu_predictor\n",
    "    num_parallel_tree=1, #default\n",
    "#Additional parameters for Dart Booster (booster=dart)\n",
    "    #sample_type='uniform', #default\n",
    "    #normalize_type='tree', #default\n",
    "    #rate_drop=0.0, #default\n",
    "    #one_dorp=0, #default\n",
    "    #skip_drop=0.0, #default\n",
    "#Parameters for Linear Booster (booster=gblinear)\n",
    "    ##reg_lambda l2\n",
    "    #lambda=1, #default\n",
    "    ##reg_alpha l1\n",
    "    #alpha=0, #default\n",
    "    #updater='shotgun', #default\n",
    "    #feature_selector='cyclic', #default\n",
    "    #top_k=0, #default\n",
    "#Parameters for Tweedie Regression (objective=reg:tweedie)\n",
    "    #tweedie_variance_power=1.5, #default\n",
    "#Learning Task Parameters\n",
    "    #objective='binary:logistic',\n",
    "    #base_score=.5, #default\n",
    "    #eval_metric='auc',\n",
    "    #seed=random_state\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'booster': ['gbtree'],\n",
    "    'learning_rate': [float(x) for x in np.linspace(start=.1, stop=.1, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=10000, stop=10000, num=1)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=19, stop=19, num=1)],\n",
    "    'gamma': [int(x) for x in np.linspace(start=10, stop=100, num=5)],\n",
    "    'min_child_weight': [int(x) for x in np.linspace(start=10, stop=100, num=5)],\n",
    "    'max_delta_step': [int(x) for x in np.linspace(start=10, stop=100, num=5)],\n",
    "    'subsample': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    'colsample_bytree': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    'colsample_bylevel': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    'colsample_bynode': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    'max_bin': [int(x) for x in np.linspace(start=3, stop=255, num=5)], #it will crash your python.exe if you start from 2\n",
    "    'reg_alpha': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "    'reg_lambda': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=X_train_xgb,\n",
    "    y=y_train_xgb,\n",
    "    sample_weight=None,\n",
    "    eval_set=[(X_train_xgb, y_train_xgb), (X_eval_xgb, y_eval_xgb)],\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=3000,\n",
    "    verbose=False,\n",
    "    xgb_model=None,\n",
    "    sample_weight_eval_set=None,\n",
    "    callbacks=None\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    data=X_test_xgb,\n",
    "    ntree_limit=train_grid.best_estimator_.best_ntree_limit,\n",
    "    validate_features=True\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(y_test_xgb, y_pred)\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.743041Z",
     "start_time": "2019-04-25T18:59:57.728082Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_XGBST_C_TREES(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, cat_feat, random_state):\n",
    "    \n",
    "    X_train_xgb, X_valid_xgb, y_train_xgb, y_valid_xgb = train_test_split(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        test_size=.25,\n",
    "        random_state=random_state,\n",
    "        stratify=y_train\n",
    "    )\n",
    "    \n",
    "    train_xgb = xgb.DMatrix(\n",
    "        data=X_train_xgb,\n",
    "        label=y_train_xgb,\n",
    "        missing=None,\n",
    "        weight=None,\n",
    "        silent=False,\n",
    "        feature_names=feat,\n",
    "        #feature_types=X_train_xgb[feat].dtypes,\n",
    "        nthread=n_threads\n",
    "    )\n",
    "\n",
    "    eval_xgb = xgb.DMatrix(\n",
    "        data=X_valid_xgb,\n",
    "        label=y_valid_xgb,\n",
    "        missing=None,\n",
    "        weight=None,\n",
    "        silent=False,\n",
    "        feature_names=feat,\n",
    "        #feature_types=X_valid_xgb[feat].dtypes,\n",
    "        nthread=n_threads\n",
    "    )\n",
    "\n",
    "    valid_xgb = xgb.DMatrix(\n",
    "        data=X_valid[feat],\n",
    "        label=y_valid,\n",
    "        missing=None,\n",
    "        weight=None,\n",
    "        silent=False,\n",
    "        feature_names=feat,\n",
    "        #feature_types=X_test_xgb[feat].dtypes,\n",
    "        nthread=n_threads\n",
    "    )\n",
    "    \n",
    "    test_xgb = xgb.DMatrix(\n",
    "        data=X_test[feat],\n",
    "        label=y_test,\n",
    "        missing=None,\n",
    "        weight=None,\n",
    "        silent=False,\n",
    "        feature_names=feat,\n",
    "        #feature_types=X_test_xgb[feat].dtypes,\n",
    "        nthread=n_threads\n",
    "    )\n",
    "\n",
    "    balance = y_train_xgb[y_train_xgb==0].shape[0]/y_train_xgb[y_train_xgb==1].shape[0]\n",
    "    \n",
    "    params = {\n",
    "    #General Parameters\n",
    "        'booster': 'gbtree', #default\n",
    "        'silent': 0, #default\n",
    "        'verbosity': 1, #default\n",
    "        'nthread': n_threads,\n",
    "        'disable_default_eval_metric': 0, #default\n",
    "        #'num_pbuffer': ?, #set automatically by XGBoost, no need to be set by user\n",
    "        #'num_feature': ?, #set automatically by XGBoost, no need to be set by user\n",
    "    #Parameters for Tree Booster (booster=gbtree)\n",
    "        #learning_rate\n",
    "        'eta': .1,\n",
    "        #min_split_loss\n",
    "        'gamma': 0,\n",
    "        'max_depth': 6, #default\n",
    "        'min_child_weight': 1, #default #The larger min_child_weight is, the more conservative the algorithm will be.\n",
    "        'max_delta_step': 0, #default #Set it to value of 1-10 might help control the update.\n",
    "        'subsample': .75,\n",
    "        'colsample_bytree': .75,\n",
    "        'colsample_bylevel': .75,\n",
    "        'colsample_bynode': .75,\n",
    "        #reg_lambda l2\n",
    "        'lambda': 1, #default\n",
    "        #reg_alpha l1\n",
    "        'alpha': 0, #default\n",
    "        'tree_method': 'hist', #gpu_hist\n",
    "        #'sketch_eps': .03, #Only used for tree_method=approx.\n",
    "        'scale_pos_weight': balance, #default\n",
    "        #'updater': 'grow_histmaker', #default\n",
    "        'refresh_leaf': 1, #default\n",
    "        'process_type': 'default', #default\n",
    "        'grow_policy': 'depthwise', #default\n",
    "        #'max_leaves': 0, #Only relevant when grow_policy=lossguide is set.\n",
    "        'max_bin': 256, #default\n",
    "        'predictor': 'cpu_predictor', #gpu_predictor\n",
    "        'num_parallel_tree': 1, #default\n",
    "    #Additional parameters for Dart Booster (booster=dart)\n",
    "        #'sample_type': 'uniform', #default\n",
    "        #'normalize_type': 'tree', #default\n",
    "        #'rate_drop': 0.0, #default\n",
    "        #'one_dorp': 0, #default\n",
    "        #'skip_drop': 0.0, #default\n",
    "    #Parameters for Linear Booster (booster=gblinear)\n",
    "        ##reg_lambda l2\n",
    "        #'lambda': 1, #default\n",
    "        ##reg_alpha l1\n",
    "        #'alpha': 0, #default\n",
    "        #'updater': 'shotgun', #default\n",
    "        #'feature_selector': 'cyclic', #default\n",
    "        #'top_k': 0, #default\n",
    "    #Parameters for Tweedie Regression (objective=reg:tweedie)\n",
    "        #'tweedie_variance_power': 1.5, #default\n",
    "    #Learning Task Parameters\n",
    "        'objective': 'reg:logistic',\n",
    "        'base_score': .5, #default\n",
    "        'eval_metric': 'auc',\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=train_xgb,\n",
    "        num_boost_round=10,\n",
    "        evals=[(train_xgb, 'train'), (eval_xgb, 'eval')],\n",
    "        obj=None,\n",
    "        feval=None,\n",
    "        maximize=False,\n",
    "        early_stopping_rounds=3,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        xgb_model=None,\n",
    "        callbacks=None,\n",
    "        learning_rates=None\n",
    "    )\n",
    "\n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict(\n",
    "            data=valid_xgb,\n",
    "            output_margin=False,\n",
    "            ntree_limit=model.best_ntree_limit,\n",
    "            pred_leaf=False,\n",
    "            pred_contribs=False,\n",
    "            approx_contribs=False,\n",
    "            pred_interactions=False,\n",
    "            validate_features=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            'MODEL XGBST',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(valid_xgb.get_label(), y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict(\n",
    "        data=test_xgb,\n",
    "        output_margin=False,\n",
    "        ntree_limit=model.best_ntree_limit,\n",
    "        pred_leaf=False,\n",
    "        pred_contribs=False,\n",
    "        approx_contribs=False,\n",
    "        pred_interactions=False,\n",
    "        validate_features=True\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        'MODEL XGBST',\n",
    "        '\\nROC AUC test score:',\n",
    "        roc_auc_score(test_xgb.get_label(), y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 LightGBM datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T18:35:07.771544Z",
     "start_time": "2019-04-20T18:35:07.754590Z"
    }
   },
   "outputs": [],
   "source": [
    "#you should skip categorical_feature setting in dataset and set in train if you gonna use gpu\n",
    "\n",
    "X_train_lgb, X_test_lgb, y_train_lgb, y_test_lgb = train_test_split(\n",
    "    X_train[feat],\n",
    "    y_train,\n",
    "    test_size=.1,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "X_test_lgb = X_test_lgb[feat]\n",
    "\n",
    "X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(\n",
    "    X_train_lgb,\n",
    "    y_train_lgb,\n",
    "    test_size=.25,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train_lgb\n",
    ")\n",
    "\n",
    "train_lgb_full = lgb.Dataset(\n",
    "    data=X_train[feat],\n",
    "    label=y_train,\n",
    "    reference=None,\n",
    "    weight=None,\n",
    "    group=None,\n",
    "    init_score=None,\n",
    "    silent=None,\n",
    "    feature_name=feat,\n",
    "    categorical_feature=cat_feat,\n",
    "    params=None,\n",
    "    free_raw_data=False #you should set is True if you don't wanna drop it by yourself\n",
    ")\n",
    "\n",
    "train_lgb = lgb.Dataset(\n",
    "    data=X_train_lgb,\n",
    "    label=y_train_lgb,\n",
    "    reference=None,\n",
    "    weight=None,\n",
    "    group=None,\n",
    "    init_score=None,\n",
    "    silent=None,\n",
    "    feature_name=feat,\n",
    "    categorical_feature=cat_feat,\n",
    "    params=None,\n",
    "    free_raw_data=False #you should set is True if you don't wanna drop it by yourself\n",
    ")\n",
    "\n",
    "valid_lgb = lgb.Dataset(\n",
    "    data=X_valid_lgb,\n",
    "    label=y_valid_lgb,\n",
    "    reference=None,\n",
    "    weight=None,\n",
    "    group=None,\n",
    "    init_score=None,\n",
    "    silent=None,\n",
    "    feature_name=feat,\n",
    "    categorical_feature=cat_feat,\n",
    "    params=None,\n",
    "    free_raw_data=False #you should set is True if you don't wanna drop it by yourself\n",
    ")\n",
    "\n",
    "test_lgb = lgb.Dataset(\n",
    "    data=X_test_lgb,\n",
    "    label=y_test_lgb,\n",
    "    reference=None,\n",
    "    weight=None,\n",
    "    group=None,\n",
    "    init_score=None,\n",
    "    silent=None,\n",
    "    feature_name=feat,\n",
    "    categorical_feature=cat_feat,\n",
    "    params=None,\n",
    "    free_raw_data=False #you should set is True if you don't wanna drop it by yourself\n",
    ")\n",
    "\n",
    "balance = y_train_lgb[y_train_lgb==0].shape[0]/y_train_lgb[y_train_lgb==1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Finding the best depth and num_leaves trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:53:31.080741Z",
     "start_time": "2019-04-18T20:53:21.348783Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "'''\n",
    "Tune Parameters for the Leaf-wise (Best-first) Tree\n",
    "LightGBM uses the leaf-wise tree growth algorithm, while many other popular tools use depth-wise tree growth.\n",
    "Compared with depth-wise growth, the leaf-wise algorithm can converge much faster.\n",
    "However, the leaf-wise growth may be over-fitting if not used with the appropriate parameters.\n",
    "\n",
    "To get good results using a leaf-wise tree, these are some important parameters:\n",
    "\n",
    "num_leaves. This is the main parameter to control the complexity of the tree model.\n",
    "Theoretically, we can set num_leaves = 2^(max_depth) to obtain the same number of leaves as depth-wise tree.\n",
    "However, this simple conversion is not good in practice.\n",
    "The reason is that a leaf-wise tree is typically much deeper than a depth-wise tree for a fixed number of leaves.\n",
    "Unconstrained depth can induce over-fitting.\n",
    "Thus, when trying to tune the num_leaves, we should let it be smaller than 2^(max_depth).\n",
    "For example, when the max_depth=7 the depth-wise tree can get good accuracy, \n",
    "but setting num_leaves to 127 may cause over-fitting, and setting it to 70 or 80 may get better accuracy than depth-wise.\n",
    "\n",
    "min_data_in_leaf.\n",
    "This is a very important parameter to prevent over-fitting in a leaf-wise tree.\n",
    "Its optimal value depends on the number of training samples and num_leaves.\n",
    "Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\n",
    "In practice, setting it to hundreds or thousands is enough for a large dataset.\n",
    "\n",
    "max_depth. You also can use max_depth to limit the tree depth explicitly.\n",
    "'''\n",
    "\n",
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "depths = range(1, 17, 2)\n",
    "\n",
    "for d in tqdm_notebook(depths):\n",
    "\n",
    "    n_l = int(np.power(2, d)*.6)\n",
    "    \n",
    "    if n_l==1:\n",
    "        n_l += 1\n",
    "    \n",
    "    model = lgb.LGBMModel(\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=n_l,\n",
    "        max_depth=d,\n",
    "        learning_rate=.1,\n",
    "        n_estimators=10000,\n",
    "        subsample_for_bin=2000000,\n",
    "        objective='binary',\n",
    "        class_weight=None,\n",
    "        min_split_gain=.0,\n",
    "        min_child_weight=.001,\n",
    "        min_child_samples=20,\n",
    "        subsample=.75,\n",
    "        subsample_freq=2,\n",
    "        colsample_bytree=.75,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_threads,\n",
    "        silent=True,\n",
    "        ##**kwargs:\n",
    "    #Core Parameters\n",
    "        #config=,\n",
    "        task='train',\n",
    "        #objective='regression',\n",
    "        #boosting='gbdt',\n",
    "        #data='',\n",
    "        #valid='',\n",
    "        #num_iterations=100000,\n",
    "        #learning_rate=.01,\n",
    "        #num_leaves=180, #2^max_depth*70%\n",
    "        #tree_learner=serial,\n",
    "        #num_threads=n_threads,\n",
    "        device_type='cpu',\n",
    "        #seed=random_state,\n",
    "    #Learning Control Parameters\n",
    "        #max_depth=8,\n",
    "        #min_data_in_leaf=20,\n",
    "        #min_sum_hessian_in_leaf=1e-3,\n",
    "        #bagging_fraction=.75,\n",
    "        #bagging_freq=2,\n",
    "        bagging_seed=random_state,\n",
    "        #feature_fraction=.75,\n",
    "        feature_fraction_seed=random_state,\n",
    "        #early_stopping_rounds=100,\n",
    "        max_delta_step=0.0,\n",
    "        #lambda_l1=0.0,\n",
    "        #lambda_l2=0.0,\n",
    "        #min_gain_to_split=0.0,\n",
    "        #drop_rate=.1, #dart\n",
    "        #max_dop=50, #dart\n",
    "        #skip_drop=.5, #dart\n",
    "        #xgboost_dart_mode=False, #dart\n",
    "        #uniform_drop=False, #dart\n",
    "        #drop_seed=random_state, #dart\n",
    "        #top_rate=.2, #goss\n",
    "        #oter_rate=.1, #goss\n",
    "        min_data_per_group=100,\n",
    "        max_cat_threshold=32,\n",
    "        cat_l2=10.0,\n",
    "        cat_smooth=10.0,\n",
    "        max_cat_to_onehot=4,\n",
    "        #top_k=20, #parallel\n",
    "        monotone_constraints=None,\n",
    "        feature_contri=None,\n",
    "        forcedsplits_filename='',\n",
    "        refit_decay_rate=.9,\n",
    "    #IO Parameters\n",
    "        verbosity=1,\n",
    "        max_bin=256,\n",
    "        min_data_in_bin=3,\n",
    "        bin_construct_sample_cnt=200000,\n",
    "        histogram_pool_size=-1.0,\n",
    "        data_random_seed=random_state,\n",
    "        #output_model=LightGBM_mode.txt, #model\n",
    "        snapshot_freq=-1,\n",
    "        #input_model=, #model\n",
    "        #output_result=LightGBM_predict_result.txt, #model\n",
    "        initscore_filename='',\n",
    "        valid_data_initscores='',\n",
    "        pre_partition=False,\n",
    "        enable_bundle=True,\n",
    "        max_conflict_rate=0.0,\n",
    "        is_enable_sparse=True,\n",
    "        sparse_threshold=.8,\n",
    "        use_missing=True,\n",
    "        zero_as_missing=False,\n",
    "        two_round=False,\n",
    "        save_binary=False,\n",
    "        header=False,\n",
    "        #label_column='',\n",
    "        #weight_column='',\n",
    "        #group_column='',\n",
    "        #ignore_column='',\n",
    "        #categorial_feature='', #train\n",
    "        #predict_raw_score=False, #predict\n",
    "        #predict_leaf_index=False, #predict\n",
    "        #predict_contrlib=False, #predict\n",
    "        #num_iterations_predict=-1, #predict\n",
    "        #pred_early_stop=False, #predict\n",
    "        #pred_early_stop_freq=10, #predict\n",
    "        #pred_early_stop_margin=10.0, #predict\n",
    "        #convert_model_language=, #convert_model\n",
    "        #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "    #Objective Parameters\n",
    "        #num_class=1, #multi_class\n",
    "        is_unbalance=False, #binary\n",
    "        scale_pos_weight=balance, #binary\n",
    "        sigmoid=1.0, #binary\n",
    "        boost_from_average=True,\n",
    "        reg_sqrt=False,\n",
    "        alpha=.9,\n",
    "        fair_c=1.0,\n",
    "        poisson_max_delta_step=.7,\n",
    "        tweedie_variance_power=1.5,\n",
    "        #max_position=20, #lambdarank\n",
    "        #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "    #Metric Parameters\n",
    "        metric='auc',\n",
    "        metric_freq=1,\n",
    "        is_provide_training_metric=False,\n",
    "    #Network Parameters\n",
    "        num_machines=1,\n",
    "        local_listen_port=12400,\n",
    "        time_out=120,\n",
    "        machine_list_filename='',\n",
    "        machines='',\n",
    "    #GPU Parameters\n",
    "        gpu_platform_id=0,\n",
    "        gpu_device_id=0,\n",
    "        gpu_use_dp=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=train_lgb.data,\n",
    "        y=train_lgb.get_label(),\n",
    "        sample_weight=None,\n",
    "        init_score=None,\n",
    "        group=None,\n",
    "        eval_set=[(train_lgb.data, train_lgb.get_label()), (valid_lgb.data, valid_lgb.get_label())],\n",
    "        eval_names=None,\n",
    "        eval_sample_weight=None,\n",
    "        eval_class_weight=None,\n",
    "        eval_init_score=None,\n",
    "        eval_group=None,\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=1000,\n",
    "        verbose=False,\n",
    "        #feature_name=feat, #for not lgbm dataset\n",
    "        #categorical_feature=cat_feat, #for not lgbm dataset\n",
    "        callbacks=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict(\n",
    "        X=train_lgb.data,\n",
    "        raw_score=False,\n",
    "        num_iteration=model.best_iteration_,\n",
    "        pred_leaf=False,\n",
    "        pred_contrib=False\n",
    "    )\n",
    "\n",
    "    y_pred_test = model.predict(\n",
    "        X=test_lgb.data,\n",
    "        raw_score=False,\n",
    "        num_iteration=model.best_iteration_,\n",
    "        pred_leaf=False,\n",
    "        pred_contrib=False\n",
    "    )\n",
    "    \n",
    "    train_results.append(roc_auc_score(train_lgb.get_label(), y_pred_train))\n",
    "    valid_results.append(roc_auc_score(test_lgb.get_label(), y_pred_test))\n",
    "    \n",
    "plot_vc(\n",
    "    x=[d for d in depths],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='DEPTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Model with all features trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:59:24.173341Z",
     "start_time": "2019-04-19T16:59:13.414131Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "global PARAMS_PREV\n",
    "PARAMS_PREV = {'learning_rate': .001}\n",
    "\n",
    "def lgbm_callback(is_changing=False):\n",
    "\n",
    "    def callback(env):\n",
    "        \n",
    "        global PARAMS_PREV\n",
    "\n",
    "        delta = .001\n",
    "        up = 20\n",
    "        down = 5\n",
    "        \n",
    "        model_callback = env.model\n",
    "        roc_auc_callback = roc_auc_score(test_lgb.label, model_callback.predict(test_lgb.data))\n",
    "        \n",
    "        #up each nth iteration\n",
    "        if (PARAMS_PREV['learning_rate'] + delta < .01) & \\\n",
    "                                (env.iteration % up == 0) & \\\n",
    "                                (env.iteration > 0) & \\\n",
    "                                (is_changing == True):\n",
    "            \n",
    "            PARAMS_PREV['learning_rate'] += delta\n",
    "            \n",
    "            print(\n",
    "                '\\nRESET LEARNING RATE UP TO:',\n",
    "                  PARAMS_PREV['learning_rate']\n",
    "            )\n",
    "            \n",
    "            print(\n",
    "               'ITERATION:',\n",
    "                env.model.current_iteration(),\n",
    "                'ROC AUC:',\n",
    "                roc_auc_callback\n",
    "            )\n",
    "            \n",
    "        #down each nth iteration\n",
    "        elif (PARAMS_PREV['learning_rate'] - delta > .0001) & \\\n",
    "                                (env.iteration % up == 0) & \\\n",
    "                                (env.iteration > 0) & \\\n",
    "                                (is_changing == True):\n",
    "            \n",
    "            PARAMS_PREV['learning_rate'] -= delta\n",
    "            \n",
    "            print(\n",
    "                '\\nRESET LEARNING RATE DOWN TO:',\n",
    "                  PARAMS_PREV['learning_rate']\n",
    "            )\n",
    "            \n",
    "            print(\n",
    "               'ITERATION:',\n",
    "                env.model.current_iteration(),\n",
    "                'ROC AUC:',\n",
    "                roc_auc_callback\n",
    "            )\n",
    "            \n",
    "    callback.before_iteration = True\n",
    "    callback.order = 0\n",
    "    return callback\n",
    "    \n",
    "params_cpu = {\n",
    "#Core Parameters\n",
    "    #'config': '',\n",
    "    'task': 'train',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    #'data': '',\n",
    "    #'valid': '',\n",
    "    #num_iterations: 100000,\n",
    "    'learning_rate': .01,\n",
    "    'num_leaves': 180, #2^max_depth*70%\n",
    "    #'tree_learner': 'serial',\n",
    "    'num_threads': n_threads,\n",
    "    'device_type': 'cpu',\n",
    "    'seed': random_state,\n",
    "#Learning Control Parameters\n",
    "    'max_depth': 19,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_sum_hessian_in_leaf': 1e-3,\n",
    "    'bagging_fraction': .75,\n",
    "    'bagging_freq': 2,\n",
    "    'bagging_seed': random_state,\n",
    "    'feature_fraction': .75,\n",
    "    'feature_fraction_seed': random_state,\n",
    "    #'early_stopping_rounds': 100,\n",
    "    'max_delta_step': 0.0,\n",
    "    'lambda_l1': 0.0,\n",
    "    'lambda_l2': 0.0,\n",
    "    'min_gain_to_split': 0.0,\n",
    "    #'drop_rate': .1, #dart\n",
    "    #'max_dop': 50, #dart\n",
    "    #skip_drop': .5, #dart\n",
    "    #'xgboost_dart_mode': False, #dart\n",
    "    #'uniform_drop': False, #dart\n",
    "    #'drop_seed': random_state, #dart\n",
    "    #'top_rate': .2, #goss\n",
    "    #'oter_rate': .1, #goss\n",
    "    'min_data_per_group': 100,\n",
    "    'max_cat_threshold': 32,\n",
    "    'cat_l2': 10.0,\n",
    "    'cat_smooth': 10.0,\n",
    "    'max_cat_to_onehot': 4,\n",
    "    #'top_k': 20, #parallel\n",
    "    'monotone_constraints': None,\n",
    "    'feature_contri': None,\n",
    "    'forcedsplits_filename': '',\n",
    "    'refit_decay_rate': .9,\n",
    "#IO Parameters\n",
    "    'verbosity': 1,\n",
    "    'max_bin': 256,\n",
    "    'min_data_in_bin': 3,\n",
    "    'bin_construct_sample_cnt': 200000,\n",
    "    'histogram_pool_size': -1.0,\n",
    "    'data_random_seed': random_state,\n",
    "    #'output_model': LightGBM_mode.txt, #model\n",
    "    'snapshot_freq': -1,\n",
    "    #'input_model': '', #model\n",
    "    #'output_result': LightGBM_predict_result.txt, #model\n",
    "    'initscore_filename': '',\n",
    "    'valid_data_initscores': '',\n",
    "    'pre_partition': False,\n",
    "    'enable_bundle': True,\n",
    "    'max_conflict_rate': 0.0,\n",
    "    'is_enable_sparse': True,\n",
    "    'sparse_threshold': .8,\n",
    "    'use_missing': True,\n",
    "    'zero_as_missing': False,\n",
    "    'two_round': False,\n",
    "    'save_binary': False,\n",
    "    'header': False,\n",
    "    'label_column': '',\n",
    "    'weight_column': '',\n",
    "    'group_column': '',\n",
    "    'ignore_column': '',\n",
    "    #'categorial_feature': '', #train\n",
    "    #'predict_raw_score': False, #predict\n",
    "    #'predict_leaf_index': False, #predict\n",
    "    #'predict_contrlib': False, #predict\n",
    "    #'num_iterations_predict': -1, #predict\n",
    "    #'pred_early_stop': False, #predict\n",
    "    #'pred_early_stop_freq': 10, #predict\n",
    "    #'pred_early_stop_margin': 10.0, #predict\n",
    "    #'convert_model_language': '', #convert_model\n",
    "    #'convert_model': 'gbdt_prediction_cpp', #convert_model\n",
    "#Objective Parameters\n",
    "    #'num_class': 1, #multi_class\n",
    "    'is_unbalance': False, #binary\n",
    "    'scale_pos_weight': balance, #binary\n",
    "    'sigmoid': 1.0, #binary\n",
    "    'boost_from_average': True,\n",
    "    'reg_sqrt': False,\n",
    "    'alpha': .9,\n",
    "    'fair_c': 1.0,\n",
    "    'poisson_max_delta_step': .7,\n",
    "    'tweedie_variance_power': 1.5,\n",
    "    #'max_position': 20, #lambdarank\n",
    "    #'label_gain': 0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    'metric': 'auc',\n",
    "    'metric_freq': 1,\n",
    "    'is_provide_training_metric': False,\n",
    "#Network Parameters\n",
    "    'num_machines': 1,\n",
    "    'local_listen_port': 12400,\n",
    "    'time_out': 120,\n",
    "    'machine_list_filename': '',\n",
    "    'machines': '',\n",
    "#GPU Parameters\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'gpu_use_dp': True\n",
    "}\n",
    "\n",
    "params_gpu = {\n",
    "#Core Parameters\n",
    "    #'config': '',\n",
    "    'task': 'train',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    #'data': '',\n",
    "    #'valid': '',\n",
    "    #num_iterations: 100000,\n",
    "    'learning_rate': .01,\n",
    "    'num_leaves': 180, #2^max_depth*70%\n",
    "    #'tree_learner': 'serial',\n",
    "    'num_threads': n_threads,\n",
    "    'device_type': 'gpu',\n",
    "    'seed': random_state,\n",
    "#Learning Control Parameters\n",
    "    'max_depth': 19,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_sum_hessian_in_leaf': 1e-3,\n",
    "    'bagging_fraction': 1.,\n",
    "    'bagging_freq': 2,\n",
    "    'bagging_seed': random_state,\n",
    "    'feature_fraction': .75,\n",
    "    'feature_fraction_seed': random_state,\n",
    "    #early_stopping_rounds': 100,\n",
    "    'max_delta_step': 0.0,\n",
    "    'lambda_l1': 0.0,\n",
    "    'lambda_l2': 0.0,\n",
    "    'min_gain_to_split': 0.0,\n",
    "    #'drop_rate': .1, #dart\n",
    "    #'max_dop': 50, #dart\n",
    "    #skip_drop': .5, #dart\n",
    "    #'xgboost_dart_mode': False, #dart\n",
    "    #'uniform_drop': False, #dart\n",
    "    #'drop_seed': random_state, #dart\n",
    "    #'top_rate': .2, #goss\n",
    "    #'oter_rate': .1, #goss\n",
    "    'min_data_per_group': 100,\n",
    "    'max_cat_threshold': 32,\n",
    "    'cat_l2': 10.0,\n",
    "    'cat_smooth': 10.0,\n",
    "    'max_cat_to_onehot': 4,\n",
    "    #'top_k': 20, #parallel\n",
    "    'monotone_constraints': None,\n",
    "    'feature_contri': None,\n",
    "    'forcedsplits_filename': '',\n",
    "    'refit_decay_rate': .9,\n",
    "#IO Parameters\n",
    "    'verbosity': 1,\n",
    "    #'max_bin': 256,\n",
    "    'min_data_in_bin': 3,\n",
    "    'bin_construct_sample_cnt': 200000,\n",
    "    'histogram_pool_size': -1.0,\n",
    "    'data_random_seed': random_state,\n",
    "    #'output_model': LightGBM_mode.txt, #model\n",
    "    'snapshot_freq': -1,\n",
    "    #'input_model': '', #model\n",
    "    #'output_result': LightGBM_predict_result.txt, #model\n",
    "    'initscore_filename': '',\n",
    "    'valid_data_initscores': '',\n",
    "    'pre_partition': False,\n",
    "    'enable_bundle': True,\n",
    "    'max_conflict_rate': 0.0,\n",
    "    'is_enable_sparse': True,\n",
    "    'sparse_threshold': .8,\n",
    "    'use_missing': True,\n",
    "    'zero_as_missing': False,\n",
    "    'two_round': False,\n",
    "    'save_binary': False,\n",
    "    'header': False,\n",
    "    'label_column': '',\n",
    "    'weight_column': '',\n",
    "    'group_column': '',\n",
    "    'ignore_column': '',\n",
    "    #'categorial_feature': '', #train\n",
    "    #'predict_raw_score': False, #predict\n",
    "    #'predict_leaf_index': False, #predict\n",
    "    #'predict_contrlib': False, #predict\n",
    "    #'num_iterations_predict': -1, #predict\n",
    "    #'pred_early_stop': False, #predict\n",
    "    #'pred_early_stop_freq': 10, #predict\n",
    "    #'pred_early_stop_margin': 10.0, #predict\n",
    "    #'convert_model_language': '', #convert_model\n",
    "    #'convert_model': 'gbdt_prediction_cpp', #convert_model\n",
    "#Objective Parameters\n",
    "    #'num_class': 1, #multi_class\n",
    "    'is_unbalance': False, #binary\n",
    "    'scale_pos_weight': balance, #binary\n",
    "    'sigmoid': 1.0, #binary\n",
    "    'boost_from_average': True,\n",
    "    'reg_sqrt': False,\n",
    "    'alpha': .9,\n",
    "    'fair_c': 1.0,\n",
    "    'poisson_max_delta_step': .7,\n",
    "    'tweedie_variance_power': 1.5,\n",
    "    #'max_position': 20, #lambdarank\n",
    "    #'label_gain': 0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    'metric': 'auc',\n",
    "    'metric_freq': 1,\n",
    "    'is_provide_training_metric': False,\n",
    "#Network Parameters\n",
    "    'num_machines': 1,\n",
    "    'local_listen_port': 12400,\n",
    "    'time_out': 120,\n",
    "    'machine_list_filename': '',\n",
    "    'machines': '',\n",
    "#GPU Parameters\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'gpu_use_dp': True\n",
    "}\n",
    "\n",
    "evals_result = {} \n",
    "\n",
    "model = lgb.train(\n",
    "    params=params_cpu,\n",
    "    train_set=train_lgb,\n",
    "    num_boost_round=100000,\n",
    "    valid_sets=[train_lgb, valid_lgb],\n",
    "    valid_names=None,\n",
    "    fobj=None,\n",
    "    feval=None,\n",
    "    init_model=None,\n",
    "    feature_name=feat, #for not lgbm dataset\n",
    "    categorical_feature=cat_feat, #for not lgbm dataset\n",
    "    early_stopping_rounds=3000,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=1000,\n",
    "    learning_rates=None,\n",
    "    keep_training_booster=False,\n",
    "    callbacks=None #[lgbm_callback(False)] it's so slow cause auc metric is not easy to calculate\n",
    ")\n",
    "\n",
    "y_pred = model.predict(\n",
    "    data=test_lgb.data,\n",
    "    num_iteration=model.best_iteration,\n",
    "    raw_score=False,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=False,\n",
    "    data_has_header=False,\n",
    "    is_reshape=True,\n",
    "    pred_parameter=None\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'BEST MODEL ITERATION:',\n",
    "    model.best_iteration\n",
    ")\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_lgb.label, y_pred)\n",
    ")\n",
    "\n",
    "lgb.plot_importance(\n",
    "    booster=model,\n",
    "    ax=None,\n",
    "    height=.2,\n",
    "    xlim=None,\n",
    "    ylim=None,\n",
    "    title='Features importance',\n",
    "    xlabel='Importance',\n",
    "    ylabel='Feature',\n",
    "    importance_type='split',\n",
    "    max_num_features=50,\n",
    "    ignore_zero=True,\n",
    "    figsize=None,\n",
    "    grid=True\n",
    ")\n",
    "\n",
    "lgb.plot_metric(\n",
    "    booster=evals_result,\n",
    "    metric='auc',\n",
    "    dataset_names=None,\n",
    "    ax=None,\n",
    "    xlim=None,\n",
    "    ylim=None,\n",
    "    title='Validation curve',\n",
    "    xlabel='Iterations',\n",
    "    ylabel='AUC',\n",
    "    figsize=None,\n",
    "    grid=True\n",
    ")\n",
    "\n",
    "lgb.plot_tree(\n",
    "    booster=model,\n",
    "    ax=None,\n",
    "    tree_index=model.best_iteration-1,\n",
    "    figsize=(20, 10),\n",
    "    old_graph_attr=None,\n",
    "    old_node_attr=None,\n",
    "    old_edge_attr=None,\n",
    "    show_info=None,\n",
    "    precision=None,\n",
    "    #**kwargs\n",
    "    #https://graphviz.readthedocs.io/en/stable/api.html#digraph\n",
    ")\n",
    "\n",
    "model.save_model(\n",
    "    filename = path + 'lgbm_model.txt',\n",
    "    num_iteration=model.best_iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:59:24.237171Z",
     "start_time": "2019-04-19T16:59:24.174338Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb.create_tree_digraph(\n",
    "    booster=model,\n",
    "    tree_index=model.best_iteration-1,\n",
    "    show_info=None,\n",
    "    precision=None,\n",
    "    old_name=None,\n",
    "    old_comment=None,\n",
    "    old_filename=None,\n",
    "    old_directory=None,\n",
    "    old_format=None,\n",
    "    old_engine=None,\n",
    "    old_encoding=None,\n",
    "    old_graph_attr=None,\n",
    "    old_node_attr=None,\n",
    "    old_edge_attr=None,\n",
    "    old_body=None,\n",
    "    old_strict=False,\n",
    "    #**kwargs\n",
    "    #https://graphviz.readthedocs.io/en/stable/api.html#digraph\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T20:10:22.437429Z",
     "start_time": "2019-04-15T20:09:12.180607Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = lgb.cv(\n",
    "    params=params_cpu,\n",
    "    train_set=train_lgb_full,\n",
    "    num_boost_round=10000,\n",
    "    folds=None,\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    metrics=['auc'],\n",
    "    fobj=None,\n",
    "    feval=None,\n",
    "    init_model=None,\n",
    "    feature_name=feat,\n",
    "    categorical_feature=cat_feat,\n",
    "    early_stopping_rounds=3000,\n",
    "    fpreproc=None,\n",
    "    verbose_eval=1000,\n",
    "    show_stdv=True,\n",
    "    seed=random_state,\n",
    "    callbacks=None #[lgbm_callback(False)] it's so slow cause auc metric is not easy to calculate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Finding the best params trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:11:49.808997Z",
     "start_time": "2019-04-19T17:11:47.556022Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "'''\n",
    "For Faster Speed:\n",
    "- Use bagging by setting bagging_fraction and bagging_freq\n",
    "- Use feature sub-sampling by setting feature_fraction (colsample_bytree)\n",
    "- Use small max_bin\n",
    "- Use save_binary to speed up data loading in future learning\n",
    "- Use parallel learning, refer to Parallel Learning Guide\n",
    "\n",
    "For Better Accuracy:\n",
    "- Use large max_bin (may be slower)\n",
    "- Use small learning_rate with large num_iterations\n",
    "- Use large num_leaves (may cause over-fitting)\n",
    "- Use bigger training data\n",
    "- Try dart\n",
    "\n",
    "Deal with Over-fitting\n",
    "- Use small max_bin\n",
    "- Use small num_leaves\n",
    "- Use min_data_in_leaf (min_child_samples) and min_sum_hessian_in_leaf (min_child_weight)\n",
    "- Use bagging by set bagging_fraction and bagging_freq\n",
    "- Use feature sub-sampling by set feature_fraction (colsample_bytree)\n",
    "- Use bigger training data\n",
    "- Try lambda_l1, lambda_l2 and min_gain_to_split (min_split_gain) for regularization\n",
    "- Try max_depth to avoid growing deep tree\n",
    "'''\n",
    "\n",
    "model = lgb.LGBMModel(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=180,\n",
    "    max_depth=19,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=1000,\n",
    "    subsample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=.75,\n",
    "    subsample_freq=2,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    #drop_rate=.1, #dart\n",
    "    #max_dop=50, #dart\n",
    "    #skip_drop=.5, #dart\n",
    "    #xgboost_dart_mode=False, #dart\n",
    "    #uniform_drop=False, #dart\n",
    "    #drop_seed=random_state, #dart\n",
    "    #top_rate=.2, #goss\n",
    "    #oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature='', #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "#for using .predict_proba method\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=180,\n",
    "    max_depth=14,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=1000,\n",
    "    subsample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    #drop_rate=.1, #dart\n",
    "    #max_dop=50, #dart\n",
    "    #skip_drop=.5, #dart\n",
    "    #xgboost_dart_mode=False, #dart\n",
    "    #uniform_drop=False, #dart\n",
    "    #drop_seed=random_state, #dart\n",
    "    #top_rate=.2, #goss\n",
    "    #oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature='', #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    #sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt'],#, 'gbrt', 'rf'],\n",
    "    'learning_rate': [float(x) for x in np.linspace(start=.1, stop=.1, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=10000, stop=10000, num=1)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=19, stop=19, num=1)],\n",
    "    'min_child_samples': [int(x) for x in np.linspace(start=10, stop=100, num=5)],\n",
    "    'min_child_weight': [float(x) for x in np.linspace(start=0.1, stop=40, num=5)],\n",
    "    'bagging_fraction': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    'bagging_freq': [int(x) for x in np.linspace(start=1, stop=10, num=5)],\n",
    "    'colsample_bytree': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    #'num_leaves': [int(np.power(2, x)*.7) for x in np.linspace(start=3, stop=3, num=1)],\n",
    "    'num_leaves': [int(x) for x in np.linspace(start=65000, stop=65000, num=1)],\n",
    "    'max_bin': [int(x) for x in np.linspace(start=3, stop=255, num=5)], #it will crash your python.exe if you start from 2\n",
    "    'min_data_per_group': [int(x) for x in np.linspace(start=10, stop=200, num=5)],\n",
    "    'min_data_in_bin': [int(x) for x in np.linspace(start=3, stop=30, num=5)],\n",
    "    'lambda_l1': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "    'lambda_l2': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "    'sigmoid': [float(x) for x in np.linspace(start=.1, stop=1., num=5)],\n",
    "    'boost_from_average': [True, False]\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=train_lgb.data,\n",
    "    y=train_lgb.get_label(),\n",
    "    sample_weight=None,\n",
    "    init_score=None,\n",
    "    #group=None, #LGBMModel\n",
    "    eval_set=[(train_lgb.data, train_lgb.get_label()), (valid_lgb.data, valid_lgb.get_label())],\n",
    "    eval_names=None,\n",
    "    eval_sample_weight=None,\n",
    "    eval_class_weight=None,\n",
    "    eval_init_score=None,\n",
    "    #eval_group=None, #LGBMModel\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=1000,\n",
    "    #feature_name=feat, #for not lgbm dataset\n",
    "    #categorical_feature=cat_feat, #for not lgbm dataset\n",
    "    callbacks=None\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    X=test_lgb.data,\n",
    "    raw_score=False,\n",
    "    num_iteration=train_grid.best_estimator_.best_iteration_,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=False\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_lgb.label, y_pred)\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Final model trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.765980Z",
     "start_time": "2019-04-25T18:59:57.744039Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_LGBM_C_TREES(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, cat_feat, random_state):\n",
    "    \n",
    "    #X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = \\\n",
    "    #    X_train.iloc[:int(X_train.shape[0]*.75)][feat], \\\n",
    "    #    X_train.iloc[int(X_train.shape[0]*.75):][feat], \\\n",
    "    #    y_train[:int(y_train.shape[0]*.75)], \\\n",
    "    #    y_train[int(y_train.shape[0]*.75):]\n",
    "    \n",
    "    X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        test_size=.25,\n",
    "        random_state=random_state,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    train_lgb = lgb.Dataset(\n",
    "        data=X_train_lgb,\n",
    "        label=y_train_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    valid_lgb = lgb.Dataset(\n",
    "        data=X_valid_lgb,\n",
    "        label=y_valid_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "    \n",
    "    eval_lgb = lgb.Dataset(\n",
    "        data=X_valid[feat],\n",
    "        label=y_valid,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    test_lgb = lgb.Dataset(\n",
    "        data=X_test[feat],\n",
    "        label=y_test,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    balance = y_train_lgb[y_train_lgb==0].shape[0]/y_train_lgb[y_train_lgb==1].shape[0]\n",
    "\n",
    "    global PARAMS_PREV\n",
    "\n",
    "    def lgbm_callback(is_changing=False):\n",
    "\n",
    "        def callback(env):\n",
    "\n",
    "            global PARAMS_PREV\n",
    "\n",
    "            delta = .001\n",
    "            up = 20\n",
    "            down = 5\n",
    "\n",
    "            model_callback = env.model\n",
    "            roc_auc_callback = roc_auc_score(test_lgb.label, model_callback.predict(test_lgb.data))\n",
    "\n",
    "            #up each nth iteration\n",
    "            if (PARAMS_PREV['learning_rate'] + delta < .01) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] += delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE UP TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "            #down each nth iteration\n",
    "            elif (PARAMS_PREV['learning_rate'] - delta > .0001) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] -= delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE DOWN TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "        callback.before_iteration = True\n",
    "        callback.order = 0\n",
    "        return callback\n",
    "    \n",
    "    params = {\n",
    "    #Core Parameters\n",
    "        #'config': '',\n",
    "        'task': 'train',\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        #'data': '',\n",
    "        #'valid': '',\n",
    "        #num_iterations: 100000,\n",
    "        'learning_rate': .1,\n",
    "        'num_leaves': 228, #2^max_depth*70%\n",
    "        #'tree_learner': 'serial',\n",
    "        'num_threads': n_threads,\n",
    "        'device_type': 'cpu',\n",
    "        'seed': random_state,\n",
    "    #Learning Control Parameters\n",
    "        'max_depth': 14,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'min_sum_hessian_in_leaf': 1e-3,\n",
    "        'bagging_fraction': .75,\n",
    "        'bagging_freq': 2,\n",
    "        'bagging_seed': random_state,\n",
    "        'feature_fraction': .75,\n",
    "        'feature_fraction_seed': random_state,\n",
    "        #'early_stopping_rounds': 100,\n",
    "        'max_delta_step': 0.0,\n",
    "        'lambda_l1': 0.0,\n",
    "        'lambda_l2': 85.33,\n",
    "        'min_gain_to_split': 0.0,\n",
    "        #'drop_rate': .1, #dart\n",
    "        #'max_dop': 50, #dart\n",
    "        #skip_drop': .5, #dart\n",
    "        #'xgboost_dart_mode': False, #dart\n",
    "        #'uniform_drop': False, #dart\n",
    "        #'drop_seed': random_state, #dart\n",
    "        #'top_rate': .2, #goss\n",
    "        #'oter_rate': .1, #goss\n",
    "        'min_data_per_group': 100,\n",
    "        'max_cat_threshold': 32,\n",
    "        'cat_l2': 10.0,\n",
    "        'cat_smooth': 10.0,\n",
    "        'max_cat_to_onehot': 4,\n",
    "        #'top_k': 20, #parallel\n",
    "        'monotone_constraints': None,\n",
    "        'feature_contri': None,\n",
    "        'forcedsplits_filename': '',\n",
    "        'refit_decay_rate': .9,\n",
    "    #IO Parameters\n",
    "        'verbosity': 1,\n",
    "        'max_bin': 66,\n",
    "        'min_data_in_bin': 3,\n",
    "        'bin_construct_sample_cnt': 200000,\n",
    "        'histogram_pool_size': -1.0,\n",
    "        'data_random_seed': random_state,\n",
    "        #'output_model': LightGBM_mode.txt, #model\n",
    "        'snapshot_freq': -1,\n",
    "        #'input_model': '', #model\n",
    "        #'output_result': LightGBM_predict_result.txt, #model\n",
    "        'initscore_filename': '',\n",
    "        'valid_data_initscores': '',\n",
    "        'pre_partition': False,\n",
    "        'enable_bundle': True,\n",
    "        'max_conflict_rate': 0.0,\n",
    "        'is_enable_sparse': True,\n",
    "        'sparse_threshold': .8,\n",
    "        'use_missing': True,\n",
    "        'zero_as_missing': False,\n",
    "        'two_round': False,\n",
    "        'save_binary': False,\n",
    "        'header': False,\n",
    "        'label_column': '',\n",
    "        'weight_column': '',\n",
    "        'group_column': '',\n",
    "        'ignore_column': '',\n",
    "        #'categorial_feature': '', #train\n",
    "        #'predict_raw_score': False, #predict\n",
    "        #'predict_leaf_index': False, #predict\n",
    "        #'predict_contrlib': False, #predict\n",
    "        #'num_iterations_predict': -1, #predict\n",
    "        #'pred_early_stop': False, #predict\n",
    "        #'pred_early_stop_freq': 10, #predict\n",
    "        #'pred_early_stop_margin': 10.0, #predict\n",
    "        #'convert_model_language': '', #convert_model\n",
    "        #'convert_model': 'gbdt_prediction_cpp', #convert_model\n",
    "    #Objective Parameters\n",
    "        #'num_class': 1, #multi_class\n",
    "        'is_unbalance': False, #binary\n",
    "        'scale_pos_weight': balance, #binary\n",
    "        'sigmoid': .775, #binary\n",
    "        'boost_from_average': True,\n",
    "        'reg_sqrt': False,\n",
    "        'alpha': .9,\n",
    "        'fair_c': 1.0,\n",
    "        'poisson_max_delta_step': .7,\n",
    "        'tweedie_variance_power': 1.5,\n",
    "        #'max_position': 20, #lambdarank\n",
    "        #'label_gain': 0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "    #Metric Parameters\n",
    "        'metric': 'auc',\n",
    "        'metric_freq': 1,\n",
    "        'is_provide_training_metric': False,\n",
    "    #Network Parameters\n",
    "        'num_machines': 1,\n",
    "        'local_listen_port': 12400,\n",
    "        'time_out': 120,\n",
    "        'machine_list_filename': '',\n",
    "        'machines': '',\n",
    "    #GPU Parameters\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'gpu_use_dp': True\n",
    "    }\n",
    "\n",
    "    PARAMS_PREV = {'learning_rate': params['learning_rate']}\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=train_lgb,\n",
    "        num_boost_round=10,\n",
    "        valid_sets=[train_lgb, valid_lgb],\n",
    "        valid_names=None,\n",
    "        fobj=None,\n",
    "        feval=None,\n",
    "        init_model=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        early_stopping_rounds=3,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        learning_rates=None,\n",
    "        keep_training_booster=False,\n",
    "        callbacks=None #[lgbm_callback(False)] it's so slow cause auc metric is not easy to calculate\n",
    "    )\n",
    "    \n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict(\n",
    "            data=eval_lgb.data,\n",
    "            num_iteration=model.best_iteration,\n",
    "            raw_score=False,\n",
    "            pred_leaf=False,\n",
    "            pred_contrib=False,\n",
    "            data_has_header=False,\n",
    "            is_reshape=True,\n",
    "            pred_parameter=None\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            'MODEL LGBM',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(eval_lgb.label, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict(\n",
    "        data=test_lgb.data,\n",
    "        num_iteration=model.best_iteration,\n",
    "        raw_score=False,\n",
    "        pred_leaf=False,\n",
    "        pred_contrib=False,\n",
    "        data_has_header=False,\n",
    "        is_reshape=True,\n",
    "        pred_parameter=None\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        'MODEL LGBM',\n",
    "        '\\nROC AUC test_score:',\n",
    "        roc_auc_score(test_lgb.label, y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Finding the best params goss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = lgb.LGBMModel(\n",
    "    boosting_type='goss',\n",
    "    num_leaves=180,\n",
    "    max_depth=19,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=10000,\n",
    "    subample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=.75,\n",
    "    subsample_freq=2,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    #drop_rate=.1, #dart\n",
    "    #max_dop=50, #dart\n",
    "    #skip_drop=.5, #dart\n",
    "    #xgboost_dart_mode=False, #dart\n",
    "    #uniform_drop=False, #dart\n",
    "    #drop_seed=random_seed, #dart\n",
    "    top_rate=.2, #goss\n",
    "    oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature=, #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "#for using .predict_proba method\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type='goss',\n",
    "    num_leaves=180,\n",
    "    max_depth=14,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=1000,\n",
    "    subsample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    #bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    #drop_rate=.1, #dart\n",
    "    #max_dop=50, #dart\n",
    "    #skip_drop=.5, #dart\n",
    "    #xgboost_dart_mode=False, #dart\n",
    "    #uniform_drop=False, #dart\n",
    "    #drop_seed=random_state, #dart\n",
    "    top_rate=.2, #goss\n",
    "    oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature='', #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    #sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['goss'],#, 'gbrt', 'rf'],\n",
    "    'learning_rate': [float(x) for x in np.linspace(start=.1, stop=.1, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=10000, stop=10000, num=1)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=19, stop=19, num=1)],\n",
    "    'min_child_samples': [int(x) for x in np.linspace(start=10, stop=100, num=5)],\n",
    "    'min_child_weight': [float(x) for x in np.linspace(start=0.1, stop=40, num=5)],\n",
    "    'colsample_bytree': [float(x) for x in np.linspace(start=0.1, stop=.9, num=5)],\n",
    "    #'num_leaves': [int(np.power(2, x)*.7) for x in np.linspace(start=3, stop=3, num=1)],\n",
    "    'num_leaves': [int(x) for x in np.linspace(start=65000, stop=65000, num=1)],\n",
    "    'max_bin': [int(x) for x in np.linspace(start=3, stop=255, num=5)], #it will crash your python.exe if you start from 2\n",
    "    'min_data_per_group': [int(x) for x in np.linspace(start=10, stop=200, num=5)],\n",
    "    'min_data_in_bin': [int(x) for x in np.linspace(start=3, stop=30, num=5)],\n",
    "    'lambda_l1': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "    'lambda_l2': [float(x) for x in np.linspace(start=0., stop=1., num=5)],\n",
    "    'sigmoid': [float(x) for x in np.linspace(start=.1, stop=1., num=5)],\n",
    "    'boost_from_average': [True, False],\n",
    "    'top_rate': [float(x) for x in np.linspace(start=.1, stop=.5, num=5)], #goss\n",
    "    'other_rate': [float(x) for x in np.linspace(start=.5, stop=.1, num=5)] #goss\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=train_lgb.data,\n",
    "    y=train_lgb.get_label(),\n",
    "    sample_weight=None,\n",
    "    init_score=None,\n",
    "    #group=None, #LGBMModel\n",
    "    eval_set=[(train_lgb.data, train_lgb.get_label()), (valid_lgb.data, valid_lgb.get_label())],\n",
    "    eval_names=None,\n",
    "    eval_sample_weight=None,\n",
    "    eval_class_weight=None,\n",
    "    eval_init_score=None,\n",
    "    #eval_group=None, #LGBMModel\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=1000,\n",
    "    #feature_name=feat, #for not lgbm dataset\n",
    "    #categorical_feature=cat_feat, #for not lgbm dataset\n",
    "    callbacks=None\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    X=test_lgb.data,\n",
    "    raw_score=False,\n",
    "    num_iteration=train_grid.best_estimator_.best_iteration_,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=False\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_lgb.label, y_pred)\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 Final model goss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T18:59:57.787921Z",
     "start_time": "2019-04-25T18:59:57.766977Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_LGBM_C_GOSS(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, cat_feat, random_state):\n",
    "    \n",
    "    #X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = \\\n",
    "    #    X_train.iloc[:int(X_train.shape[0]*.75)][feat], \\\n",
    "    #    X_train.iloc[int(X_train.shape[0]*.75):][feat], \\\n",
    "    #    y_train[:int(y_train.shape[0]*.75)], \\\n",
    "    #    y_train[int(y_train.shape[0]*.75):]\n",
    "    \n",
    "    X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        test_size=.25,\n",
    "        random_state=random_state,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    train_lgb = lgb.Dataset(\n",
    "        data=X_train_lgb,\n",
    "        label=y_train_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    valid_lgb = lgb.Dataset(\n",
    "        data=X_valid_lgb,\n",
    "        label=y_valid_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "    \n",
    "    eval_lgb = lgb.Dataset(\n",
    "        data=X_valid[feat],\n",
    "        label=y_valid,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    test_lgb = lgb.Dataset(\n",
    "        data=X_test[feat],\n",
    "        label=y_test,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    balance = y_train_lgb[y_train_lgb==0].shape[0]/y_train_lgb[y_train_lgb==1].shape[0]\n",
    "\n",
    "    global PARAMS_PREV\n",
    "\n",
    "    def lgbm_callback(is_changing=False):\n",
    "\n",
    "        def callback(env):\n",
    "\n",
    "            global PARAMS_PREV\n",
    "\n",
    "            delta = .001\n",
    "            up = 20\n",
    "            down = 5\n",
    "\n",
    "            model_callback = env.model\n",
    "            roc_auc_callback = roc_auc_score(test_lgb.label, model_callback.predict(test_lgb.data))\n",
    "\n",
    "            #up each nth iteration\n",
    "            if (PARAMS_PREV['learning_rate'] + delta < .01) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] += delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE UP TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "            #down each nth iteration\n",
    "            elif (PARAMS_PREV['learning_rate'] - delta > .0001) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] -= delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE DOWN TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "        callback.before_iteration = True\n",
    "        callback.order = 0\n",
    "        return callback\n",
    "    \n",
    "    params = {\n",
    "    #Core Parameters\n",
    "        #'config': '',\n",
    "        'task': 'train',\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'goss',\n",
    "        #'data': '',\n",
    "        #'valid': '',\n",
    "        #num_iterations: 100000,\n",
    "        'learning_rate': .1,\n",
    "        'num_leaves': 115, #2^max_depth*70%\n",
    "        #'tree_learner': 'serial',\n",
    "        'num_threads': n_threads,\n",
    "        'device_type': 'cpu',\n",
    "        'seed': random_state,\n",
    "    #Learning Control Parameters\n",
    "        'max_depth': 14,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'min_sum_hessian_in_leaf': 1e-3,\n",
    "        #'bagging_fraction': .75,\n",
    "        #'bagging_freq': 2,\n",
    "        #'bagging_seed': random_state,\n",
    "        'feature_fraction': .75,\n",
    "        'feature_fraction_seed': random_state,\n",
    "        #'early_stopping_rounds': 100,\n",
    "        'max_delta_step': 0.0,\n",
    "        'lambda_l1': 28.4,\n",
    "        'lambda_l2': 28.4,\n",
    "        'min_gain_to_split': 0.0,\n",
    "        #'drop_rate': .1, #dart\n",
    "        #'max_dop': 50, #dart\n",
    "        #skip_drop': .5, #dart\n",
    "        #'xgboost_dart_mode': False, #dart\n",
    "        #'uniform_drop': False, #dart\n",
    "        #'drop_seed': random_state, #dart\n",
    "        'top_rate': .3, #goss\n",
    "        'oter_rate': .5, #goss\n",
    "        'min_data_per_group': 100,\n",
    "        'max_cat_threshold': 32,\n",
    "        'cat_l2': 10.0,\n",
    "        'cat_smooth': 10.0,\n",
    "        'max_cat_to_onehot': 4,\n",
    "        #'top_k': 20, #parallel\n",
    "        'monotone_constraints': None,\n",
    "        'feature_contri': None,\n",
    "        'forcedsplits_filename': '',\n",
    "        'refit_decay_rate': .9,\n",
    "    #IO Parameters\n",
    "        'verbosity': 1,\n",
    "        'max_bin': 129,\n",
    "        'min_data_in_bin': 3,\n",
    "        'bin_construct_sample_cnt': 200000,\n",
    "        'histogram_pool_size': -1.0,\n",
    "        'data_random_seed': random_state,\n",
    "        #'output_model': LightGBM_mode.txt, #model\n",
    "        'snapshot_freq': -1,\n",
    "        #'input_model': '', #model\n",
    "        #'output_result': LightGBM_predict_result.txt, #model\n",
    "        'initscore_filename': '',\n",
    "        'valid_data_initscores': '',\n",
    "        'pre_partition': False,\n",
    "        'enable_bundle': True,\n",
    "        'max_conflict_rate': 0.0,\n",
    "        'is_enable_sparse': True,\n",
    "        'sparse_threshold': .8,\n",
    "        'use_missing': True,\n",
    "        'zero_as_missing': False,\n",
    "        'two_round': False,\n",
    "        'save_binary': False,\n",
    "        'header': False,\n",
    "        'label_column': '',\n",
    "        'weight_column': '',\n",
    "        'group_column': '',\n",
    "        'ignore_column': '',\n",
    "        #'categorial_feature': '', #train\n",
    "        #'predict_raw_score': False, #predict\n",
    "        #'predict_leaf_index': False, #predict\n",
    "        #'predict_contrlib': False, #predict\n",
    "        #'num_iterations_predict': -1, #predict\n",
    "        #'pred_early_stop': False, #predict\n",
    "        #'pred_early_stop_freq': 10, #predict\n",
    "        #'pred_early_stop_margin': 10.0, #predict\n",
    "        #'convert_model_language': '', #convert_model\n",
    "        #'convert_model': 'gbdt_prediction_cpp', #convert_model\n",
    "    #Objective Parameters\n",
    "        #'num_class': 1, #multi_class\n",
    "        'is_unbalance': False, #binary\n",
    "        'scale_pos_weight': balance, #binary\n",
    "        'sigmoid': .775, #binary\n",
    "        'boost_from_average': True,\n",
    "        'reg_sqrt': False,\n",
    "        'alpha': .9,\n",
    "        'fair_c': 1.0,\n",
    "        'poisson_max_delta_step': .7,\n",
    "        'tweedie_variance_power': 1.5,\n",
    "        #'max_position': 20, #lambdarank\n",
    "        #'label_gain': 0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "    #Metric Parameters\n",
    "        'metric': 'auc',\n",
    "        'metric_freq': 1,\n",
    "        'is_provide_training_metric': False,\n",
    "    #Network Parameters\n",
    "        'num_machines': 1,\n",
    "        'local_listen_port': 12400,\n",
    "        'time_out': 120,\n",
    "        'machine_list_filename': '',\n",
    "        'machines': '',\n",
    "    #GPU Parameters\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'gpu_use_dp': True\n",
    "    }\n",
    "\n",
    "    PARAMS_PREV = {'learning_rate': params['learning_rate']}\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=train_lgb,\n",
    "        num_boost_round=10,\n",
    "        valid_sets=[train_lgb, valid_lgb],\n",
    "        valid_names=None,\n",
    "        fobj=None,\n",
    "        feval=None,\n",
    "        init_model=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        early_stopping_rounds=3,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        learning_rates=None,\n",
    "        keep_training_booster=False,\n",
    "        callbacks=None #[lgbm_callback(False)] it's so slow cause auc metric is not easy to calculate\n",
    "    )\n",
    "\n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict(\n",
    "            data=eval_lgb.data,\n",
    "            num_iteration=model.best_iteration,\n",
    "            raw_score=False,\n",
    "            pred_leaf=False,\n",
    "            pred_contrib=False,\n",
    "            data_has_header=False,\n",
    "            is_reshape=True,\n",
    "            pred_parameter=None\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            'MODEL LGBM',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(eval_lgb.label, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict(\n",
    "        data=test_lgb.data,\n",
    "        num_iteration=model.best_iteration,\n",
    "        raw_score=False,\n",
    "        pred_leaf=False,\n",
    "        pred_contrib=False,\n",
    "        data_has_header=False,\n",
    "        is_reshape=True,\n",
    "        pred_parameter=None\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        'MODEL LGBM',\n",
    "        '\\nROC AUC test_score:',\n",
    "        roc_auc_score(test_lgb.label, y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Finding the best params dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "model = lgb.LGBMModel(\n",
    "    boosting_type='dart',\n",
    "    num_leaves=180,\n",
    "    max_depth=14,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=1000,\n",
    "    subsample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=.75,\n",
    "    subsample_freq=2,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    drop_rate=.1, #dart\n",
    "    max_dop=50, #dart\n",
    "    skip_drop=.5, #dart\n",
    "    xgboost_dart_mode=False, #dart\n",
    "    uniform_drop=False, #dart\n",
    "    drop_seed=random_state, #dart\n",
    "    #top_rate=.2, #goss\n",
    "    #oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature=, #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "#for using .predict_proba method\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type='dart',\n",
    "    num_leaves=180,\n",
    "    max_depth=14,\n",
    "    learning_rate=.1,\n",
    "    n_estimators=1000,\n",
    "    subsample_for_bin=2000000,\n",
    "    objective='binary',\n",
    "    class_weight=None,\n",
    "    min_split_gain=.0,\n",
    "    min_child_weight=.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=.75,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_threads,\n",
    "    silent=True,\n",
    "    ##**kwargs:\n",
    "#Core Parameters\n",
    "    #config=,\n",
    "    task='train',\n",
    "    #objective='regression',\n",
    "    #boosting='gbdt',\n",
    "    #data='',\n",
    "    #valid='',\n",
    "    #num_iterations=100000,\n",
    "    #learning_rate=.01,\n",
    "    #num_leaves=180, #2^max_depth*70%\n",
    "    #tree_learner=serial,\n",
    "    #num_threads=n_threads,\n",
    "    device_type='cpu',\n",
    "    #seed=random_state,\n",
    "#Learning Control Parameters\n",
    "    #max_depth=8,\n",
    "    #min_data_in_leaf=20,\n",
    "    #min_sum_hessian_in_leaf=1e-3,\n",
    "    #bagging_fraction=.75,\n",
    "    #bagging_freq=2,\n",
    "    bagging_seed=random_state,\n",
    "    #feature_fraction=.75,\n",
    "    feature_fraction_seed=random_state,\n",
    "    #early_stopping_rounds=100,\n",
    "    max_delta_step=0.0,\n",
    "    #lambda_l1=0.0,\n",
    "    #lambda_l2=0.0,\n",
    "    #min_gain_to_split=0.0,\n",
    "    drop_rate=.1, #dart\n",
    "    max_dop=50, #dart\n",
    "    skip_drop=.5, #dart\n",
    "    xgboost_dart_mode=False, #dart\n",
    "    uniform_drop=False, #dart\n",
    "    drop_seed=random_state, #dart\n",
    "    #top_rate=.2, #goss\n",
    "    #oter_rate=.1, #goss\n",
    "    min_data_per_group=100,\n",
    "    max_cat_threshold=32,\n",
    "    cat_l2=10.0,\n",
    "    cat_smooth=10.0,\n",
    "    max_cat_to_onehot=4,\n",
    "    #top_k=20, #parallel\n",
    "    monotone_constraints=None,\n",
    "    feature_contri=None,\n",
    "    forcedsplits_filename='',\n",
    "    refit_decay_rate=.9,\n",
    "#IO Parameters\n",
    "    verbosity=1,\n",
    "    max_bin=256,\n",
    "    min_data_in_bin=3,\n",
    "    bin_construct_sample_cnt=200000,\n",
    "    histogram_pool_size=-1.0,\n",
    "    data_random_seed=random_state,\n",
    "    #output_model=LightGBM_mode.txt, #model\n",
    "    snapshot_freq=-1,\n",
    "    #input_model=, #model\n",
    "    #output_result=LightGBM_predict_result.txt, #model\n",
    "    initscore_filename='',\n",
    "    valid_data_initscores='',\n",
    "    pre_partition=False,\n",
    "    enable_bundle=True,\n",
    "    max_conflict_rate=0.0,\n",
    "    is_enable_sparse=True,\n",
    "    sparse_threshold=.8,\n",
    "    use_missing=True,\n",
    "    zero_as_missing=False,\n",
    "    two_round=False,\n",
    "    save_binary=False,\n",
    "    header=False,\n",
    "    #label_column='',\n",
    "    #weight_column='',\n",
    "    #group_column='',\n",
    "    #ignore_column='',\n",
    "    #categorial_feature='', #train\n",
    "    #predict_raw_score=False, #predict\n",
    "    #predict_leaf_index=False, #predict\n",
    "    #predict_contrlib=False, #predict\n",
    "    #num_iterations_predict=-1, #predict\n",
    "    #pred_early_stop=False, #predict\n",
    "    #pred_early_stop_freq=10, #predict\n",
    "    #pred_early_stop_margin=10.0, #predict\n",
    "    #convert_model_language=, #convert_model\n",
    "    #convert_model=gbdt_prediction_cpp, #convert_model\n",
    "#Objective Parameters\n",
    "    #num_class=1, #multi_class\n",
    "    is_unbalance=False, #binary\n",
    "    scale_pos_weight=balance, #binary\n",
    "    #sigmoid=1.0, #binary\n",
    "    boost_from_average=True,\n",
    "    reg_sqrt=False,\n",
    "    alpha=.9,\n",
    "    fair_c=1.0,\n",
    "    poisson_max_delta_step=.7,\n",
    "    tweedie_variance_power=1.5,\n",
    "    #max_position=20, #lambdarank\n",
    "    #label_gain=0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "#Metric Parameters\n",
    "    metric='auc',\n",
    "    metric_freq=1,\n",
    "    is_provide_training_metric=False,\n",
    "#Network Parameters\n",
    "    num_machines=1,\n",
    "    local_listen_port=12400,\n",
    "    time_out=120,\n",
    "    machine_list_filename='',\n",
    "    machines='',\n",
    "#GPU Parameters\n",
    "    gpu_platform_id=0,\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=True\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['dart'],\n",
    "    'learning_rate': [float(x) for x in np.linspace(start=.1, stop=.1, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=1000, stop=1000, num=1)],\n",
    "    'max_depth': [int(x) for x in np.linspace(start=14, stop=14, num=1)],\n",
    "    #'num_leaves': [int(np.power(2, x)*.7) for x in np.linspace(start=3, stop=3, num=1)],\n",
    "    'num_leaves': [int(x) for x in np.linspace(start=65000, stop=65000, num=1)],\n",
    "    'max_bin': [int(x) for x in np.linspace(start=3, stop=255, num=10)], #it will crash your python.exe if you start from 2\n",
    "    'lambda_l1': [float(x) for x in np.linspace(start=0, stop=256, num=10)],\n",
    "    'lambda_l2': [float(x) for x in np.linspace(start=0, stop=256, num=10)],\n",
    "    'scale_pos_weight': [float(x) for x in np.linspace(start=.1, stop=1., num=5)],\n",
    "    'sigmoid': [float(x) for x in np.linspace(start=.1, stop=1., num=5)],\n",
    "    'drop_rate': [float(x) for x in np.linspace(start=.1, stop=1.0, num=5)], #dart\n",
    "    'max_drop': [int(x) for x in np.linspace(start=0, stop=256, num=5)] + [-1], #dart\n",
    "    'skip_drop': [float(x) for x in np.linspace(start=.1, stop=1.0, num=5)], #dart\n",
    "    'xgboost_dart_mode': [True, False], #dart\n",
    "    'uniform_drop': [True, False] #dart\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=train_lgb.data,\n",
    "    y=train_lgb.get_label(),\n",
    "    sample_weight=None,\n",
    "    init_score=None,\n",
    "    #group=None, #LGBMModel\n",
    "    eval_set=[(train_lgb.data, train_lgb.get_label()), (valid_lgb.data, valid_lgb.get_label())],\n",
    "    eval_names=None,\n",
    "    eval_sample_weight=None,\n",
    "    eval_class_weight=None,\n",
    "    eval_init_score=None,\n",
    "    #eval_group=None, #LGBMModel\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=1000,\n",
    "    #feature_name=feat, #for not lgbm dataset\n",
    "    #categorical_feature=cat_feat, #for not lgbm dataset\n",
    "    callbacks=None\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    X=test_lgb.data,\n",
    "    raw_score=False,\n",
    "    num_iteration=train_grid.best_estimator_.best_iteration_,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=False\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_lgb.label, y_pred)\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 Final model dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:00:01.982703Z",
     "start_time": "2019-04-25T19:00:01.960762Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_LGBM_C_DART(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, cat_feat, random_state):\n",
    "    \n",
    "    #X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = \\\n",
    "    #    X_train.iloc[:int(X_train.shape[0]*.75)][feat], \\\n",
    "    #    X_train.iloc[int(X_train.shape[0]*.75):][feat], \\\n",
    "    #    y_train[:int(y_train.shape[0]*.75)], \\\n",
    "    #    y_train[int(y_train.shape[0]*.75):]\n",
    "    \n",
    "    X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        test_size=.25,\n",
    "        random_state=random_state,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    train_lgb = lgb.Dataset(\n",
    "        data=X_train_lgb,\n",
    "        label=y_train_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    valid_lgb = lgb.Dataset(\n",
    "        data=X_valid_lgb,\n",
    "        label=y_valid_lgb,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "    \n",
    "    eval_lgb = lgb.Dataset(\n",
    "        data=X_valid[feat],\n",
    "        label=y_valid,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    test_lgb = lgb.Dataset(\n",
    "        data=X_test[feat],\n",
    "        label=y_test,\n",
    "        reference=None,\n",
    "        weight=None,\n",
    "        group=None,\n",
    "        init_score=None,\n",
    "        silent=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        params=None,\n",
    "        free_raw_data=True\n",
    "    )\n",
    "\n",
    "    balance = y_train_lgb[y_train_lgb==0].shape[0]/y_train_lgb[y_train_lgb==1].shape[0]\n",
    "\n",
    "    global PARAMS_PREV\n",
    "\n",
    "    def lgbm_callback(is_changing=False):\n",
    "\n",
    "        def callback(env):\n",
    "\n",
    "            global PARAMS_PREV\n",
    "\n",
    "            delta = .001\n",
    "            up = 20\n",
    "            down = 5\n",
    "\n",
    "            model_callback = env.model\n",
    "            roc_auc_callback = roc_auc_score(test_lgb.label, model_callback.predict(test_lgb.data))\n",
    "\n",
    "            #up each nth iteration\n",
    "            if (PARAMS_PREV['learning_rate'] + delta < .01) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] += delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE UP TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "            #down each nth iteration\n",
    "            elif (PARAMS_PREV['learning_rate'] - delta > .0001) & \\\n",
    "                                    (env.iteration % up == 0) & \\\n",
    "                                    (env.iteration > 0) & \\\n",
    "                                    (is_changing == True):\n",
    "\n",
    "                PARAMS_PREV['learning_rate'] -= delta\n",
    "\n",
    "                print(\n",
    "                    '\\nRESET LEARNING RATE DOWN TO:',\n",
    "                      PARAMS_PREV['learning_rate']\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                   'ITERATION:',\n",
    "                    env.model.current_iteration(),\n",
    "                    'ROC AUC:',\n",
    "                    roc_auc_callback\n",
    "                )\n",
    "\n",
    "        callback.before_iteration = True\n",
    "        callback.order = 0\n",
    "        return callback\n",
    "    \n",
    "    params = {\n",
    "    #Core Parameters\n",
    "        #'config': '',\n",
    "        'task': 'train',\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'dart',\n",
    "        #'data': '',\n",
    "        #'valid': '',\n",
    "        #num_iterations: 100000,\n",
    "        'learning_rate': .1,\n",
    "        'num_leaves': 115, #2^max_depth*70%\n",
    "        #'tree_learner': 'serial',\n",
    "        'num_threads': n_threads,\n",
    "        'device_type': 'cpu',\n",
    "        'seed': random_state,\n",
    "    #Learning Control Parameters\n",
    "        'max_depth': 14,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'min_sum_hessian_in_leaf': 1e-3,\n",
    "        #'bagging_fraction': .75,\n",
    "        #'bagging_freq': 2,\n",
    "        #'bagging_seed': random_state,\n",
    "        'feature_fraction': .75,\n",
    "        'feature_fraction_seed': random_state,\n",
    "        #'early_stopping_rounds': 100,\n",
    "        'max_delta_step': 0.0,\n",
    "        'lambda_l1': 28.4,\n",
    "        'lambda_l2': 28.4,\n",
    "        'min_gain_to_split': 0.0,\n",
    "        'drop_rate': .1, #dart\n",
    "        'max_dop': 50, #dart\n",
    "        'skip_drop': .5, #dart\n",
    "        'xgboost_dart_mode': False, #dart\n",
    "        'uniform_drop': False, #dart\n",
    "        'drop_seed': random_state, #dart\n",
    "        'top_rate': .3, #goss\n",
    "        'oter_rate': .5, #goss\n",
    "        'min_data_per_group': 100,\n",
    "        'max_cat_threshold': 32,\n",
    "        'cat_l2': 10.0,\n",
    "        'cat_smooth': 10.0,\n",
    "        'max_cat_to_onehot': 4,\n",
    "        #'top_k': 20, #parallel\n",
    "        'monotone_constraints': None,\n",
    "        'feature_contri': None,\n",
    "        'forcedsplits_filename': '',\n",
    "        'refit_decay_rate': .9,\n",
    "    #IO Parameters\n",
    "        'verbosity': 1,\n",
    "        'max_bin': 129,\n",
    "        'min_data_in_bin': 3,\n",
    "        'bin_construct_sample_cnt': 200000,\n",
    "        'histogram_pool_size': -1.0,\n",
    "        'data_random_seed': random_state,\n",
    "        #'output_model': LightGBM_mode.txt, #model\n",
    "        'snapshot_freq': -1,\n",
    "        #'input_model': '', #model\n",
    "        #'output_result': LightGBM_predict_result.txt, #model\n",
    "        'initscore_filename': '',\n",
    "        'valid_data_initscores': '',\n",
    "        'pre_partition': False,\n",
    "        'enable_bundle': True,\n",
    "        'max_conflict_rate': 0.0,\n",
    "        'is_enable_sparse': True,\n",
    "        'sparse_threshold': .8,\n",
    "        'use_missing': True,\n",
    "        'zero_as_missing': False,\n",
    "        'two_round': False,\n",
    "        'save_binary': False,\n",
    "        'header': False,\n",
    "        'label_column': '',\n",
    "        'weight_column': '',\n",
    "        'group_column': '',\n",
    "        'ignore_column': '',\n",
    "        #'categorial_feature': '', #train\n",
    "        #'predict_raw_score': False, #predict\n",
    "        #'predict_leaf_index': False, #predict\n",
    "        #'predict_contrlib': False, #predict\n",
    "        #'num_iterations_predict': -1, #predict\n",
    "        #'pred_early_stop': False, #predict\n",
    "        #'pred_early_stop_freq': 10, #predict\n",
    "        #'pred_early_stop_margin': 10.0, #predict\n",
    "        #'convert_model_language': '', #convert_model\n",
    "        #'convert_model': 'gbdt_prediction_cpp', #convert_model\n",
    "    #Objective Parameters\n",
    "        #'num_class': 1, #multi_class\n",
    "        'is_unbalance': False, #binary\n",
    "        'scale_pos_weight': balance, #binary\n",
    "        'sigmoid': .775, #binary\n",
    "        'boost_from_average': True,\n",
    "        'reg_sqrt': False,\n",
    "        'alpha': .9,\n",
    "        'fair_c': 1.0,\n",
    "        'poisson_max_delta_step': .7,\n",
    "        'tweedie_variance_power': 1.5,\n",
    "        #'max_position': 20, #lambdarank\n",
    "        #'label_gain': 0,1,3,7,15,31,63,...,2^30-1, #lambdarank\n",
    "    #Metric Parameters\n",
    "        'metric': 'auc',\n",
    "        'metric_freq': 1,\n",
    "        'is_provide_training_metric': False,\n",
    "    #Network Parameters\n",
    "        'num_machines': 1,\n",
    "        'local_listen_port': 12400,\n",
    "        'time_out': 120,\n",
    "        'machine_list_filename': '',\n",
    "        'machines': '',\n",
    "    #GPU Parameters\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'gpu_use_dp': True\n",
    "    }\n",
    "\n",
    "    PARAMS_PREV = {'learning_rate': params['learning_rate']}\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=train_lgb,\n",
    "        num_boost_round=10,\n",
    "        valid_sets=[train_lgb, valid_lgb],\n",
    "        valid_names=None,\n",
    "        fobj=None,\n",
    "        feval=None,\n",
    "        init_model=None,\n",
    "        feature_name=feat,\n",
    "        categorical_feature=cat_feat,\n",
    "        #early_stopping_rounds=.,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        learning_rates=None,\n",
    "        keep_training_booster=False,\n",
    "        callbacks=None #[lgbm_callback(False)] it's so slow cause auc metric is not easy to calculate\n",
    "    )\n",
    "\n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict(\n",
    "            data=eval_lgb.data,\n",
    "            num_iteration=model.best_iteration,\n",
    "            raw_score=False,\n",
    "            pred_leaf=False,\n",
    "            pred_contrib=False,\n",
    "            data_has_header=False,\n",
    "            is_reshape=True,\n",
    "            pred_parameter=None\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            'MODEL LGBM',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(eval_lgb.label, y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict(\n",
    "        data=test_lgb.data,\n",
    "        num_iteration=model.best_iteration,\n",
    "        raw_score=False,\n",
    "        pred_leaf=False,\n",
    "        pred_contrib=False,\n",
    "        data_has_header=False,\n",
    "        is_reshape=True,\n",
    "        pred_parameter=None\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        'MODEL LGBM',\n",
    "        '\\nROC AUC test_score:',\n",
    "        roc_auc_score(test_lgb.label, y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.0 Catboost datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T18:13:21.312175Z",
     "start_time": "2019-04-19T18:13:21.271284Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_ctbst, X_test_ctbst, y_train_ctbst, y_test_ctbst = train_test_split(\n",
    "    X_train[feat],\n",
    "    y_train,\n",
    "    test_size=.1,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "X_test_ctbst = X_test_ctbst[feat]\n",
    "\n",
    "X_train_ctbst, X_eval_ctbst, y_train_ctbst, y_eval_ctbst = train_test_split(\n",
    "    X_train_ctbst,\n",
    "    y_train_ctbst,\n",
    "    test_size=.25,\n",
    "    random_state=random_state,\n",
    "    stratify=y_train_ctbst\n",
    ")\n",
    "\n",
    "train_ctbst_full = ctbst.Pool(\n",
    "    data=X_train[feat],\n",
    "    label=y_train,\n",
    "    cat_features=cat_feat,\n",
    "    column_description=None,\n",
    "    pairs=None,\n",
    "    delimiter='\\t',\n",
    "    has_header=True,\n",
    "    weight=None,\n",
    "    group_id=None,\n",
    "    group_weight=None,\n",
    "    subgroup_id=None,\n",
    "    pairs_weight=None,\n",
    "    baseline=None,\n",
    "    feature_names=feat,\n",
    "    thread_count=n_threads\n",
    ")\n",
    "\n",
    "train_ctbst = ctbst.Pool(\n",
    "    data=X_train_ctbst,\n",
    "    label=y_train_ctbst,\n",
    "    cat_features=cat_feat,\n",
    "    column_description=None,\n",
    "    pairs=None,\n",
    "    delimiter='\\t',\n",
    "    has_header=True,\n",
    "    weight=None,\n",
    "    group_id=None,\n",
    "    group_weight=None,\n",
    "    subgroup_id=None,\n",
    "    pairs_weight=None,\n",
    "    baseline=None,\n",
    "    feature_names=feat,\n",
    "    thread_count=n_threads\n",
    ")\n",
    "\n",
    "eval_ctbst = ctbst.Pool(\n",
    "    data=X_eval_ctbst,\n",
    "    label=y_eval_ctbst,\n",
    "    cat_features=cat_feat,\n",
    "    column_description=None,\n",
    "    pairs=None,\n",
    "    delimiter='\\t',\n",
    "    has_header=True,\n",
    "    weight=None,\n",
    "    group_id=None,\n",
    "    group_weight=None,\n",
    "    subgroup_id=None,\n",
    "    pairs_weight=None,\n",
    "    baseline=None,\n",
    "    feature_names=feat,\n",
    "    thread_count=n_threads\n",
    ")\n",
    "\n",
    "test_ctbst = ctbst.Pool(\n",
    "    data=X_test_ctbst,\n",
    "    label=y_test_ctbst,\n",
    "    cat_features=cat_feat,\n",
    "    column_description=None,\n",
    "    pairs=None,\n",
    "    delimiter='\\t',\n",
    "    has_header=True,\n",
    "    weight=None,\n",
    "    group_id=None,\n",
    "    group_weight=None,\n",
    "    subgroup_id=None,\n",
    "    pairs_weight=None,\n",
    "    baseline=None,\n",
    "    feature_names=feat,\n",
    "    thread_count=n_threads\n",
    ")\n",
    "\n",
    "balance = y_train_ctbst[y_train_ctbst==0].shape[0]/y_train_ctbst[y_train_ctbst==1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 Finding the best one_hot_max_size and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T18:08:22.672223Z",
     "start_time": "2019-04-19T18:07:28.636112Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "ohmss = range(10, 250, 10)\n",
    "\n",
    "for ohms in tqdm_notebook(ohmss):\n",
    "    \n",
    "    model = ctbst.CatBoostClassifier(\n",
    "        iterations=10000,\n",
    "        learning_rate=.1,\n",
    "        depth=5,\n",
    "        l2_leaf_reg=3,\n",
    "        model_size_reg=.5,\n",
    "        #rsm=.75, #CPU\n",
    "        loss_function='Logloss',\n",
    "        border_count=254,\n",
    "        feature_border_type='GreedyLogSum',\n",
    "        input_borders=None,\n",
    "        output_borders=None,\n",
    "        fold_permutation_block=None,\n",
    "        #od_pval=.01, #IncToDec\n",
    "        od_wait=20,\n",
    "        od_type='Iter',\n",
    "        nan_mode='Min',\n",
    "        counter_calc_method='Full',\n",
    "        leaf_estimation_iterations=100,\n",
    "        leaf_estimation_method='Gradient',\n",
    "        thread_count=n_threads,\n",
    "        random_seed=random_state,\n",
    "        #use_best_model=True, #set in train\n",
    "        best_model_min_trees=None,\n",
    "        verbose=0,\n",
    "        #silent=None,\n",
    "        #logging_level='Silent',\n",
    "        metric_period=1,\n",
    "        ctr_leaf_count_limit=None,\n",
    "        store_all_simple_ctr=False,\n",
    "        max_ctr_complexity=4,\n",
    "        has_time=False,\n",
    "        allow_const_label=False,\n",
    "        #classes_count=None, #Multiclassification\n",
    "        #class_weights=1,\n",
    "        class_names=None,\n",
    "        one_hot_max_size=ohms,\n",
    "        random_strength=1,\n",
    "        name='experiment',\n",
    "        ignored_features=None,\n",
    "        train_dir='catboost_info',\n",
    "        custom_loss=None,\n",
    "        custom_metric=None,\n",
    "        eval_metric='AUC',\n",
    "        bagging_temperature=1,\n",
    "        save_snapshot=False,\n",
    "        snapshot_file='experiment.cbsnapshot',\n",
    "        #snapshot_interval=600,\n",
    "        fold_len_multiplier=2,\n",
    "        used_ram_limit=None,\n",
    "        gpu_ram_part=.95, #GPU\n",
    "        #pinned_memory_size=1073741824, #GPU\n",
    "        allow_writing_files=True,\n",
    "        final_ctr_computation_mode='Default',\n",
    "        approx_on_full_history=False,\n",
    "        boosting_type='Ordered', #GPU\n",
    "        #simple_ctr='Borders',\n",
    "        #combinations_ctr='Borders',\n",
    "        #per_feature_ctr='Borsers',\n",
    "        ctr_description=None,\n",
    "        ctr_target_border_count=None,\n",
    "        task_type='GPU',\n",
    "        device_config=None,\n",
    "        devices='0',\n",
    "        bootstrap_type='Bayesian',\n",
    "        #subsample=.66, #Poison or Bernulli\n",
    "        sampling_unit=None,\n",
    "        dev_score_calc_obj_block_size=None,\n",
    "        dev_efb_max_buckets=None,\n",
    "        efb_max_conflict_fraction=None,\n",
    "        #max_depth=None, #depth\n",
    "        #n_estimators=None, #iterations\n",
    "        #num_boost_round=None, #iterations\n",
    "        #num_trees=None, #iterations\n",
    "        #colsample_bylevel=None, #rsm\n",
    "        #random_state=random_state, #random_seed\n",
    "        #reg_lambda=None, #l2_leaf_reg\n",
    "        #objective=None, #loss_function\n",
    "        #eta=None, #learning_rate\n",
    "        #max_bin=None, #border_count\n",
    "        scale_pos_weight=balance,\n",
    "        gpu_cat_features_storage='GpuRam', #GPU\n",
    "        data_partition='FeatureParallel', #GPU\n",
    "        metadata=None,\n",
    "        #early_stopping_rounds=3000, #set in train\n",
    "        #cat_features=cat_feat, #set in train\n",
    "        grow_policy='SymmetricTree', #GPU\n",
    "        min_data_in_leaf=1,\n",
    "        #max_leaves=31, #lossguide\n",
    "        score_function='Correlation', #GPU\n",
    "        leaf_estimation_backtracking='AnyImprovement',\n",
    "        ctr_history_unit=None\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=train_ctbst,\n",
    "        #y=None, #for not Pool\n",
    "        #cat_features=cat_feat, #for not Pool\n",
    "        #sample_weight=None, #for not Pool\n",
    "        baseline=None,\n",
    "        use_best_model=True,\n",
    "        eval_set=[eval_ctbst], #[train_ctbst, eval_ctbst] #CPU\n",
    "        #verbose=True,\n",
    "        logging_level=None,\n",
    "        plot=False,\n",
    "        column_description=None,\n",
    "        verbose_eval=None,\n",
    "        metric_period=None,\n",
    "        silent=None,\n",
    "        early_stopping_rounds=3000,\n",
    "        save_snapshot=None,\n",
    "        snapshot_file=None,\n",
    "        snapshot_interval=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict(\n",
    "        data=train_ctbst,\n",
    "        prediction_type='Probability',\n",
    "        ntree_start=0,\n",
    "        ntree_end=model.best_iteration_,\n",
    "        thread_count=n_threads,\n",
    "        verbose=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = y_pred_train[:, 1]\n",
    "    \n",
    "    y_pred_test = model.predict(\n",
    "        data=test_ctbst,\n",
    "        prediction_type='Probability',\n",
    "        ntree_start=0,\n",
    "        ntree_end=model.best_iteration_,\n",
    "        thread_count=n_threads,\n",
    "        verbose=None\n",
    "    )\n",
    "    \n",
    "    y_pred_test = y_pred_test[:, 1]\n",
    "    \n",
    "    train_results.append(roc_auc_score(train_ctbst.get_label(), y_pred_train))\n",
    "    valid_results.append(roc_auc_score(test_ctbst.get_label(), y_pred_test))\n",
    "    \n",
    "plot_vc(\n",
    "    x=[ohms for d in ohmss],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='ohe_hot_max_size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T18:13:26.528800Z",
     "start_time": "2019-04-19T18:13:21.313172Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_results = []\n",
    "valid_results = []\n",
    "\n",
    "depths = range(1, 9, 1)\n",
    "\n",
    "for d in tqdm_notebook(depths):\n",
    "    \n",
    "    model = ctbst.CatBoostClassifier(\n",
    "        iterations=10,\n",
    "        learning_rate=.1,\n",
    "        depth=d,\n",
    "        l2_leaf_reg=3,\n",
    "        model_size_reg=.5,\n",
    "        #rsm=.75, #CPU\n",
    "        loss_function='Logloss',\n",
    "        border_count=254,\n",
    "        feature_border_type='GreedyLogSum',\n",
    "        input_borders=None,\n",
    "        output_borders=None,\n",
    "        fold_permutation_block=None,\n",
    "        #od_pval=.01, #IncToDec\n",
    "        od_wait=20,\n",
    "        od_type='Iter',\n",
    "        nan_mode='Min',\n",
    "        counter_calc_method='Full',\n",
    "        leaf_estimation_iterations=100,\n",
    "        leaf_estimation_method='Gradient',\n",
    "        thread_count=n_threads,\n",
    "        random_seed=random_state,\n",
    "        #use_best_model=True, #set in train\n",
    "        best_model_min_trees=None,\n",
    "        verbose=0,\n",
    "        #silent=None,\n",
    "        #logging_level='Silent',\n",
    "        metric_period=1,\n",
    "        ctr_leaf_count_limit=None,\n",
    "        store_all_simple_ctr=False,\n",
    "        max_ctr_complexity=4,\n",
    "        has_time=False,\n",
    "        allow_const_label=False,\n",
    "        #classes_count=None, #Multiclassification\n",
    "        #class_weights=1,\n",
    "        class_names=None,\n",
    "        one_hot_max_size=3,\n",
    "        random_strength=1,\n",
    "        name='experiment',\n",
    "        ignored_features=None,\n",
    "        train_dir='catboost_info',\n",
    "        custom_loss=None,\n",
    "        custom_metric=None,\n",
    "        eval_metric='AUC',\n",
    "        bagging_temperature=1,\n",
    "        save_snapshot=False,\n",
    "        snapshot_file='experiment.cbsnapshot',\n",
    "        #snapshot_interval=600,\n",
    "        fold_len_multiplier=2,\n",
    "        used_ram_limit=None,\n",
    "        gpu_ram_part=.95, #GPU\n",
    "        #pinned_memory_size=1073741824, #GPU\n",
    "        allow_writing_files=True,\n",
    "        final_ctr_computation_mode='Default',\n",
    "        approx_on_full_history=False,\n",
    "        boosting_type='Ordered', #GPU\n",
    "        #simple_ctr='Borders',\n",
    "        #combinations_ctr='Borders',\n",
    "        #per_feature_ctr='Borsers',\n",
    "        ctr_description=None,\n",
    "        ctr_target_border_count=None,\n",
    "        task_type='GPU',\n",
    "        device_config=None,\n",
    "        devices='0',\n",
    "        bootstrap_type='Bayesian',\n",
    "        #subsample=.66, #Poison or Bernulli\n",
    "        sampling_unit=None,\n",
    "        dev_score_calc_obj_block_size=None,\n",
    "        dev_efb_max_buckets=None,\n",
    "        efb_max_conflict_fraction=None,\n",
    "        #max_depth=None, #depth\n",
    "        #n_estimators=None, #iterations\n",
    "        #num_boost_round=None, #iterations\n",
    "        #num_trees=None, #iterations\n",
    "        #colsample_bylevel=None, #rsm\n",
    "        #random_state=random_state, #random_seed\n",
    "        #reg_lambda=None, #l2_leaf_reg\n",
    "        #objective=None, #loss_function\n",
    "        #eta=None, #learning_rate\n",
    "        #max_bin=None, #border_count\n",
    "        scale_pos_weight=balance,\n",
    "        gpu_cat_features_storage='GpuRam', #GPU\n",
    "        data_partition='FeatureParallel', #GPU\n",
    "        metadata=None,\n",
    "        #early_stopping_rounds=3000, #set in train\n",
    "        #cat_features=cat_feat, #set in train\n",
    "        grow_policy='SymmetricTree', #GPU\n",
    "        min_data_in_leaf=1,\n",
    "        #max_leaves=31, #lossguide\n",
    "        score_function='Correlation', #GPU\n",
    "        leaf_estimation_backtracking='AnyImprovement',\n",
    "        ctr_history_unit=None\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=train_ctbst,\n",
    "        #y=None, #for not Pool\n",
    "        #cat_features=cat_feat, #for not Pool\n",
    "        #sample_weight=None, #for not Pool\n",
    "        baseline=None,\n",
    "        use_best_model=True,\n",
    "        eval_set=[eval_ctbst], #[train_ctbst, eval_ctbst] #CPU\n",
    "        #verbose=True,\n",
    "        logging_level=None,\n",
    "        plot=False,\n",
    "        column_description=None,\n",
    "        verbose_eval=None,\n",
    "        metric_period=None,\n",
    "        silent=None,\n",
    "        early_stopping_rounds=3000,\n",
    "        save_snapshot=None,\n",
    "        snapshot_file=None,\n",
    "        snapshot_interval=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = model.predict(\n",
    "        data=train_ctbst,\n",
    "        prediction_type='Probability',\n",
    "        ntree_start=0,\n",
    "        ntree_end=model.best_iteration_,\n",
    "        thread_count=n_threads,\n",
    "        verbose=None\n",
    "    )\n",
    "\n",
    "    y_pred_train = y_pred_train[:, 1]\n",
    "    \n",
    "    y_pred_test = model.predict(\n",
    "        data=test_ctbst,\n",
    "        prediction_type='Probability',\n",
    "        ntree_start=0,\n",
    "        ntree_end=model.best_iteration_,\n",
    "        thread_count=n_threads,\n",
    "        verbose=None\n",
    "    )\n",
    "    \n",
    "    y_pred_test = y_pred_test[:, 1]\n",
    "    \n",
    "    train_results.append(roc_auc_score(train_ctbst.get_label(), y_pred_train))\n",
    "    valid_results.append(roc_auc_score(test_ctbst.get_label(), y_pred_test))\n",
    "    \n",
    "plot_vc(\n",
    "    x=[d for d in depths],\n",
    "    y_train=train_results,\n",
    "    y_valid=valid_results,\n",
    "    xlabel='DEPTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 Model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T20:43:46.798018Z",
     "start_time": "2019-04-19T20:43:42.398783Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "params_cpu = {\n",
    "#Common parameters\n",
    "    'loss_function': 'Logloss',\n",
    "    #'custom_metric': None,\n",
    "    'eval_metric': 'AUC',\n",
    "    'iterations': 10,\n",
    "    'learning_rate': .1,\n",
    "    'random_seed': random_state,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'bagging_temperature': 1,\n",
    "    #'subsample': .66, #Poison or Bernulli\n",
    "    'sampling_frequency': 'PerTreeLevel', #CPU\n",
    "    'random_strength': 1,\n",
    "    'use_best_model': True,\n",
    "    #'best_model_min_trees': None, #set in train\n",
    "    'depth': 8,\n",
    "    'ignored_features': [],\n",
    "    'one_hot_max_size': 2,\n",
    "    'has_time': False,\n",
    "    'rsm': .75, #CPU\n",
    "    'nan_mode': 'Min',\n",
    "    #'fold_permutation_block_size': 1,\n",
    "    'leaf_estimation_iterations': 100,\n",
    "    'leaf_estimation_method': 'Gradient',\n",
    "    'fold_len_multiplier': 2,\n",
    "    'approx_on_full_history': False,\n",
    "    #'class_weights': 1, #LogLoss\n",
    "    'scale_pos_weight': balance, #LogLoss\n",
    "    #'boosting_type': 'Ordered', #GPU\n",
    "    'allow_const_label': False,\n",
    "#Overfitting detection settings\n",
    "    'od_type': 'Iter',\n",
    "    #'od_pval': .01, #IncToDec\n",
    "    'od_wait': 20,\n",
    "    #'early_stopping_rounds': True,\n",
    "#Binarization settings\n",
    "    'border_count': 254,\n",
    "    'feature_border_type': 'GreedyLogSum',\n",
    "#Multiclassification settings\n",
    "    #'classes_count': None, #Multiclassification\n",
    "#Performance settings\n",
    "    'thread_count': n_threads,\n",
    "    'used_ram_limit': None,\n",
    "    'gpu_ram_part': .95, #GPU\n",
    "    'pinned_memory_size': 1073741824, #GPU\n",
    "    'gpu_cat_features_storage': 'GpuRam', #GPU\n",
    "    'data_partition': 'FeatureParallel', #GPU\n",
    "#Processing unit settings\n",
    "    'task_type': 'CPU',\n",
    "    'devices': '0',\n",
    "#Visualization settings\n",
    "    'name': 'experiment',\n",
    "#Output settings\n",
    "    'logging_level': 'Silent',\n",
    "    'metric_period': 1,\n",
    "    #'verbose': 1,\n",
    "    'train_dir': 'catboost_info',\n",
    "    'model_size_reg': .5,\n",
    "    'allow_writing_files': True,\n",
    "    'save_snapshot': False,\n",
    "    'snapshot_file': 'experiment.cbsnapshot',\n",
    "    #'snapshot_interval': 600,\n",
    "    #'roc_file': None,\n",
    "#CTR settings\n",
    "    #'simple_ctr': 'Borders',\n",
    "    #'combinations_ctr': 'Borders',\n",
    "    #'per_feature_ctr': 'Borsers',\n",
    "    'counter_calc_method': 'Full',\n",
    "    'max_ctr_complexity': 4,\n",
    "    #'ctr_leaf_count_limit': None,\n",
    "    'store_all_simple_ctr': False,\n",
    "    'final_ctr_computation_mode': 'Default'\n",
    "}\n",
    "\n",
    "params_gpu = {\n",
    "#Common parameters\n",
    "    'loss_function': 'Logloss',\n",
    "    #'custom_metric': None,\n",
    "    'eval_metric': 'AUC',\n",
    "    'iterations': 10,\n",
    "    'learning_rate': .1,\n",
    "    'random_seed': random_state,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'bagging_temperature': 1,\n",
    "    #'subsample': .66, #Poison or Bernulli\n",
    "    #'sampling_frequency': 'PerTreeLevel', #CPU\n",
    "    'random_strength': 1,\n",
    "    'use_best_model': True,\n",
    "    #'best_model_min_trees': None, #set in train\n",
    "    'depth': 8,\n",
    "    'ignored_features': [],\n",
    "    'one_hot_max_size': 2,\n",
    "    'has_time': False,\n",
    "    #'rsm': .75, #CPU\n",
    "    'nan_mode': 'Min',\n",
    "    #'fold_permutation_block_size': 1,\n",
    "    'leaf_estimation_iterations': 100,\n",
    "    'leaf_estimation_method': 'Gradient',\n",
    "    'fold_len_multiplier': 2,\n",
    "    'approx_on_full_history': False,\n",
    "    #'class_weights': 1, #LogLoss\n",
    "    'scale_pos_weight': balance, #LogLoss\n",
    "    'boosting_type': 'Ordered', #GPU\n",
    "    'allow_const_label': False,\n",
    "#Overfitting detection settings\n",
    "    'od_type': 'Iter',\n",
    "    #'od_pval': .01, #IncToDec\n",
    "    'od_wait': 20,\n",
    "    #'early_stopping_rounds': True,\n",
    "#Binarization settings\n",
    "    'border_count': 254,\n",
    "    'feature_border_type': 'GreedyLogSum',\n",
    "#Multiclassification settings\n",
    "    #'classes_count': None, #Multiclassification\n",
    "#Performance settings\n",
    "    'thread_count': n_threads,\n",
    "    'used_ram_limit': None,\n",
    "    'gpu_ram_part': .95, #GPU\n",
    "    #'pinned_memory_size': 1073741824, #GPU\n",
    "    'gpu_cat_features_storage': 'GpuRam', #GPU\n",
    "    'data_partition': 'FeatureParallel', #GPU\n",
    "#Processing unit settings\n",
    "    'task_type': 'GPU',\n",
    "    'devices': '0',\n",
    "#Visualization settings\n",
    "    'name': 'experiment',\n",
    "#Output settings\n",
    "    'logging_level': 'Silent',\n",
    "    'metric_period': 1,\n",
    "    #'verbose': 1,\n",
    "    'train_dir': 'catboost_info',\n",
    "    'model_size_reg': .5,\n",
    "    'allow_writing_files': True,\n",
    "    'save_snapshot': False,\n",
    "    'snapshot_file': 'experiment.cbsnapshot',\n",
    "    #'snapshot_interval': 600,\n",
    "    #'roc_file': None,\n",
    "#CTR settings\n",
    "    #'simple_ctr': 'Borders',\n",
    "    #'combinations_ctr': 'Borders',\n",
    "    #'per_feature_ctr': 'Borsers',\n",
    "    'counter_calc_method': 'Full',\n",
    "    'max_ctr_complexity': 4,\n",
    "    #'ctr_leaf_count_limit': None,\n",
    "    'store_all_simple_ctr': False,\n",
    "    'final_ctr_computation_mode': 'Default'\n",
    "}\n",
    "\n",
    "#model = ctbst.CatBoost(\n",
    "#    params=params_cpu\n",
    "#)\n",
    "\n",
    "#model.fit(\n",
    "#    X=train_ctbst,\n",
    "#    #y=y_train_ctbst, #for not pool dataset\n",
    "#    #cat_features=cat_feat, #fot not pool dataset\n",
    "#    pairs=None,\n",
    "#    #sample_weight=None, #fot not pool dataset\n",
    "#    #group_id=None, #fot not pool dataset\n",
    "#    #group_weight=None, #fot not pool dataset\n",
    "#    #subgroup_id=None, #fot not pool dataset\n",
    "#    #pairs_weight=None, #fot not pool dataset\n",
    "#    #baseline=None,\n",
    "#    use_best_model=True,\n",
    "#    eval_set=eval_ctbst,\n",
    "#    #verbose=True,\n",
    "#    #logging_level='Verbose',\n",
    "#    plot=True,\n",
    "#    column_description=None,\n",
    "#    verbose_eval=False, #500\n",
    "#    metric_period=None,\n",
    "#    #silent=False, #verbose eval is set\n",
    "#    early_stopping_rounds=100\n",
    "#)\n",
    "\n",
    "model = ctbst.train(\n",
    "    #dtrain\n",
    "    pool=train_ctbst,\n",
    "    params=params_gpu,\n",
    "    logging_level=None,\n",
    "    #verbose_eval\n",
    "    verbose=1000,\n",
    "    #num_boost_round=None, #get from params\n",
    "    #iterations=None=None, #get from params\n",
    "    #evals\n",
    "    eval_set=[eval_ctbst], #[train_ctbst, eval_ctbst], #CPU\n",
    "    plot=True,\n",
    "    metric_period=None,\n",
    "    early_stopping_rounds=3000,\n",
    "    save_snapshot=None,\n",
    "    snapshot_file=None,\n",
    "    snapshot_interval=None\n",
    ")\n",
    "\n",
    "y_pred = model.predict(\n",
    "    data=test_ctbst,\n",
    "    prediction_type='Probability',\n",
    "    ntree_start=0,\n",
    "    ntree_end=model.best_iteration_,\n",
    "    thread_count=n_threads,\n",
    "    verbose=None\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC score:',\n",
    "    roc_auc_score(test_ctbst.get_label(), y_pred),\n",
    ")\n",
    "\n",
    "plot_feat_imp(\n",
    "    feat=feat,\n",
    "    imp=model.get_feature_importance(),\n",
    "    n_feat=50\n",
    ")\n",
    "\n",
    "model.save_model(\n",
    "    fname='model_ctbst',\n",
    "    format='cbm',\n",
    "    export_parameters=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:21:04.869043Z",
     "start_time": "2019-04-19T17:20:45.837361Z"
    }
   },
   "outputs": [],
   "source": [
    "ctbst.cv(\n",
    "    #dtrain\n",
    "    pool=train_ctbst_full,\n",
    "    params=params_gpu,\n",
    "    #num_boost_round=None, #get from params\n",
    "    #iterations=None=None, #get from params\n",
    "    #nfold\n",
    "    fold_count=5,\n",
    "    inverted=False,\n",
    "    #seed\n",
    "    partition_random_seed=random_state,\n",
    "    shuffle=True,\n",
    "    logging_level=None,\n",
    "    stratified=False,\n",
    "    as_pandas=True,\n",
    "    metric_period=None,\n",
    "    #verbose_eval\n",
    "    plot=True,\n",
    "    early_stopping_rounds=3000,\n",
    "    save_snapshot=None,\n",
    "    snapshot_file=None,\n",
    "    snapshot_interval=None,\n",
    "    max_time_spent_on_fixed_cost_ratio=0.05,\n",
    "    dev_max_iterations_batch_size=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3 Finding the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T20:48:45.169904Z",
     "start_time": "2019-04-19T20:48:45.160928Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ctbst.CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=1,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3,\n",
    "    model_size_reg=.5,\n",
    "    #rsm=.75, #CPU\n",
    "    loss_function='Logloss',\n",
    "    border_count=254,\n",
    "    feature_border_type='GreedyLogSum',\n",
    "    input_borders=None,\n",
    "    output_borders=None,\n",
    "    fold_permutation_block=None,\n",
    "    #od_pval=.01, #IncToDec\n",
    "    od_wait=20,\n",
    "    od_type='Iter',\n",
    "    nan_mode='Min',\n",
    "    counter_calc_method='Full',\n",
    "    leaf_estimation_iterations=100,\n",
    "    leaf_estimation_method='Gradient',\n",
    "    thread_count=n_threads,\n",
    "    random_seed=random_state,\n",
    "    #use_best_model=True, #set in train\n",
    "    best_model_min_trees=None,\n",
    "    verbose=0,\n",
    "    #silent=None,\n",
    "    #logging_level='Silent',\n",
    "    metric_period=1,\n",
    "    ctr_leaf_count_limit=None,\n",
    "    store_all_simple_ctr=False,\n",
    "    max_ctr_complexity=4,\n",
    "    has_time=False,\n",
    "    allow_const_label=False,\n",
    "    #classes_count=None, #Multiclassification\n",
    "    #class_weights=1,\n",
    "    class_names=None,\n",
    "    one_hot_max_size=3,\n",
    "    random_strength=1,\n",
    "    name='experiment',\n",
    "    ignored_features=None,\n",
    "    train_dir='catboost_info',\n",
    "    custom_loss=None,\n",
    "    custom_metric=None,\n",
    "    eval_metric='AUC',\n",
    "    bagging_temperature=1,\n",
    "    save_snapshot=False,\n",
    "    snapshot_file='experiment.cbsnapshot',\n",
    "    #snapshot_interval=600,\n",
    "    fold_len_multiplier=2,\n",
    "    used_ram_limit=None,\n",
    "    gpu_ram_part=.95, #GPU\n",
    "    #pinned_memory_size=1073741824, #GPU\n",
    "    allow_writing_files=True,\n",
    "    final_ctr_computation_mode='Default',\n",
    "    approx_on_full_history=False,\n",
    "    #boosting_type='Ordered', #GPU\n",
    "    #simple_ctr='Borders',\n",
    "    #combinations_ctr='Borders',\n",
    "    #per_feature_ctr='Borsers',\n",
    "    ctr_description=None,\n",
    "    ctr_target_border_count=None,\n",
    "    task_type='CPU',\n",
    "    device_config=None,\n",
    "    devices='0',\n",
    "    bootstrap_type='Bayesian',\n",
    "    #subsample=.66, #Poison or Bernulli\n",
    "    sampling_unit=None,\n",
    "    dev_score_calc_obj_block_size=None,\n",
    "    dev_efb_max_buckets=None,\n",
    "    efb_max_conflict_fraction=None,\n",
    "    #max_depth=None, #depth\n",
    "    #n_estimators=None, #iterations\n",
    "    #num_boost_round=None, #iterations\n",
    "    #num_trees=None, #iterations\n",
    "    #colsample_bylevel=None, #rsm\n",
    "    #random_state=random_state, #random_seed\n",
    "    #reg_lambda=None, #l2_leaf_reg\n",
    "    #objective=None, #loss_function\n",
    "    #eta=None, #learning_rate\n",
    "    #max_bin=None, #border_count\n",
    "    scale_pos_weight=balance,\n",
    "    #gpu_cat_features_storage='GpuRam', #GPU\n",
    "    #data_partition='FeatureParallel', #GPU\n",
    "    metadata=None,\n",
    "    #early_stopping_rounds=3000, #set in train\n",
    "    #cat_features=cat_feat, #set in train\n",
    "    #grow_policy='SymmetricTree', #GPU\n",
    "    min_data_in_leaf=1,\n",
    "    #max_leaves=31, #lossguide\n",
    "    #score_function='Correlation', #GPU\n",
    "    leaf_estimation_backtracking='AnyImprovement',\n",
    "    ctr_history_unit=None\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [int(x) for x in np.linspace(start=1, stop=1, num=1)],\n",
    "}\n",
    "\n",
    "train_grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=n_threads,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=train_ctbst.get_features(),\n",
    "    y=train_ctbst.get_label()\n",
    ")\n",
    "\n",
    "train_grid.fit(\n",
    "    X=train_ctbst.get_features(),\n",
    "    y=train_ctbst.get_label(),\n",
    "    cat_features=cat_feat, #for not Pool\n",
    "    sample_weight=None, #for not Pool\n",
    "    baseline=None,\n",
    "    use_best_model=True,\n",
    "    eval_set=[(train_ctbst.get_features(), train_ctbst.get_label()), (eval_ctbst.get_features(), eval_ctbst.get_label())],\n",
    "    #verbose=True,\n",
    "    logging_level=None,\n",
    "    plot=False,\n",
    "    column_description=None,\n",
    "    verbose_eval=None,\n",
    "    metric_period=None,\n",
    "    silent=None,\n",
    "    early_stopping_rounds=3,\n",
    "    save_snapshot=None,\n",
    "    snapshot_file=None,\n",
    "    snapshot_interval=None\n",
    ")\n",
    "\n",
    "y_pred = train_grid.best_estimator_.predict_proba(\n",
    "    data=test_ctbst,\n",
    "    ntree_start=0,\n",
    "    ntree_end=train_grid.best_estimator_.best_iteration_,\n",
    "    thread_count=n_threads,\n",
    "    verbose=None\n",
    ")\n",
    "\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(\n",
    "    '\\n',\n",
    "    'ROC AUC:',\n",
    "    roc_auc_score(test_ctbst.get_label(), y_pred)\n",
    ")\n",
    "\n",
    "print(train_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:00:10.005249Z",
     "start_time": "2019-04-25T19:00:09.989292Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_CTBST_C(X_train, X_valid, X_test, y_train, y_valid, y_test, feat, cat_feat, random_state):\n",
    "    \n",
    "    #X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = \\\n",
    "    #    X_train.iloc[:int(X_train.shape[0]*.75)][feat], \\\n",
    "    #    X_train.iloc[int(X_train.shape[0]*.75):][feat], \\\n",
    "    #    y_train[:int(y_train.shape[0]*.75)], \\\n",
    "    #    y_train[int(y_train.shape[0]*.75):]\n",
    "    \n",
    "    X_train_ctbst, X_eval_ctbst, y_train_ctbst, y_eval_ctbst = train_test_split(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        test_size=.25,\n",
    "        random_state=random_state,\n",
    "        stratify=y_train\n",
    "    )\n",
    "    \n",
    "    train_ctbst = ctbst.Pool(\n",
    "        data=X_train_ctbst,\n",
    "        label=y_train_ctbst,\n",
    "        cat_features=cat_feat,\n",
    "        column_description=None,\n",
    "        pairs=None,\n",
    "        delimiter='\\t',\n",
    "        has_header=True,\n",
    "        weight=None,\n",
    "        group_id=None,\n",
    "        group_weight=None,\n",
    "        subgroup_id=None,\n",
    "        pairs_weight=None,\n",
    "        baseline=None,\n",
    "        feature_names=feat,\n",
    "        thread_count=n_threads\n",
    "    )\n",
    "\n",
    "    eval_ctbst = ctbst.Pool(\n",
    "        data=X_eval_ctbst,\n",
    "        label=y_eval_ctbst,\n",
    "        cat_features=cat_feat,\n",
    "        column_description=None,\n",
    "        pairs=None,\n",
    "        delimiter='\\t',\n",
    "        has_header=True,\n",
    "        weight=None,\n",
    "        group_id=None,\n",
    "        group_weight=None,\n",
    "        subgroup_id=None,\n",
    "        pairs_weight=None,\n",
    "        baseline=None,\n",
    "        feature_names=feat,\n",
    "        thread_count=n_threads\n",
    "    )\n",
    "    \n",
    "    valid_ctbst = ctbst.Pool(\n",
    "        data=X_valid[feat],\n",
    "        label=y_valid,\n",
    "        cat_features=cat_feat,\n",
    "        column_description=None,\n",
    "        pairs=None,\n",
    "        delimiter='\\t',\n",
    "        has_header=True,\n",
    "        weight=None,\n",
    "        group_id=None,\n",
    "        group_weight=None,\n",
    "        subgroup_id=None,\n",
    "        pairs_weight=None,\n",
    "        baseline=None,\n",
    "        feature_names=feat,\n",
    "        thread_count=n_threads\n",
    "    )\n",
    "\n",
    "    test_ctbst = ctbst.Pool(\n",
    "        data=X_test[feat],\n",
    "        label=y_test,\n",
    "        cat_features=cat_feat,\n",
    "        column_description=None,\n",
    "        pairs=None,\n",
    "        delimiter='\\t',\n",
    "        has_header=True,\n",
    "        weight=None,\n",
    "        group_id=None,\n",
    "        group_weight=None,\n",
    "        subgroup_id=None,\n",
    "        pairs_weight=None,\n",
    "        baseline=None,\n",
    "        feature_names=feat,\n",
    "        thread_count=n_threads\n",
    "    )\n",
    "\n",
    "    balance = y_train_ctbst[y_train_ctbst==0].shape[0]/y_train_ctbst[y_train_ctbst==1].shape[0]\n",
    "    \n",
    "    params = {\n",
    "    #Common parameters\n",
    "        'loss_function': 'Logloss',\n",
    "        #'custom_metric': None,\n",
    "        'eval_metric': 'AUC',\n",
    "        'iterations': 10,\n",
    "        'learning_rate': .1,\n",
    "        'random_seed': random_state,\n",
    "        'l2_leaf_reg': 3,\n",
    "        'bootstrap_type': 'Bayesian',\n",
    "        'bagging_temperature': 1,\n",
    "        #'subsample': .66, #Poison or Bernulli\n",
    "        #'sampling_frequency': 'PerTreeLevel', #CPU\n",
    "        'random_strength': 1,\n",
    "        'use_best_model': True,\n",
    "        #'best_model_min_trees': None, #set in train\n",
    "        'depth': 8,\n",
    "        'ignored_features': [],\n",
    "        'one_hot_max_size': 2,\n",
    "        'has_time': False,\n",
    "        #'rsm': .75, #CPU\n",
    "        'nan_mode': 'Min',\n",
    "        #'fold_permutation_block_size': 1,\n",
    "        'leaf_estimation_iterations': 100,\n",
    "        'leaf_estimation_method': 'Gradient',\n",
    "        'fold_len_multiplier': 2,\n",
    "        'approx_on_full_history': False,\n",
    "        #'class_weights': 1, #LogLoss\n",
    "        'scale_pos_weight': balance, #LogLoss\n",
    "        'boosting_type': 'Ordered', #GPU\n",
    "        'allow_const_label': False,\n",
    "    #Overfitting detection settings\n",
    "        'od_type': 'Iter',\n",
    "        #'od_pval': .01, #IncToDec\n",
    "        'od_wait': 20,\n",
    "        #'early_stopping_rounds': True,\n",
    "    #Binarization settings\n",
    "        'border_count': 254,\n",
    "        'feature_border_type': 'GreedyLogSum',\n",
    "    #Multiclassification settings\n",
    "        #'classes_count': None, #Multiclassification\n",
    "    #Performance settings\n",
    "        'thread_count': n_threads,\n",
    "        'used_ram_limit': None,\n",
    "        'gpu_ram_part': .95, #GPU\n",
    "        #'pinned_memory_size': 1073741824, #GPU\n",
    "        'gpu_cat_features_storage': 'GpuRam', #GPU\n",
    "        'data_partition': 'FeatureParallel', #GPU\n",
    "    #Processing unit settings\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0',\n",
    "    #Visualization settings\n",
    "        'name': 'experiment',\n",
    "    #Output settings\n",
    "        'logging_level': 'Silent',\n",
    "        'metric_period': 1,\n",
    "        #'verbose': 1,\n",
    "        'train_dir': 'catboost_info',\n",
    "        'model_size_reg': .5,\n",
    "        'allow_writing_files': True,\n",
    "        'save_snapshot': False,\n",
    "        'snapshot_file': 'experiment.cbsnapshot',\n",
    "        #'snapshot_interval': 600,\n",
    "        #'roc_file': None,\n",
    "    #CTR settings\n",
    "        #'simple_ctr': 'Borders',\n",
    "        #'combinations_ctr': 'Borders',\n",
    "        #'per_feature_ctr': 'Borsers',\n",
    "        'counter_calc_method': 'Full',\n",
    "        'max_ctr_complexity': 4,\n",
    "        #'ctr_leaf_count_limit': None,\n",
    "        'store_all_simple_ctr': False,\n",
    "        'final_ctr_computation_mode': 'Default'\n",
    "    }\n",
    "\n",
    "    #model = ctbst.CatBoost(\n",
    "    #    params=params_cpu\n",
    "    #)\n",
    "\n",
    "    #model.fit(\n",
    "    #    X=train_ctbst,\n",
    "    #    #y=y_train_ctbst, #for not pool dataset\n",
    "    #    #cat_features=cat_feat, #fot not pool dataset\n",
    "    #    pairs=None,\n",
    "    #    #sample_weight=None, #fot not pool dataset\n",
    "    #    #group_id=None, #fot not pool dataset\n",
    "    #    #group_weight=None, #fot not pool dataset\n",
    "    #    #subgroup_id=None, #fot not pool dataset\n",
    "    #    #pairs_weight=None, #fot not pool dataset\n",
    "    #    #baseline=None,\n",
    "    #    use_best_model=True,\n",
    "    #    eval_set=eval_ctbst,\n",
    "    #    #verbose=True,\n",
    "    #    #logging_level='Verbose',\n",
    "    #    plot=True,\n",
    "    #    column_description=None,\n",
    "    #    verbose_eval=False, #500\n",
    "    #    metric_period=None,\n",
    "    #    #silent=False, #verbose eval is set\n",
    "    #    early_stopping_rounds=100\n",
    "    #)\n",
    "\n",
    "    model = ctbst.train(\n",
    "        #dtrain\n",
    "        pool=train_ctbst,\n",
    "        params=params,\n",
    "        logging_level=None,\n",
    "        #verbose_eval\n",
    "        verbose=1000,\n",
    "        #num_boost_round=None, #get from params\n",
    "        #iterations=None=None, #get from params\n",
    "        #evals\n",
    "        eval_set=[eval_ctbst], #[train_ctbst, eval_ctbst], #CPU\n",
    "        plot=False,\n",
    "        metric_period=None,\n",
    "        early_stopping_rounds=3,\n",
    "        save_snapshot=None,\n",
    "        snapshot_file=None,\n",
    "        snapshot_interval=None\n",
    "    )\n",
    "    \n",
    "    if X_valid.shape[0] > 0 and y_valid.shape[0] > 0:\n",
    "        \n",
    "        y_valid_pred = model.predict(\n",
    "            data=valid_ctbst,\n",
    "            prediction_type='Probability',\n",
    "            ntree_start=0,\n",
    "            ntree_end=model.best_iteration_,\n",
    "            thread_count=n_threads,\n",
    "            verbose=None\n",
    "        )\n",
    "\n",
    "        y_valid_pred = y_valid_pred[:, 1]\n",
    "\n",
    "        print(\n",
    "            'MODEL LGBM',\n",
    "            '\\nROC AUC valid score:',\n",
    "            roc_auc_score(valid_ctbst.get_label(), y_valid_pred)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        y_valid_pred = np.nan\n",
    "        \n",
    "    y_test_pred = model.predict(\n",
    "        data=test_ctbst,\n",
    "        prediction_type='Probability',\n",
    "        ntree_start=0,\n",
    "        ntree_end=model.best_iteration_,\n",
    "        thread_count=n_threads,\n",
    "        verbose=None\n",
    "    )\n",
    "\n",
    "    y_test_pred = y_test_pred[:, 1]\n",
    "\n",
    "    print(\n",
    "        'MODEL CTBST',\n",
    "        '\\nROC_AUC:',\n",
    "        roc_auc_score(test_ctbst.get_label(), y_test_pred)\n",
    "    )\n",
    "\n",
    "    return y_valid_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Final calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:00:21.999174Z",
     "start_time": "2019-04-25T19:00:21.996181Z"
    }
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "folds = KFold(\n",
    "    n_splits=n_folds,\n",
    "    shuffle=True,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:00:26.760441Z",
     "start_time": "2019-04-25T19:00:25.078938Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_RFC,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        #cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='RFC'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_rfc = oof\n",
    "pred_rfc = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:15.100952Z",
     "start_time": "2019-04-25T19:01:13.414463Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_ETC,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        #cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='ETC'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_etc = oof\n",
    "pred_etc = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:18.495873Z",
     "start_time": "2019-04-25T19:01:17.102601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_XGBST_C_TREES,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='XGBST C TREES'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_xgbst_c = oof\n",
    "pred_xgbst_c = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:19.763484Z",
     "start_time": "2019-04-25T19:01:18.497868Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_LGBM_C_TREES,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='LGBM C TREES'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_lgbm_c_trees = oof\n",
    "pred_lgbm_c_trees = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:21.038075Z",
     "start_time": "2019-04-25T19:01:19.765478Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_LGBM_C_GOSS,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='LGBM C GOSS'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_lgbm_c_goss = oof\n",
    "pred_lgbm_c_goss = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:22.314661Z",
     "start_time": "2019-04-25T19:01:21.040070Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_LGBM_C_DART,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='LGBM C DART'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_lgbm_c_dart = oof\n",
    "pred_lgbm_c_dart = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:37.607763Z",
     "start_time": "2019-04-25T19:01:22.315658Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat].iloc[train_ind], X_train[feat].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_CTBST_C,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat,\n",
    "        cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='CATBOOST'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "    \n",
    "oof_ctbst_c = oof\n",
    "pred_ctbst_c = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:01:37.668600Z",
     "start_time": "2019-04-25T19:01:37.608761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train['pred_rfc'] = oof_rfc\n",
    "X_train['pred_etc'] = oof_etc\n",
    "X_train['pred_lgbm_c_trees'] = oof_lgbm_c_trees\n",
    "X_train['pred_lgbm_c_goss'] = oof_lgbm_c_goss\n",
    "X_train['pred_lgbm_c_dart'] = oof_lgbm_c_dart\n",
    "X_train['pred_ctbst_c'] = oof_ctbst_c\n",
    "\n",
    "X_test['pred_rfc'] = pred_rfc\n",
    "X_test['pred_etc'] = pred_etc\n",
    "X_test['pred_lgbm_c_trees'] = pred_lgbm_c_trees\n",
    "X_test['pred_lgbm_c_goss'] = pred_lgbm_c_goss\n",
    "X_test['pred_lgbm_c_dart'] = pred_lgbm_c_dart\n",
    "X_test['pred_ctbst_c'] = pred_ctbst_c\n",
    "\n",
    "feat_stack = [\n",
    "    'pred_rfc',\n",
    "    'pred_etc',\n",
    "    'pred_lgbm_c_trees',\n",
    "    'pred_lgbm_c_goss',\n",
    "    'pred_lgbm_c_dart',\n",
    "    'pred_ctbst_c'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:02:05.419213Z",
     "start_time": "2019-04-25T19:02:03.725743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(X_train.shape[0])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for f, (train_ind, valid_ind) in enumerate(folds.split(X_train, y_train)):\n",
    "    \n",
    "    print('\\nfold {}'.format(f))\n",
    "    \n",
    "    X_train_f, X_valid_f = X_train[feat + feat_stack].iloc[train_ind], X_train[feat + feat_stack].iloc[valid_ind]\n",
    "    y_train_f, y_valid_f = y_train.iloc[train_ind], y_train.iloc[valid_ind]\n",
    "\n",
    "    oof[valid_ind], pred = model_mean(\n",
    "        model=model_RFC,\n",
    "        X_train=X_train_f,\n",
    "        X_valid=X_valid_f,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train_f,\n",
    "        y_valid=y_valid_f,\n",
    "        y_test=y_test_fake,\n",
    "        feat=feat + feat_stack,\n",
    "        #cat_feat=cat_feat,\n",
    "        random_state=random_state,\n",
    "        samples=1,\n",
    "        info='RFC'\n",
    "    )\n",
    "    \n",
    "    preds += pred / n_folds\n",
    "\n",
    "oof = oof\n",
    "pred = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:02:42.998645Z",
     "start_time": "2019-04-25T19:02:42.942794Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_full = X_train[['ID_code']]\n",
    "\n",
    "X_train_full['y_pred'] = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:02:43.757615Z",
     "start_time": "2019-04-25T19:02:43.702777Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_full = X_test[['ID_code']]\n",
    "\n",
    "X_test_full['y_pred'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.  Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:02:58.789414Z",
     "start_time": "2019-04-25T19:02:58.734562Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_stack = []\n",
    "test_stack = []\n",
    "\n",
    "train_stack.append(X_train_full['y_pred'])\n",
    "test_stack.append(X_test_full['y_pred'])\n",
    "\n",
    "train_stack = np.vstack(train_stack).T\n",
    "test_stack = np.vstack(test_stack).T\n",
    "\n",
    "folds = KFold(\n",
    "    n_splits=20,\n",
    "    shuffle=True,\n",
    "    random_state=random_state\n",
    ")\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "pred_stack = np.zeros(test_stack.shape[0])\n",
    "\n",
    "#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, y_train)):\n",
    "for (trn_idx, val_idx) in tqdm_notebook(folds.split(train_stack, y_train)):\n",
    "    \n",
    "    #print('fold n{}'.format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], y_train.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], y_train.iloc[val_idx].values\n",
    "    \n",
    "    #print('-'*10 + 'Stacking' + str(fold_) + '-'*10)\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(\n",
    "        X=trn_data,\n",
    "        y=trn_y\n",
    "    )\n",
    "    \n",
    "    oof_stack[val_idx] = clf.predict(val_data)\n",
    "    #print('CV score fold:', roc_auc_score(y_train[val_idx], oof_stack[val_idx]))\n",
    "    \n",
    "    pred_stack += clf.predict(test_stack)/folds.n_splits\n",
    "    \n",
    "print('CV score summary:', roc_auc_score(y_train, oof_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:03:04.614837Z",
     "start_time": "2019-04-25T19:03:04.550011Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = X_test[['ID_code']]\n",
    "sub['target'] = pred_stack\n",
    "sub.to_csv(path + 'submission_mix.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:03:06.295343Z",
     "start_time": "2019-04-25T19:03:06.285370Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T19:03:29.668703Z",
     "start_time": "2019-04-25T19:03:29.645765Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv(path + 'submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "403.767px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
