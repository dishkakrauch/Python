{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "import lightgbm as lgb\n",
    "import catboost as ctbst\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import tensorflow\n",
    "KERAS_BACKEND=tensorflow\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.utils import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "from plotly.offline import *\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from pylab import *\n",
    "init_notebook_mode(connected=True)\n",
    "import shap\n",
    "from tqdm import *\n",
    "from IPython.display import *\n",
    "\n",
    "import threading as th\n",
    "import multiprocessing as mp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannot use seed cause python has function with the same name\n",
    "random_state = 1\n",
    "path = 'D:/Python/Kaggle/VSB/'\n",
    "n_threads = mp.cpu_count()-1 #th.active_count()\n",
    "\n",
    "# select how many folds will be created\n",
    "N_SPLITS = 10\n",
    "# it is just a constant with the measurements data size\n",
    "sample_size = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the official metric used in this competition\n",
    "# below is the declaration of a function used inside the keras model, calculation with K (keras backend / thensorflow)\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "0              0              0       0\n",
       "               1              1       0\n",
       "               2              2       0\n",
       "1              0              3       1\n",
       "               1              4       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just load train data\n",
    "df_train = pd.read_csv(path + 'metadata_train.csv')\n",
    "# set index, it makes the data access much faster\n",
    "df_train = df_train.set_index(['id_measurement', 'phase'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in other notebook I have extracted the min and max values from the train data, the measurements\n",
    "max_num = 127\n",
    "min_num = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function standardize the data from (-128 to 127) to (-1 to 1)\n",
    "# Theoretically it helps in the NN Model training, but I didn't tested without it\n",
    "def min_max_transf(ts, min_data, max_data, range_needed=(-1,1)):\n",
    "    if min_data < 0:\n",
    "        ts_std = (ts + abs(min_data)) / (max_data + abs(min_data))\n",
    "    else:\n",
    "        ts_std = (ts - min_data) / (max_data - min_data)\n",
    "    if range_needed[0] < 0:    \n",
    "        return ts_std * (range_needed[1] + abs(range_needed[0])) + range_needed[0]\n",
    "    else:\n",
    "        return ts_std * (range_needed[1] - range_needed[0]) + range_needed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one of the most important peace of code of this Kernel\n",
    "# Any power line contain 3 phases of 800000 measurements, or 2.4 millions data \n",
    "# It would be praticaly impossible to build a NN with an input of that size\n",
    "# The ideia here is to reduce it each phase to a matrix of <n_dim> bins by n features\n",
    "# Each bin is a set of 5000 measurements (800000 / 160), so the features are extracted from this 5000 chunk data.\n",
    "def transform_ts(ts, n_dim=160, min_max=(-1,1)):\n",
    "    # convert data into -1 to 1\n",
    "    ts_std = min_max_transf(ts, min_data=min_num, max_data=max_num)\n",
    "    # bucket or chunk size, 5000 in this case (800000 / 160)\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    # new_ts will be the container of the new data\n",
    "    new_ts = []\n",
    "    # this for iteract any chunk/bucket until reach the whole sample_size (800000)\n",
    "    for i in range(0, sample_size, bucket_size):\n",
    "        # cut each bucket to ts_range\n",
    "        ts_range = ts_std[i:i + bucket_size]\n",
    "        # calculate each feature\n",
    "        mean = ts_range.mean()\n",
    "        std = ts_range.std() # standard deviation\n",
    "        std_top = mean + std # I have to test it more, but is is like a band\n",
    "        std_bot = mean - std\n",
    "        #sm = ts_range.sum()\n",
    "        #mn = ts_range.min()\n",
    "        #mx = ts_range.max()\n",
    "        #md = ts_range.median()\n",
    "        \n",
    "        # I think that the percentiles are very important, it is like a distribuiton analysis from each chunk\n",
    "        percentil_calc = np.percentile(ts_range, [0, 1, 25, 50, 75, 99, 100])\n",
    "        max_range = percentil_calc[-1] - percentil_calc[0] # this is the amplitude of the chunk\n",
    "        relative_percentile = percentil_calc - mean # maybe it could heap to understand the asymmetry\n",
    "        # now, we just add all the features to new_ts and convert it to np.array\n",
    "        new_ts.append(np.concatenate([np.asarray([mean, std, std_top, std_bot, max_range]), percentil_calc, relative_percentile]))\n",
    "    return np.asarray(new_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function take a piece of data and convert using transform_ts(), but it does to each of the 3 phases\n",
    "# if we would try to do in one time, could exceed the RAM Memmory\n",
    "def prep_data(start, end):\n",
    "    # load a piece of data from file\n",
    "    praq_train = pq.read_pandas(path + 'train.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    X = []\n",
    "    y = []\n",
    "    # using tdqm to evaluate processing time\n",
    "    # takes each index from df_train and iteract it from start to end\n",
    "    # it is divided by 3 because for each id_measurement there are 3 id_signal, and the start/end parameters are id_signal\n",
    "    for id_measurement in tqdm_notebook(df_train.index.levels[0].unique()[int(start/3):int(end/3)]):\n",
    "        X_signal = []\n",
    "        # for each phase of the signal\n",
    "        for phase in [0,1,2]:\n",
    "            # extract from df_train both signal_id and target to compose the new data sets\n",
    "            signal_id, target = df_train.loc[id_measurement].loc[phase]\n",
    "            # but just append the target one time, to not triplicate it\n",
    "            if phase == 0:\n",
    "                y.append(target)\n",
    "            # extract and transform data into sets of features\n",
    "            X_signal.append(transform_ts(praq_train[str(signal_id)]))\n",
    "        # concatenate all the 3 phases in one matrix\n",
    "        X_signal = np.concatenate(X_signal, axis=1)\n",
    "        # add the data to X\n",
    "        X.append(X_signal)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Passed non-file path: /Python/Kaggle/VSB/train.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e908d0a4877b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mload_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#X, y = prep_data(0, len(df_train))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e908d0a4877b>\u001b[0m in \u001b[0;36mload_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mX_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-d350dd368122>\u001b[0m in \u001b[0;36mprep_data\u001b[1;34m(start, end)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# load a piece of data from file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpraq_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'train.parquet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36mread_pandas\u001b[1;34m(source, columns, use_threads, memory_map, metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                       \u001b[0muse_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                       \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m                       use_pandas_metadata=True)\n\u001b[0m\u001b[0;32m   1129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, filesystem)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         return fs.read_parquet(path, columns=columns,\n\u001b[0;32m   1106\u001b[0m                                \u001b[0muse_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m                                use_pandas_metadata=use_pandas_metadata)\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParquetFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyarrow\\filesystem.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(self, path, columns, metadata, schema, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParquetDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         dataset = ParquetDataset(path, schema=schema, metadata=metadata,\n\u001b[1;32m--> 179\u001b[1;33m                                  filesystem=self)\n\u001b[0m\u001b[0;32m    180\u001b[0m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0;32m    181\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads)\u001b[0m\n\u001b[0;32m    888\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon_metadata_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_manifest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m             path_or_paths, self.fs, metadata_nthreads=metadata_nthreads)\n\u001b[0m\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon_metadata_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36m_make_manifest\u001b[1;34m(path_or_paths, fs, pathsep, metadata_nthreads)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m                 raise IOError('Passed non-file path: {0}'\n\u001b[1;32m-> 1065\u001b[1;33m                               .format(path))\n\u001b[0m\u001b[0;32m   1066\u001b[0m             \u001b[0mpiece\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParquetDatasetPiece\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mpieces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Passed non-file path: /Python/Kaggle/VSB/train.parquet"
     ]
    }
   ],
   "source": [
    "# this code is very simple, divide the total size of the df_train into two sets and process it\n",
    "X = []\n",
    "y = []\n",
    "def load_all():\n",
    "    total_size = len(df_train)\n",
    "    for ini, end in [(0, int(total_size/2)), (int(total_size/2), total_size)]:\n",
    "        X_temp, y_temp = prep_data(ini, end)\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "load_all()\n",
    "\n",
    "#X, y = prep_data(0, len(df_train))\n",
    "\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Python/Kaggle/VSB/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 160, 57) (2904,)\n"
     ]
    }
   ],
   "source": [
    "# The X shape here is very important. It is also important undertand a little how a LSTM works\n",
    "# X.shape[0] is the number of id_measuremts contained in train data\n",
    "# X.shape[1] is the number of chunks resultant of the transformation, each of this date enters in the LSTM serialized\n",
    "# This way the LSTM can understand the position of a data relative with other and activate a signal that needs\n",
    "# a serie of inputs in a specifc order.\n",
    "# X.shape[3] is the number of features multiplied by the number of phases (3)\n",
    "print(X.shape, y.shape)\n",
    "# save data into file, a numpy specific format\n",
    "np.save(\"X.npy\",X)\n",
    "np.save(\"y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is NN LSTM Model creation\n",
    "def model_lstm(input_shape):\n",
    "    # The shape was explained above, must have this order\n",
    "    inp = Input(shape=(input_shape[1], input_shape[2],))\n",
    "    # This is the LSTM layer\n",
    "    # Bidirecional implies that the 160 chunks are calculated in both ways, 0 to 159 and 159 to zero\n",
    "    # although it appear that just 0 to 159 way matter, I have tested with and without, and tha later worked best\n",
    "    # 128 and 64 are the number of cells used, too many can overfit and too few can underfit\n",
    "    x = Bidirectional(CuDNNLSTM(512, return_sequences=True))(inp)\n",
    "    x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    # The second LSTM can give more fire power to the model, but can overfit it too\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    # Attention is a new tecnology that can be applyed to a Recurrent NN to give more meanings to a signal found in the middle\n",
    "    # of the data, it helps more in longs chains of data. A normal RNN give all the responsibility of detect the signal\n",
    "    # to the last cell. Google RNN Attention for more information :)\n",
    "    x = Attention(input_shape[1])(x)\n",
    "    # A intermediate full connected (Dense) can help to deal with nonlinears outputs\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    # A binnary classification as this must finish with shape (1,)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    # Pay attention in the addition of matthews_correlation metric in the compilation, it is a success factor key\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[matthews_correlation])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fold 1\n",
      "Train on 2613 samples, validate on 291 samples\n",
      "Epoch 1/50\n",
      "2613/2613 [==============================] - ETA: 47s - loss: 0.6943 - matthews_correlation: 0.092 - ETA: 25s - loss: 0.6203 - matthews_correlation: 0.046 - ETA: 18s - loss: 0.5204 - matthews_correlation: 0.030 - ETA: 14s - loss: 0.4632 - matthews_correlation: 0.023 - ETA: 12s - loss: 0.4255 - matthews_correlation: 0.018 - ETA: 10s - loss: 0.3987 - matthews_correlation: 0.015 - ETA: 8s - loss: 0.3809 - matthews_correlation: 0.013 - ETA: 7s - loss: 0.3652 - matthews_correlation: 0.01 - ETA: 6s - loss: 0.3432 - matthews_correlation: 0.01 - ETA: 6s - loss: 0.3303 - matthews_correlation: 0.00 - ETA: 5s - loss: 0.3242 - matthews_correlation: 0.00 - ETA: 4s - loss: 0.3091 - matthews_correlation: 0.00 - ETA: 3s - loss: 0.3070 - matthews_correlation: 0.00 - ETA: 3s - loss: 0.3002 - matthews_correlation: 0.00 - ETA: 2s - loss: 0.2890 - matthews_correlation: 0.00 - ETA: 2s - loss: 0.2896 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.2875 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.2822 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2774 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2753 - matthews_correlation: 0.00 - 10s 4ms/step - loss: 0.2752 - matthews_correlation: 0.0045 - val_loss: 0.2324 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_0.h5\n",
      "Epoch 2/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1899 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2564 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2279 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2138 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2221 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2061 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2414 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2271 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2284 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2325 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2323 - matthews_correlation: 0.0000e+00 - val_loss: 0.2324 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2748 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2851 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2614 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2429 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2414 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2341 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2397 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2391 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2298 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2404 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2268 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2214 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2251 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2244 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2306 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2314 - matthews_correlation: 0.0000e+00 - val_loss: 0.2326 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1738 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1848 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1688 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1800 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1950 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1979 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1966 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1928 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2086 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2067 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2094 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2174 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2153 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2179 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2190 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2211 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2287 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2300 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2317 - matthews_correlation: 0.0000e+00 - val_loss: 0.2362 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2930 - matthews_correlation: 0.0000e+ - ETA: 7s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2444 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2518 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2722 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2626 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2586 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2555 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2485 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2538 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2558 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2442 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2384 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2396 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2433 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2379 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2319 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2305 - matthews_correlation: 0.0000e+00 - val_loss: 0.2336 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2587 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2473 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2434 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2756 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2673 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2582 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2463 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2522 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2482 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2450 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2459 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2317 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2409 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2349 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2376 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2349 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2313 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2304 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2324 - matthews_correlation: 0.0000e+00 - val_loss: 0.2330 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1894 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2119 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1974 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1849 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1903 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2049 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2091 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2176 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2333 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2351 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2366 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2420 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2369 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2358 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2326 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2312 - matthews_correlation: 0.0000e+00 - val_loss: 0.2340 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 8/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2827 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2240 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2369 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2495 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2423 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2216 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2170 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2164 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2298 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2352 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2351 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2386 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2406 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2374 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2335 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2322 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 9/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1966 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2185 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2468 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2412 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2406 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2371 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2318 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2366 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2379 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2360 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2329 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2334 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2320 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 10/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2547 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2409 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2557 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2382 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2448 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2464 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2448 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2436 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2426 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2418 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2377 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2358 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2326 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2278 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2245 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2298 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2278 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1675 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2689 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2500 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2430 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2547 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2466 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2407 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2381 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2268 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2222 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2252 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2245 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2279 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2259 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2265 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2332 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 12/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2120 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1998 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2086 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2103 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2146 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2249 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2292 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2350 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2361 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2316 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2313 - matthews_correlation: 0.0000e+00 - val_loss: 0.2322 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 13/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1682 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2234 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2212 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2345 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2235 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2292 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2356 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2290 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2317 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2307 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2298 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2300 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2307 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 14/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2546 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2442 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2267 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2277 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2140 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2137 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2217 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2241 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2267 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2223 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2263 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2277 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2306 - matthews_correlation: 0.0000e+00 - val_loss: 0.2326 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 15/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1539 - matthews_correlation: 0.0000e+ - ETA: 7s - loss: 0.1647 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2012 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2145 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2376 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2205 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2264 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2195 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2153 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2133 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2181 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2162 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2327 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2316 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2339 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2325 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 16/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1941 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2041 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2060 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2141 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2300 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2408 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2431 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2455 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2433 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2427 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2409 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2394 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2378 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2335 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2311 - matthews_correlation: 0.0000e+00 - val_loss: 0.2322 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 17/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2118 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1892 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2126 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2187 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2129 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2165 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2375 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2400 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2396 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2492 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2444 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2415 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2411 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2370 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2326 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2369 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2335 - matthews_correlation: 0.0000e+00 - val_loss: 0.2319 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 18/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2755 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2653 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2403 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2277 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2200 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2111 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2180 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2262 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2258 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2374 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2369 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2314 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2312 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 19/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2135 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2135 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2257 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2444 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2429 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2362 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2376 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2373 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2308 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2283 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2299 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2244 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2283 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2303 - matthews_correlation: 0.0000e+00 - val_loss: 0.2314 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 20/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1669 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1997 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1964 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2057 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2069 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2077 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2189 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2206 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2179 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2211 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2204 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2180 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2206 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2243 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2259 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2317 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2305 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2293 - matthews_correlation: 0.0000e+00 - val_loss: 0.2395 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 7s - loss: 0.3760 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.3223 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.3068 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2941 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2639 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2359 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2257 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2181 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2235 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2175 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2133 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2167 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2148 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2264 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2290 - matthews_correlation: 0.0000e+00 - val_loss: 0.2377 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 22/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2574 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2225 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2160 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2119 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2358 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2562 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2481 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2463 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2493 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2420 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2375 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2352 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2294 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2299 - matthews_correlation: 0.0000e+00 - val_loss: 0.2261 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 23/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1183 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1504 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1975 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2219 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2275 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2387 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2377 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2468 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2460 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2736 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2673 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2665 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2660 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2582 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2586 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2548 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2513 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2458 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2478 - matthews_correlation: 0.0000e+00 - val_loss: 0.2360 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 24/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2720 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2743 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2644 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2449 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2531 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2372 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2247 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2402 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2308 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2271 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2305 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2348 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2325 - matthews_correlation: 0.0000e+00 - val_loss: 0.2318 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 25/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1720 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1919 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1909 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2028 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2299 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2084 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2060 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2042 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2162 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2179 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2192 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2303 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2312 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2320 - matthews_correlation: 0.0000e+00 - val_loss: 0.2313 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 26/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2215 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1881 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1868 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2068 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2226 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2138 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2186 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2358 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2427 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2403 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2427 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2418 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2349 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2343 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2303 - matthews_correlation: 0.0000e+00 - val_loss: 0.2372 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 27/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1829 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1982 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1974 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2090 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2223 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2372 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2278 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2317 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2298 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2329 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2324 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2305 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2281 - matthews_correlation: 0.0000e+00 - val_loss: 0.2175 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 28/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1753 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2106 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1937 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2107 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1963 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1924 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2157 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2228 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2262 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2260 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2222 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2192 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2221 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2233 - matthews_correlation: 0.0000e+00 - val_loss: 0.2185 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 29/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2631 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2503 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2150 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2241 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2130 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1995 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2080 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2076 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2054 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2100 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2110 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2103 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2053 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2115 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2147 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2171 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2151 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2093 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2092 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2119 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2150 - matthews_correlation: 0.0000e+00 - val_loss: 0.2073 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 30/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2733 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2542 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2530 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2427 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2548 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2512 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2489 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2402 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2352 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2440 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2457 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2456 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2362 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2364 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2403 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2305 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2311 - matthews_correlation: 0.0000e+00 - val_loss: 0.2303 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1527 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2080 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2184 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2152 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2209 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2114 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2099 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2145 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2154 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2196 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2198 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2212 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2242 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2244 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2223 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2230 - matthews_correlation: 0.0000e+00 - val_loss: 0.2023 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 32/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1826 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2162 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2103 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2115 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2151 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2277 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2167 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2132 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2158 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2177 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2157 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2137 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2119 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2147 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2173 - matthews_correlation: 0.0000e+00 - val_loss: 0.2275 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 33/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1145 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1609 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2257 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2245 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2082 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2044 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2007 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2107 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2165 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2210 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2225 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2259 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2235 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2229 - matthews_correlation: 0.0000e+00 - val_loss: 0.2193 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 34/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2764 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2082 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1916 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2019 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2156 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2176 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2239 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2264 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2413 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2332 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2278 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2213 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2204 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2197 - matthews_correlation: 0.0000e+00 - val_loss: 0.2151 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 35/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2631 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2673 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2511 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2350 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2371 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2263 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2183 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2160 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2126 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2096 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2108 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2181 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2155 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2112 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2158 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2134 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2159 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2165 - matthews_correlation: 0.0000e+00 - val_loss: 0.2097 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 36/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2012 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1900 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2503 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2443 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2303 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2192 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2118 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2118 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2092 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2157 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2118 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2192 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2132 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2100 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2116 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2222 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2164 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2172 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2156 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2158 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2136 - matthews_correlation: 0.0000e+00 - val_loss: 0.2020 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 37/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1521 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1958 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2360 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2196 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2163 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2342 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2218 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2189 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2159 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2087 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2061 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2039 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2055 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2056 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2040 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2042 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2072 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2075 - matthews_correlation: 0.0000e+00 - val_loss: 0.1932 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 38/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1879 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1782 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1773 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1766 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1799 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1851 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1782 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1857 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1923 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2018 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2018 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1951 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1930 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1960 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2003 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2000 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2016 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2009 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1988 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2020 - matthews_correlation: 0.0000e+00 - val_loss: 0.1958 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 39/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1255 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1752 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1937 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1940 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1983 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1915 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1836 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1829 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1853 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1856 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1886 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1860 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1897 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1955 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1978 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1958 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1941 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1956 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1972 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1984 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2011 - matthews_correlation: 0.0000e+00 - val_loss: 0.1963 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 40/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1684 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2114 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2416 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2282 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2271 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2162 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2187 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2057 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2052 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2073 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2006 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1966 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1924 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1881 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1923 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1962 - matthews_correlation: -0.0014   - ETA: 0s - loss: 0.1902 - matthews_correlation: -0.001 - ETA: 0s - loss: 0.1986 - matthews_correlation: -0.001 - 8s 3ms/step - loss: 0.1993 - matthews_correlation: 0.0091 - val_loss: 0.1888 - val_matthews_correlation: 0.2639\n",
      "\n",
      "Epoch 00040: val_matthews_correlation improved from 0.00000 to 0.26392, saving model to weights_0.h5\n",
      "Epoch 41/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1790 - matthews_correlation: 0.24 - ETA: 6s - loss: 0.1705 - matthews_correlation: 0.33 - ETA: 6s - loss: 0.1569 - matthews_correlation: 0.37 - ETA: 5s - loss: 0.1693 - matthews_correlation: 0.37 - ETA: 5s - loss: 0.1705 - matthews_correlation: 0.33 - ETA: 5s - loss: 0.1716 - matthews_correlation: 0.35 - ETA: 4s - loss: 0.1740 - matthews_correlation: 0.32 - ETA: 4s - loss: 0.1724 - matthews_correlation: 0.28 - ETA: 4s - loss: 0.1727 - matthews_correlation: 0.30 - ETA: 3s - loss: 0.1779 - matthews_correlation: 0.27 - ETA: 3s - loss: 0.1755 - matthews_correlation: 0.28 - ETA: 3s - loss: 0.1729 - matthews_correlation: 0.28 - ETA: 2s - loss: 0.1787 - matthews_correlation: 0.27 - ETA: 2s - loss: 0.1846 - matthews_correlation: 0.28 - ETA: 1s - loss: 0.1866 - matthews_correlation: 0.26 - ETA: 1s - loss: 0.1879 - matthews_correlation: 0.25 - ETA: 1s - loss: 0.1900 - matthews_correlation: 0.25 - ETA: 0s - loss: 0.1926 - matthews_correlation: 0.24 - ETA: 0s - loss: 0.1934 - matthews_correlation: 0.24 - ETA: 0s - loss: 0.1941 - matthews_correlation: 0.25 - 8s 3ms/step - loss: 0.1959 - matthews_correlation: 0.2512 - val_loss: 0.1790 - val_matthews_correlation: 0.4989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_matthews_correlation improved from 0.26392 to 0.49887, saving model to weights_0.h5\n",
      "Epoch 42/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1330 - matthews_correlation: 0.52 - ETA: 6s - loss: 0.1577 - matthews_correlation: 0.32 - ETA: 6s - loss: 0.1790 - matthews_correlation: 0.38 - ETA: 5s - loss: 0.1909 - matthews_correlation: 0.35 - ETA: 5s - loss: 0.1934 - matthews_correlation: 0.38 - ETA: 5s - loss: 0.1884 - matthews_correlation: 0.32 - ETA: 4s - loss: 0.1957 - matthews_correlation: 0.27 - ETA: 4s - loss: 0.1869 - matthews_correlation: 0.27 - ETA: 4s - loss: 0.1775 - matthews_correlation: 0.28 - ETA: 3s - loss: 0.1812 - matthews_correlation: 0.29 - ETA: 3s - loss: 0.1839 - matthews_correlation: 0.26 - ETA: 3s - loss: 0.1848 - matthews_correlation: 0.26 - ETA: 2s - loss: 0.1867 - matthews_correlation: 0.27 - ETA: 2s - loss: 0.1811 - matthews_correlation: 0.29 - ETA: 1s - loss: 0.1779 - matthews_correlation: 0.31 - ETA: 1s - loss: 0.1802 - matthews_correlation: 0.29 - ETA: 1s - loss: 0.1826 - matthews_correlation: 0.27 - ETA: 0s - loss: 0.1913 - matthews_correlation: 0.26 - ETA: 0s - loss: 0.1969 - matthews_correlation: 0.24 - ETA: 0s - loss: 0.1967 - matthews_correlation: 0.23 - 8s 3ms/step - loss: 0.1987 - matthews_correlation: 0.2323 - val_loss: 0.2087 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 43/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2185 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1924 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1765 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1693 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1955 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2012 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2041 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2108 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2126 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2148 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2143 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2098 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2014 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2038 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2002 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2119 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2092 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2080 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2087 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2037 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2045 - matthews_correlation: 0.0000e+00 - val_loss: 0.2024 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 44/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1356 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1563 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1638 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1617 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1958 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2034 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1979 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2071 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1994 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2062 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2080 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2093 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2053 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2000 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1981 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2051 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2067 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2038 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2010 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1978 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.1977 - matthews_correlation: 0.0000e+00 - val_loss: 0.1914 - val_matthews_correlation: 0.2146\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 45/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.1295 - matthews_correlation: 0.40 - ETA: 6s - loss: 0.1518 - matthews_correlation: 0.18 - ETA: 6s - loss: 0.1924 - matthews_correlation: 0.18 - ETA: 5s - loss: 0.1819 - matthews_correlation: 0.20 - ETA: 5s - loss: 0.2013 - matthews_correlation: 0.16 - ETA: 5s - loss: 0.1979 - matthews_correlation: 0.13 - ETA: 4s - loss: 0.2196 - matthews_correlation: 0.11 - ETA: 4s - loss: 0.2247 - matthews_correlation: 0.10 - ETA: 4s - loss: 0.2230 - matthews_correlation: 0.08 - ETA: 3s - loss: 0.2195 - matthews_correlation: 0.08 - ETA: 3s - loss: 0.2169 - matthews_correlation: 0.07 - ETA: 3s - loss: 0.2082 - matthews_correlation: 0.06 - ETA: 2s - loss: 0.2083 - matthews_correlation: 0.06 - ETA: 2s - loss: 0.2073 - matthews_correlation: 0.05 - ETA: 1s - loss: 0.2061 - matthews_correlation: 0.05 - ETA: 1s - loss: 0.2049 - matthews_correlation: 0.05 - ETA: 1s - loss: 0.2076 - matthews_correlation: 0.04 - ETA: 0s - loss: 0.2055 - matthews_correlation: 0.04 - ETA: 0s - loss: 0.2024 - matthews_correlation: 0.04 - ETA: 0s - loss: 0.2002 - matthews_correlation: 0.04 - 8s 3ms/step - loss: 0.1996 - matthews_correlation: 0.0394 - val_loss: 0.1996 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 46/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2388 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1792 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1795 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1744 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1573 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1585 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1615 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1708 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1642 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1642 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1750 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1820 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1885 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1935 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2007 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1987 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1969 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1997 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1964 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1976 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.1983 - matthews_correlation: 0.0000e+00 - val_loss: 0.1953 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 47/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1514 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1891 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2117 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1917 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1864 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1809 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1871 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1843 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1881 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1947 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1959 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.1999 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2007 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.1982 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1994 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2011 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1953 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1952 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1981 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.1949 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.1954 - matthews_correlation: 0.0000e+00 - val_loss: 0.2086 - val_matthews_correlation: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 48/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2349 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1838 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2031 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2110 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2057 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2190 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2143 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2133 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2080 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2137 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2129 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2140 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2072 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2020 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1979 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.1996 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2035 - matthews_correlation: -0.0016   - ETA: 0s - loss: 0.2058 - matthews_correlation: 0.013 - ETA: 0s - loss: 0.2097 - matthews_correlation: 0.01 - ETA: 0s - loss: 0.2039 - matthews_correlation: 0.01 - 8s 3ms/step - loss: 0.2027 - matthews_correlation: 0.0109 - val_loss: 0.1972 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 49/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2173 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2443 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2284 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2406 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2221 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2129 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2048 - matthews_correlation: -0.0010   - ETA: 3s - loss: 0.1985 - matthews_correlation: -9.3164e-0 - ETA: 2s - loss: 0.1958 - matthews_correlation: -8.5997e-0 - ETA: 2s - loss: 0.1968 - matthews_correlation: -7.9855e-0 - ETA: 1s - loss: 0.1971 - matthews_correlation: -7.4531e-0 - ETA: 1s - loss: 0.1946 - matthews_correlation: -6.9873e-0 - ETA: 1s - loss: 0.2015 - matthews_correlation: -6.5763e-0 - ETA: 0s - loss: 0.2011 - matthews_correlation: -6.2109e-0 - ETA: 0s - loss: 0.2057 - matthews_correlation: -5.8840e-0 - ETA: 0s - loss: 0.2053 - matthews_correlation: -5.5898e-0 - 8s 3ms/step - loss: 0.2031 - matthews_correlation: -9.3771e-04 - val_loss: 0.1859 - val_matthews_correlation: 0.1461\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.49887\n",
      "Epoch 50/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2130 - matthews_correlation: 0.15 - ETA: 6s - loss: 0.2250 - matthews_correlation: 0.06 - ETA: 6s - loss: 0.2252 - matthews_correlation: 0.15 - ETA: 5s - loss: 0.2043 - matthews_correlation: 0.11 - ETA: 5s - loss: 0.1893 - matthews_correlation: 0.09 - ETA: 5s - loss: 0.1997 - matthews_correlation: 0.07 - ETA: 4s - loss: 0.1921 - matthews_correlation: 0.06 - ETA: 4s - loss: 0.1917 - matthews_correlation: 0.05 - ETA: 4s - loss: 0.1943 - matthews_correlation: 0.05 - ETA: 3s - loss: 0.1965 - matthews_correlation: 0.04 - ETA: 3s - loss: 0.2035 - matthews_correlation: 0.04 - ETA: 3s - loss: 0.1908 - matthews_correlation: 0.03 - ETA: 2s - loss: 0.1991 - matthews_correlation: 0.03 - ETA: 2s - loss: 0.1994 - matthews_correlation: 0.03 - ETA: 1s - loss: 0.1932 - matthews_correlation: 0.06 - ETA: 1s - loss: 0.1925 - matthews_correlation: 0.05 - ETA: 1s - loss: 0.1912 - matthews_correlation: 0.07 - ETA: 0s - loss: 0.1927 - matthews_correlation: 0.07 - ETA: 0s - loss: 0.2003 - matthews_correlation: 0.06 - ETA: 0s - loss: 0.2012 - matthews_correlation: 0.06 - 8s 3ms/step - loss: 0.2000 - matthews_correlation: 0.0645 - val_loss: 0.2006 - val_matthews_correlation: 0.2096\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.49887\n",
      "Beginning fold 2\n",
      "Train on 2613 samples, validate on 291 samples\n",
      "Epoch 1/50\n",
      "2613/2613 [==============================] - ETA: 45s - loss: 0.6936 - matthews_correlation: 0.146 - ETA: 25s - loss: 0.6371 - matthews_correlation: 0.073 - ETA: 17s - loss: 0.5475 - matthews_correlation: 0.048 - ETA: 14s - loss: 0.4680 - matthews_correlation: 0.036 - ETA: 11s - loss: 0.3983 - matthews_correlation: 0.029 - ETA: 10s - loss: 0.3651 - matthews_correlation: 0.024 - ETA: 8s - loss: 0.3418 - matthews_correlation: 0.020 - ETA: 7s - loss: 0.3524 - matthews_correlation: 0.01 - ETA: 6s - loss: 0.3483 - matthews_correlation: 0.01 - ETA: 5s - loss: 0.3326 - matthews_correlation: 0.01 - ETA: 5s - loss: 0.3205 - matthews_correlation: 0.01 - ETA: 4s - loss: 0.3106 - matthews_correlation: 0.01 - ETA: 3s - loss: 0.3064 - matthews_correlation: 0.01 - ETA: 3s - loss: 0.3083 - matthews_correlation: 0.01 - ETA: 2s - loss: 0.3060 - matthews_correlation: 0.00 - ETA: 2s - loss: 0.2979 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.2918 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.2886 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2857 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2866 - matthews_correlation: 0.00 - 10s 4ms/step - loss: 0.2863 - matthews_correlation: 0.0072 - val_loss: 0.2326 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_1.h5\n",
      "Epoch 2/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1898 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2485 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2397 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2426 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2446 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2405 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2375 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2370 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2369 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2327 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2318 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2316 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2756 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2615 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2103 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2107 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2221 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2134 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2156 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2132 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2212 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2151 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2233 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2371 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2318 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2301 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2333 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2331 - matthews_correlation: 0.0000e+00 - val_loss: 0.2351 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2555 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2553 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2681 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2647 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2466 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2445 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2308 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2116 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2191 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2187 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2184 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2324 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2327 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2329 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2330 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2341 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2328 - matthews_correlation: 0.0000e+00 - val_loss: 0.2341 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1589 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1970 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2360 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2233 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2473 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2587 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2537 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2497 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2464 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2420 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2439 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2390 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2414 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2359 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2315 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2312 - matthews_correlation: 0.0000e+00 - val_loss: 0.2343 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.3068 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2480 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2438 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2537 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2468 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2251 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2299 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2222 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2216 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2209 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2277 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2309 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2317 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2976 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.3072 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2830 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2516 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2292 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2301 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2279 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2415 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2429 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2371 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2297 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2260 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2341 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2319 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2316 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2562 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2233 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2484 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2425 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2263 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2271 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2187 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2146 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2110 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2143 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2173 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2170 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2181 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2217 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2224 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2276 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2317 - matthews_correlation: 0.0000e+00 - val_loss: 0.2322 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 9/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1925 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2235 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2531 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2676 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2554 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2562 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2665 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2721 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2652 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2594 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2576 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2558 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2557 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2498 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2416 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2412 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2342 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2306 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2338 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2324 - matthews_correlation: 0.0000e+00 - val_loss: 0.2428 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 10/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.3245 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2580 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2528 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2497 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2426 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2495 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2442 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2381 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2395 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2317 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2335 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 11/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1706 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1915 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1912 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1964 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1907 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2056 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2098 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2101 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2155 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2083 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2086 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2109 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2198 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2192 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2293 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2247 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2302 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2309 - matthews_correlation: 0.0000e+00 - val_loss: 0.2337 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 12/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2548 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2215 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2129 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2077 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2150 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2202 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2160 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2241 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2312 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2356 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2344 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2344 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2330 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 13/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2544 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2544 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2578 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2573 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2570 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2502 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2427 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2438 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2447 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2446 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2411 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2407 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2415 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2387 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2384 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2316 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2303 - matthews_correlation: 0.0000e+00 - val_loss: 0.2333 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 14/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.3268 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2696 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2660 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2700 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2814 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2886 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2745 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2721 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2655 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2563 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2506 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2442 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2435 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2384 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2390 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2327 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2306 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2326 - matthews_correlation: 0.0000e+00 - val_loss: 0.2330 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 15/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2122 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2122 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2122 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2122 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2234 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2206 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2076 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2015 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2145 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2143 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2125 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2154 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2240 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2246 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2308 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2305 - matthews_correlation: 0.0000e+00 - val_loss: 0.2328 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 16/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2344 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2148 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2215 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2268 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2215 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2221 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2288 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2333 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2313 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 17/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 7s - loss: 0.2123 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2557 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2394 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2512 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2660 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2465 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2476 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2415 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2387 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2401 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2344 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2345 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2359 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2284 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2264 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2312 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1898 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1786 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1823 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1898 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2284 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2366 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2382 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2313 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2263 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2308 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2344 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2311 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 19/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2965 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2757 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2333 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2226 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2147 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2116 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2168 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2117 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2225 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2210 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2254 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2306 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2350 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2349 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2360 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2321 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2318 - matthews_correlation: 0.0000e+00 - val_loss: 0.2335 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 20/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2938 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2840 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2678 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2791 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2742 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2710 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2577 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2426 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2395 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2368 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2366 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2364 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2345 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2410 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2375 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2431 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2359 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2324 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2329 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 21/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2121 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2235 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2008 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2213 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2156 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2179 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2148 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2123 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2163 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2141 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2191 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2186 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2254 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2352 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2318 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2340 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2309 - matthews_correlation: 0.0000e+00 - val_loss: 0.2331 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 22/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2150 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2247 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2211 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2140 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2095 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2136 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2134 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2188 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2130 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2152 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2234 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2186 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2181 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2177 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2158 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2242 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2261 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2278 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2316 - matthews_correlation: 0.0000e+ - 7s 3ms/step - loss: 0.2314 - matthews_correlation: 0.0000e+00 - val_loss: 0.2326 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 23/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2342 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2444 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2609 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2545 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2508 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2420 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2466 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2404 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2275 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2299 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2332 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2318 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 24/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2121 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1899 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2121 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2288 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2395 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2300 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2209 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2219 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2196 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2206 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2200 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2236 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2211 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2280 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 25/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2124 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2021 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2749 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2748 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2629 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2584 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2580 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2483 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2512 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2479 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2468 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2443 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2400 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2369 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2317 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2297 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2318 - matthews_correlation: 0.0000e+00 - val_loss: 0.2345 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 26/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1892 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2483 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2360 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2509 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2517 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2387 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2381 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2335 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2370 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2431 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2511 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2552 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2492 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2362 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2329 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 27/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2547 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2443 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2169 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2345 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2465 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2551 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2439 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2430 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2376 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2239 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2246 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2311 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2347 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2313 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2128 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2128 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2127 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2127 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2212 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2292 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2261 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2323 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2293 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2254 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2339 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2318 - matthews_correlation: 0.0000e+ - 7s 3ms/step - loss: 0.2305 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 29/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1707 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1810 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1914 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2075 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2260 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2372 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2344 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2440 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2431 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2488 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2463 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2428 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2436 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2407 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2306 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2307 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2315 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 30/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1700 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1803 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1835 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1963 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2086 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2169 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2187 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2211 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2222 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2240 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2203 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2299 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2270 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2309 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 31/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2342 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1847 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1816 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2097 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2227 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2402 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2371 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2347 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2268 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2275 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2301 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2264 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2301 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2294 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2313 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 32/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2562 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2123 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1905 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1904 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2167 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2196 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2185 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2259 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2268 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2356 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2261 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2253 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2281 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2218 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2298 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2306 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 33/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1492 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1809 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2411 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2287 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2382 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2129 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2075 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2176 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2253 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2260 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2213 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2241 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2258 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2274 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2267 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2307 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 34/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1494 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2132 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2215 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2370 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2314 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2460 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2540 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2524 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2526 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2500 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2452 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2422 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2406 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2335 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2310 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 35/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1898 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2010 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2207 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2308 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2225 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2130 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2131 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2255 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2404 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2448 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2432 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2418 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2414 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2365 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2364 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2354 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2331 - matthews_correlation: 0.0000e+00 - val_loss: 0.2329 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 36/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.3543 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.3044 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2877 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2844 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2744 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2610 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2630 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2645 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2679 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2543 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2543 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2544 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2480 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2467 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2434 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2405 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2378 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2321 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2296 - matthews_correlation: 0.0000e+00 - val_loss: 0.2334 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 37/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2583 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2436 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2538 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2693 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2403 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2397 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2218 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2233 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2225 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2252 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2227 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2264 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2248 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2253 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2257 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2304 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2312 - matthews_correlation: 0.0000e+00 - val_loss: 0.2322 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1305 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1822 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1858 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1824 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2010 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2065 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2104 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2290 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2209 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2293 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2282 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2336 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2336 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2312 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 39/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1907 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2235 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2197 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2121 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2076 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1967 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2126 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2037 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2101 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2032 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2128 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2108 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2217 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2210 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2205 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2226 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2295 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2322 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2311 - matthews_correlation: 0.0000e+00 - val_loss: 0.2349 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 40/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.3309 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2839 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2559 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2416 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2265 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2240 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2249 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2330 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2247 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2253 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2348 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2359 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2323 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 41/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2988 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2342 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2199 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2127 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2169 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2162 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2310 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2420 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2364 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2341 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2321 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2388 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2399 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2368 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2341 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2329 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2330 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2320 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2306 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 42/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2551 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2229 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2252 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2267 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2278 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2259 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2283 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2207 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2201 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2240 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2302 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2291 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2270 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2296 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2287 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2306 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 43/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2754 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2853 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2884 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2750 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2594 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2426 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2262 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2401 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2283 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2323 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2340 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2356 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2326 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2289 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2282 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2274 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2317 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 44/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1452 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2451 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2923 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2883 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2815 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2670 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2568 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2468 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2433 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2386 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2401 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2363 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2377 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2374 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2357 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2394 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2343 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2332 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2310 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2318 - matthews_correlation: 0.0000e+00 - val_loss: 0.2325 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 45/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.1676 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1674 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1974 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2183 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2171 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2417 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2491 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2523 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2526 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2471 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2374 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2324 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2316 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2329 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2330 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2330 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2317 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 46/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2761 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2382 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2520 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2681 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2558 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2486 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2471 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2459 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2449 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2456 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2413 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2382 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2354 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2353 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2342 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2307 - matthews_correlation: 0.0000e+00 - val_loss: 0.2323 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 47/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2121 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1674 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1899 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2072 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2271 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2398 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2334 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2260 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2200 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2214 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2244 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2217 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2194 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2219 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2254 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2182 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2227 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2199 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2271 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2311 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2130 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2134 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2071 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2190 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2025 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1948 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2033 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2021 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2148 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2167 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2239 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2212 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2206 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2170 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2223 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2190 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2255 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2270 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2307 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2314 - matthews_correlation: 0.0000e+00 - val_loss: 0.2317 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 49/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2968 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2488 - matthews_correlation: -0.0098   - ETA: 6s - loss: 0.2530 - matthews_correlation: -0.006 - ETA: 5s - loss: 0.2642 - matthews_correlation: -0.004 - ETA: 5s - loss: 0.2791 - matthews_correlation: -0.003 - ETA: 5s - loss: 0.2678 - matthews_correlation: -0.003 - ETA: 4s - loss: 0.2586 - matthews_correlation: -0.002 - ETA: 4s - loss: 0.2512 - matthews_correlation: -0.002 - ETA: 4s - loss: 0.2492 - matthews_correlation: -0.002 - ETA: 3s - loss: 0.2398 - matthews_correlation: -0.002 - ETA: 3s - loss: 0.2420 - matthews_correlation: -0.001 - ETA: 3s - loss: 0.2380 - matthews_correlation: -0.001 - ETA: 2s - loss: 0.2366 - matthews_correlation: -0.001 - ETA: 2s - loss: 0.2489 - matthews_correlation: -0.001 - ETA: 1s - loss: 0.2436 - matthews_correlation: -0.001 - ETA: 1s - loss: 0.2430 - matthews_correlation: -0.001 - ETA: 1s - loss: 0.2426 - matthews_correlation: -0.001 - ETA: 0s - loss: 0.2399 - matthews_correlation: -0.001 - ETA: 0s - loss: 0.2387 - matthews_correlation: -0.001 - ETA: 0s - loss: 0.2405 - matthews_correlation: -9.8393e-0 - 8s 3ms/step - loss: 0.2381 - matthews_correlation: -9.6397e-04 - val_loss: 0.2315 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 50/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2528 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2116 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.1678 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1900 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2024 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2093 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2127 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2119 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2273 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2320 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2301 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2383 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2367 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2362 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2346 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2309 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2303 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2304 - matthews_correlation: 0.0000e+00 - val_loss: 0.2343 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.00000\n",
      "Beginning fold 3\n",
      "Train on 2613 samples, validate on 291 samples\n",
      "Epoch 1/50\n",
      "2613/2613 [==============================] - ETA: 46s - loss: 0.6947 - matthews_correlation: 0.099 - ETA: 25s - loss: 0.6408 - matthews_correlation: 0.049 - ETA: 18s - loss: 0.5442 - matthews_correlation: 0.033 - ETA: 14s - loss: 0.4637 - matthews_correlation: 0.024 - ETA: 11s - loss: 0.4288 - matthews_correlation: 0.019 - ETA: 10s - loss: 0.4035 - matthews_correlation: 0.016 - ETA: 8s - loss: 0.3801 - matthews_correlation: 0.014 - ETA: 7s - loss: 0.3644 - matthews_correlation: 0.01 - ETA: 6s - loss: 0.3499 - matthews_correlation: 0.01 - ETA: 5s - loss: 0.3271 - matthews_correlation: 0.00 - ETA: 5s - loss: 0.3261 - matthews_correlation: 0.00 - ETA: 4s - loss: 0.3209 - matthews_correlation: 0.00 - ETA: 3s - loss: 0.3198 - matthews_correlation: 0.00 - ETA: 3s - loss: 0.3212 - matthews_correlation: 0.00 - ETA: 2s - loss: 0.3145 - matthews_correlation: 0.00 - ETA: 2s - loss: 0.3122 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.3017 - matthews_correlation: 0.00 - ETA: 1s - loss: 0.2983 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2919 - matthews_correlation: 0.00 - ETA: 0s - loss: 0.2933 - matthews_correlation: 0.00 - 10s 4ms/step - loss: 0.2929 - matthews_correlation: 0.0049 - val_loss: 0.2341 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_2.h5\n",
      "Epoch 2/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2126 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2009 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2214 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2195 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2471 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2374 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2338 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2219 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2189 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2241 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2231 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2272 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2351 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2325 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2315 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2305 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2275 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2279 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2319 - matthews_correlation: 0.0000e+00 - val_loss: 0.2320 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2550 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2652 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2616 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2599 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2385 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2266 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2172 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2143 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2186 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2244 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2275 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2300 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2237 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2230 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2282 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2245 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2214 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2256 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2314 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2322 - matthews_correlation: 0.0000e+00 - val_loss: 0.2329 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2345 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2158 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2100 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1975 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1894 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.1832 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1997 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.1957 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2053 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2108 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2110 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2152 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2205 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2232 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2328 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2305 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2286 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2300 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2312 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2338 - matthews_correlation: 0.0000e+00 - val_loss: 0.2362 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2613/2613 [==============================] - ETA: 7s - loss: 0.2193 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2470 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2379 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2331 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2337 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2438 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2510 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2464 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2404 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2333 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2294 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2261 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2269 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2276 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2250 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2304 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2280 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2285 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2252 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2291 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2322 - matthews_correlation: 0.0000e+00 - val_loss: 0.2321 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/50\n",
      "2613/2613 [==============================] - ETA: 6s - loss: 0.2768 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2860 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.3142 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2819 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2809 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2608 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2632 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2627 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2621 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2633 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2608 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2520 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2458 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2434 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2459 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2380 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2322 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2327 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2319 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2325 - matthews_correlation: 0.0000e+ - 8s 3ms/step - loss: 0.2336 - matthews_correlation: 0.0000e+00 - val_loss: 0.2397 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/50\n",
      "2432/2613 [==========================>...] - ETA: 6s - loss: 0.2930 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2786 - matthews_correlation: 0.0000e+ - ETA: 6s - loss: 0.2726 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2689 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2619 - matthews_correlation: 0.0000e+ - ETA: 5s - loss: 0.2607 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2683 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2644 - matthews_correlation: 0.0000e+ - ETA: 4s - loss: 0.2595 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2540 - matthews_correlation: 0.0000e+ - ETA: 3s - loss: 0.2510 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2469 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2419 - matthews_correlation: 0.0000e+ - ETA: 2s - loss: 0.2428 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2355 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2341 - matthews_correlation: 0.0000e+ - ETA: 1s - loss: 0.2418 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2402 - matthews_correlation: 0.0000e+ - ETA: 0s - loss: 0.2375 - matthews_correlation: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Here is where the training happens\n",
    "\n",
    "# First, create a set of indexes of the 5 folds\n",
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=random_state).split(X, y))\n",
    "preds_val = []\n",
    "y_val = []\n",
    "# Then, iteract with each fold\n",
    "# If you dont know, enumerate(['a', 'b', 'c']) returns [(0, 'a'), (1, 'b'), (2, 'c')]\n",
    "for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "    K.clear_session() # I dont know what it do, but I imagine that it \"clear session\" :)\n",
    "    print(\"Beginning fold {}\".format(idx+1))\n",
    "    # use the indexes to extract the folds in the train and validation data\n",
    "    train_X, train_y, val_X, val_y = X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "    # instantiate the model for this fold\n",
    "    model = model_lstm(train_X.shape)\n",
    "    # This checkpoint helps to avoid overfitting. It just save the weights of the model if it delivered an\n",
    "    # validation matthews_correlation greater than the last one.\n",
    "    ckpt = ModelCheckpoint('weights_{}.h5'.format(idx), save_best_only=True, save_weights_only=True, verbose=1, monitor='val_matthews_correlation', mode='max')\n",
    "    # Train, train, train\n",
    "    model.fit(train_X, train_y, batch_size=128, epochs=50, validation_data=[val_X, val_y], callbacks=[ckpt])\n",
    "    # loads the best weights saved by the checkpoint\n",
    "    model.load_weights('weights_{}.h5'.format(idx))\n",
    "    # Add the predictions of the validation to the list preds_val\n",
    "    preds_val.append(model.predict(val_X, batch_size=512))\n",
    "    # and the val true y\n",
    "    y_val.append(val_y)\n",
    "\n",
    "# concatenates all and prints the shape    \n",
    "preds_val = np.concatenate(preds_val)[...,0]\n",
    "y_val = np.concatenate(y_val)\n",
    "preds_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#160 bins\n",
    "#default model\n",
    "Epoch 00050: val_matthews_correlation did not improve from 0.64946\n",
    "Wall time: 13min 28s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#160 bins\n",
    "#with one more recurrent LSTM layer\n",
    "Epoch 00050: val_matthews_correlation did not improve from 0.69118\n",
    "Wall time: 26min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of this kernel must be binary (0 or 1), but the output of the NN Model is float (0 to 1).\n",
    "# So, find the best threshold to convert float to binary is crucial to the result\n",
    "# this piece of code is a function that evaluates all the possible thresholds from 0 to 1 by 0.01\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm_notebook([i * 0.01 for i in range(100)]):\n",
    "        score = K.eval(\n",
    "            matthews_correlation(\n",
    "                tf.convert_to_tensor(y_true, np.float64),\n",
    "                tf.convert_to_tensor((y_proba > threshold), np.float64))\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'matthews_correlation': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fed25197324578a5edacdcbee9ac7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bbeab1d2bbef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'threshold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-3d708953d0ac>\u001b[0m in \u001b[0;36mthreshold_search\u001b[1;34m(y_true, y_proba)\u001b[0m\n\u001b[0;32m      9\u001b[0m             matthews_correlation(\n\u001b[0;32m     10\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 tf.convert_to_tensor((y_proba > threshold), np.float64))\n\u001b[0m\u001b[0;32m     12\u001b[0m         )\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \"\"\"\n\u001b[1;32m--> 713\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5155\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5156\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5157\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_threshold = threshold_search(y_val, preds_val)['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now load the test data\n",
    "# This first part is the meta data, not the main data, the measurements\n",
    "meta_test = pd.read_csv(path + 'metadata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test = meta_test.set_index(['signal_id'])\n",
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First we daclarete a series of parameters to initiate the loading of the main data\n",
    "# it is too large, it is impossible to load in one time, so we are doing it in dividing in 10 parts\n",
    "first_sig = meta_test.index[0]\n",
    "n_parts = 10\n",
    "max_line = len(meta_test)\n",
    "part_size = int(max_line / n_parts)\n",
    "last_part = max_line % n_parts\n",
    "print(first_sig, n_parts, max_line, part_size, last_part, n_parts * part_size + last_part)\n",
    "# Here we create a list of lists with start index and end index for each of the 10 parts and one for the last partial part\n",
    "start_end = [[x, x+part_size] for x in range(first_sig, max_line + first_sig, part_size)]\n",
    "start_end = start_end[:-1] + [[start_end[-1][0], start_end[-1][0] + last_part]]\n",
    "print(start_end)\n",
    "X_test = []\n",
    "# now, very like we did above with the train data, we convert the test data part by part\n",
    "# transforming the 3 phases 800000 measurement in matrix (160,57)\n",
    "for start, end in start_end:\n",
    "    subset_test = pq.read_pandas(path + 'test.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    for i in tqdm(subset_test.columns):\n",
    "        id_measurement, phase = meta_test.loc[int(i)]\n",
    "        subset_test_col = subset_test[i]\n",
    "        subset_trans = transform_ts(subset_test_col)\n",
    "        X_test.append([i, id_measurement, phase, subset_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input = np.asarray([np.concatenate([X_test[i][3],X_test[i+1][3], X_test[i+2][3]], axis=1) for i in range(0,len(X_test), 3)])\n",
    "np.save(\"X_test.npy\",X_test_input)\n",
    "X_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + 'sample_submission.csv')\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = []\n",
    "for i in range(N_SPLITS):\n",
    "    model.load_weights('weights_{}.h5'.format(i))\n",
    "    pred = model.predict(X_test_input, batch_size=300, verbose=1)\n",
    "    pred_3 = []\n",
    "    for pred_scalar in pred:\n",
    "        for i in range(3):\n",
    "            pred_3.append(pred_scalar)\n",
    "    preds_test.append(pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = (np.squeeze(np.mean(preds_test, axis=0)) > best_threshold).astype(np.int)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = preds_test\n",
    "submission.to_csv(path + 'submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
